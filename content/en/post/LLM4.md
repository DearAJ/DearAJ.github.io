---
date: 2025-05-11T11:00:59-04:00
description: "RAG（检索增强生成）是一种结合信息检索与文本生成的技术，其核心思想是在生成答案前，先从外部知识库中检索相关文档或信息作为参考，从而增强生成内容的准确性和事实性。"
featured_image: "/images/RAG/pia.jpg"
tags: ["LLM"]
title: "LLM - 4.大模型增强 - RAG"
---

![0-1](/images/RAG/0-1.png)

<!--more-->

![0-2](/images/RAG/0-2.png)

**背景**：

1. 即便是参数量巨大的模型，其知识记忆效率依然较低，且难以完全覆盖所有领域的知识点。
1. “幻觉”问题：当模型需要处理最新的科技进展、时事新闻或特定领域的专业知识时，其生成结果可能出现错误、不完整甚至虚构的现象。

![0-3](/images/RAG/0-3.jpg)

&nbsp;

## 1 检索增强生成基础

**检索增强生成(Retrieval-Augmented Generation, RAG)**：通过引入**外部知识库**或**实时搜索工具**，使模型在推理和生成过程中能够动态检索相关信息。

### 1.1 RAG 系统框架

**核心**：将**外部检索**与**生成模块**有机整合，通过动态引入外部知识来提升生成结果的准确性与可靠性。

![1](/images/RAG/1.png)

**检索模块**：从外部知识库或数据源中定位与用户查询相关的信息。

**生成模块**：基于检索器提供的相关内容生成最终的答案。

&nbsp;

### 1.2 RAG 任务分级

![2](/images/RAG/2.png)

1. #### 显性事实查询

   最简单的一类，通常以明文形式呈现，无需复杂的推理或逻辑分析即可解答。

   **主要任务**：准确定位和提取相关信息，生成准确的响应。

   **挑战**：数据处理；数据检索；评估。

2. #### 隐性事实查询

   涉及信息之间不直接显现的数据关系，通常需要一定程度的常识推理或基本逻辑推导。

   **主要任务**：将原始查询分解为多个检索操作，并将结果聚合为一个完整的答案；多步推理。

   **挑战**：自适应检索量；推理与检索之间的协调。

3. #### 可解释推理查询

   借助外部数据（纯文本/结构化指令）提供推理依据的相对直接的查询任务。

   **挑战**：提示优化成本；可解释性受限。

4. #### 隐性推理查询

   通常隐含在数据（领域内数据、前置知识）中，体现为一种内嵌于数据中的领域专业知识。

   **挑战**：逻辑检索；数据不足。

&nbsp;

### 1.3 RAG 系统难点

检索质量、系统效率与任务优化、多模态扩展。

&nbsp;

&nbsp;

## 2 模块化 RAG 架构 (Modular RAG)

![3](/images/RAG/3.png)

分为三个层级：

+ 顶层聚焦于 RAG 的关键阶段，将每个阶段视为独立模块，同时引入一个编排模块来协调 RAG 流程；
+ 中层由每个模块内的子模块组成，进一步细化和优化各项功能；
+ 底层由操作的基本单元（即操作符）构成.

### 2.1 索引模块

**核心任务**: 将文档划分为可管理的片段（Chunk），也成为“块”。

+ 较大的片段在构建时能够捕获更多上下文信息；但不准确、计算成本高、内容冗余。
+ 较小的片段在设计上更加精炼，噪声较少；难支持语义理解、信息间难关联。

**解决方法**：块优化 / 结构优化。

1. #### 向量块优化

   + **滑动窗口方法**

     在相邻片段之间引入重叠区域。重叠区域包含了相邻块中共同的内容，确保了上下文信息延续。

     ![4](/images/RAG/4.png)

   + **语义块切分方法**

     根据内容的语义连贯性，将文档动态划分为完整思想或主题单元。

     ![5](/images/RAG/5.png)

     如果相邻段落之间的嵌入向量的相似度较高，就将它们合并为同一语义块；如果相似度显著降低，则开启一个新的块。

   + **小到大（Small-to-Big）**

     将用于检索的片段与用于生成的片段分开处理。

     1. 从较小的总结片段中进行检索，并引用它们对应的父级较大片段。
     2. 或：直接检索单独的句子，并结合其周围的文本构建上下文。

2. #### 结构化组织

   **层次化索引**：一种基于文档层次结构组织内容的技术。建立父子节点之间的关联关系，将文档内容分解为不同层次的片段，并链接到相应的节点上。

   ![6](/images/RAG/6.png)

   构建层次化索引的方法：

   + 结构感知：通过显式的文本结构（如段落、章节）进行分层组织；
   + 内容感知：利用文档的原生格式自动提取标题、目录等层级关系；
   + 语义感知：基于语义识别技术，对文本进行深度语义分割，捕捉隐藏的语义层次和逻辑关系。

   **知识图谱索引（KG Index）**：通过将文档组织为图结构，显式表示文档内容的语义关联。

&nbsp;

### 2.2 检索前优化 (Pre-retrievalProcessing)

**目的**：用于优化查询输入，从而提高检索的有效性。

**挑战**：查询措辞不当；语言复杂性和歧义性。

**核心模块**：查询扩展、查询转换、查询组织。

1. #### 查询扩展

   通过将单一查询扩展为多个查询的方法，丰富查询的内容，弥补原始查询中可能缺乏的细节和语义信息。

   + **多查询(Multi-Query)**：提示工程利用大语言模型将单一查询扩展为多个查询，并支持并行执行。
   + **子查询(Sub-Query)**：对复杂问题进行分解和规划，将其转化为多个更易处理的子问题。
   + 验证链(Chain-of-Verification, CoVe)：让大语言模型对扩展生成的子查询及其结果进行逐步验证，减少生成内容与真实情况不符的问题。

2. #### 查询转换

   又称查询改写，指通过对用户的原始查询进行改写或重构，将其转换为更适合检索和生成的形式。

   + HyDE：首先生成假设文档（即假定的答案），并根据生成的假设文档进行搜索。
   + 反向 HyDE：系统为每个文档片段生成一个假设查询。

3. #### 查询结构化

   将用户的查询重新构建为适应不同数据类型，例如结构化数据（如表格和图形数据）的查询。

&nbsp;

### 2.3 检索

**目标**：适应不同的数据类型和查询类型。

**分类**：稀疏检索、稠密检索、混合检索。

1. #### 稀疏检索

   基于统计特征的方法，通过将查询和文档转换为**稀疏向量**来实现检索。

   ![7](/images/RAG/7.png)

   稀疏检索（如 TF-IDF 和 BM25）擅长处理显性特征，且高效。

   **缺点**：捕捉复杂语义关系的局限性。

2. #### 稠密检索

   通过深度学习模型将查询和文档编码为**稠密向量**的检索方法。

   ![8](/images/RAG/8.png)

   稠密检索（如基于深度学习模型生成的语义向量）能够捕捉复杂的语义关系。

   **缺点**：计算成本和存储要求。

3. #### 混合检索

   将稀疏向量和稠密向量的得分进行融合，或者在检索流程中分阶段使用两者。

   ![9](/images/RAG/9.png)

   1. 粗排：使用稀疏检索从大规模文档库中快速筛选出一个候选集合。
   2. 对候选文档进行稠密检索或语义重排序，以提升结果的相关性。

&nbsp;

### 2.4 检索后优化

挑战：

+ **中间遗忘**：对长文本往往只能记住开头和结尾部分，而容易遗忘中间内容；
+ **"噪声/反事实"文本**：检索到的文本中可能包含噪声信息或与事实相悖的内容；
+ **上下文窗口长度有限**：即使检索到了大量相关内容，也无法全部纳入模型处理。

常见组成部分：重排序（Rerank）、内容压缩、内容选择等

1. #### 重排序

   **目的**：对检索到的文章片段（chunks）进行**重新排序**，以提升结果的相关性和多样性。

   + **基于规则**的重排序：通过计算特定的指标（多样性、相关性、最大边际相关性等）对数据块进行排序。
   + **基于模型**的重排序：利用语言模型对数据块进行排序，通常通过计算数据块与查询之间的相关性来完成。

2. #### 内容压缩

   **目标**：通过内容压缩**减少噪声**，同时保留信息完整性。

   + 通过**小型语言模型**对检索内容进行对齐和预训练，以检测并移除提示中的不重要信息
   + 利用**大语言模型**对检索内容进行评估（LLM-Critique）

3. #### 内容选择

   通过识别和移除冗余信息，**保留最为关键**的内容。

   关键：计算输入内容的**自信息量**（衡量内容信息价值的指标）。

&nbsp;

### 2.5 生成 (整个RAG系统核心)

利用大语言模型结合**用户查询**与**检索到的上下文信息**生成答案。

&nbsp;

### 2.6 编排 (核心控制单元)

编排模块**在关键节点进行决策，并动态选择后续步骤**。

主要模块：路由（Routing）、调度（Scheduling）、融合（Fusion）。

1. #### 路由

   将查询分配到针对不同场景设计的特定管道中。

   + **元数据路由（Metadata Routing）**

     每个 RAG 流程都定义了一组**关键词**，当查询中的关键词与某流程的关键词集合匹配度高时，被选为处理流程。

     适合：对显性关键词高度敏感的场景

   + **语义路由（Semantic Routing）**

     依赖查询的语义信，每个意图对应一个具体的 RAG 流程，路由机制根据最大匹配概率选择最相关的流程。

     适合：需要深层次意图理解的复杂场景

   + **混合路由（Hybrid Routing）**

     结合元数据路由和语义路由的优点，引入权重因子，在元数据匹配和语义分析之间找到平衡点。

     适合：复杂、多样化的查询环境

2. #### 调度

   识别关键节点，负责管理和协调系统的各个流程。

   + **规则判定（Rule Judge）**

     评估生成答案的质量并决定进一步的操作。

     系统检查生成答案中每个词的概率是否高于设定的阈值 τ，若满足条件，则接受当前答案；否则，系统会重新生成新答案。

   + **大语言模型直接进行判断（LLM Judge）**

     + 利用 LLM 的上下文学习能力，通过精心设计的提示来进行决策；
     + 通过对 LLM 进行微调，使其生成特定的触发标记，来直接控制模型的行为。

   + **知识引导调度（Knowledge-Guided Scheduling）**

     中间方法，通过知识图谱引导信息检索与生成过程：构建推理链，每个节点包含解决问题所需的关键信息，并据此分别进行信息检索和内容生成。

3. #### 融合

   整合各分支生成的信息。

   + **大语言模型融合**

     利用大语言模型强大的分析与整合能力，将不同分支的信息进行统一处理。

   + **加权集成**

     通过不同分支生成的词元（token）的加权值来综合选择最终输出。

     权重是通过文档与输入查询的相似度得分计算。

   + **倒数排名融合（Reciprocal Rank Fusion， RRF）**

     一种定制的加权平均方法，将多个检索结果的排名整合为统一的列表。

&nbsp;

&nbsp;

## 3 RAG 系统设计模式

**RAG flow**：各种模式通过模块化操作符之间的协作形成了模块的工作流。

### 3.1 线性模式

![10](/images/RAG/10.png)

如：“重写-检索-阅读”(RRR)方法。

&nbsp;

### 3.2 条件模式

![11](/images/RAG/11.png)

&nbsp;

### 3.3 分支模式

并行运行多个分支，有分支的结果通过聚合函数合并为中间输出结果。

+ #### 预检索分支模式

  分支间执行不同的流程。通过生成多个子查询，并**并行**检索。

  ![12](/images/RAG/12.png)

+ #### 后检索分支模式

  分支间执行相同的 RAG 流程。每个文档块被独立送入生成模块进行处理，生成对应的结果集合。

  ![13](/images/RAG/13.png)

&nbsp;

### 3.4 循环模式

关键在于**判断模块**，用于决定流程是否需要返回到之前的模块或继续向下执行。

+ #### 迭代型

  多次循环执行检索和生成操作，在每次迭代中逐步优化结果。

  ![14](/images/RAG/14.png)

+ #### 递归型

  每一步都依赖于前一步的输出，通过不断加深检索过程，逐步挖掘更深层次的信息。

  **每次检索都会基于一个重新改写的查询展开。**

  ![15](/images/RAG/15.png)

+ #### 自适应型（主动型）

  通过动态调整检索流程，主动决定何时进行检索以及何时终止流程并生成最终结果。

  ![16](/images/RAG/16.png)

  + **基于提示的方法**

    通过设计动态提示对模型进行引导

  + **基于指令微调的方法**

    利用指令微调的方法实现更精准的检索控制

&nbsp;

&nbsp;

## 4 RAG 系统训练与优化

### 4.1 文本嵌入模型微调

**文本嵌入（Text Embedding）**：将文本转换为固定维度向量（通常是高维浮点数组），旨在以数学形式捕捉语言的语义信息，并将其映射到向量空间中。

+ #### 研究历史

  1. **计数式嵌入**

     用词频和逆文档频率来表示文本，但忽略了词语的语义和上下文信息。

  2. **静态词嵌入**

     通过上下文生成固定的词向量，但每个词的向量是静态的，无法反映词义在不同上下文中的变化。

  3. **上下文嵌入**

     引入了上下文敏感的动态嵌入模型，生成能够根据上下文调整的词或句子向量，实现了对多义词和复杂语境的更深层次理解。

  4. **通用文本嵌入**

     最新阶段：致力于构建能适配多任务、多领域、多语言的统一模型。

+ #### 代表模型

  +  **GTE 模型 (General-purpose Text Embedding)**

    引入了多阶段对比学习策略，并采用多样化的训练数据混合方式。

  + **REMED**

    其中 EM-FT 模型通过高效的嵌入式微调方法，对预训练模型中的医学句子表示进行端到端微调。

  + **MMD**

    一个综合且可靠的医学信息检索评估基准。

  + **MPD**

    一个从美国国家生物技术信息中心采样 1,000 篇医学论文构建而成的数据集。

&nbsp;

### 4.2 查询优化

1. **简单查询**：直接生成答案，从而减少无关上下文对响应质量的影响。
2. **复杂查询**：将查询拆解为可解答的子查询，分别检索相关信息，整合子查询结果，生成对原始查询的完整回答。
3. **多义性较强的模糊查询**：通过识别用户意图来澄清查询内容，并构建精准的检索请求，获取相关信息后生成细致且全面的响应。

#### RQ-RAG 算法

能够通过重写、分解和消除歧义来动态优化搜索查询。

+ **核心**：构建与推理过程相匹配的训练数据。

  ![17](/images/RAG/17.png)

+ **解码策略**：树形解码

  ![16](/images/RAG/18.png)

RQ-RAG 能生成多条候选轨迹，通过逐步迭代的方式全面探索潜在答案的空间，为最终的响应提供更丰富的支持。

&nbsp;

### 4.3 幻觉感知的生成模型优化

+ **Hallucination Aware Tuning(RAG-HAT)**

  该方法通过训练幻觉检测模型，识别出幻觉并给出易于理解的解释，说明幻觉产生的位置和原因，以及提供防御性建议。

  + **训练过程**

    1. 专注于训练模型输出幻觉的预测标签，完成基础的幻觉检测任务；
    2. 通过使用 LoRA 微调，使模型能够基于预测标签生成幻觉的详细解释，包括幻觉描述以及防御性建议。

  + **直接偏好优化(DPO)方法**

    通过构建成对的偏好数据集，指导大语言模型生更少幻觉内容的回答。

  + **“过于谨慎惩罚”(OCP)策略**

    从“优选”样本中删除一个句子以生成“拒绝”（Rejected）样本，鼓励模型在减少幻觉的同时保持回答的内容完整性。

&nbsp;

### 4.4 重排模型优化

对检索到的候选文档进行精细**排序**，**优先选择那些与输入问题更相关的文档**，为生成模型提供更高质量的上下文。

+ #### JudgeRank

  一种专为需要**深入推理**的文本检索任务设计的**零样本点式重排序方法**

  + **问题分析**：通过提示识别查询中的核心问题；
  + **文档摘要**：对每个候选文档生成抽取式摘要，并解释文档如何回应查询；
  + **相关性判断**：基于之前的分析，模型对文档的相关性进行最终判断。

&nbsp;

### 4.5 检索与生成联合优化

+ #### RankRAG

  利用单个大语言模型完成重排序和答案生成。

  **两阶段微调策略**：

  ![19](/images/RAG/19.png)

  1. **有监督微调**提升语言模型的基本指令遵循能力
  2. **指令调优**专注于增强模型的检索排序和生成能力。

  **核心**：将各种任务标准化为统一的 QA 格。

  + **推理流程**
    1. **检索**：从语料库中检索出与问题相关的前 N 个上下文。
    2. **重排序**：计算问题与检索到的 N 个上下文之间的相关性得分（生成正确答案（True）的概率）。
    3. **生成**：保留的前 k 个上下文与问题连接后输入 RankRAG 模型，用于生成最终答案。

&nbsp;

&nbsp;

## 5 RAG 系统评估

**检索模块**： RAG 系统的核心部分，负责从庞大的外部知识库中提取与用户查询相关的信息。

**生成模块**：通过大语言模型对检索结果进行加工，以生成连贯且与查询相关的回答。

### 5.1 评估目标

1. #### 检索模块的评估目标

   相关性（Relevance）、准确性（Accuracy）、覆盖率与多样性（Coverage and Diversity）、动态适应性（Dynamic Adaptability）、排序能力（Ranking Ability）（系统是否能够将最相关的文档排在前面）。

2. #### 生成模块的评估目标

   相关性（Relevance）、真实性与忠实度（Faithfulness）、正确性（Correctness）、连贯性与流畅性（Coherence and Fluency）、生成内容的多维度要求（Multi-Dimensional Requirements）、开放性任务的适应能力（Adaptability to Open Tasks）。

3. #### 整体系统的评估目标

   协作效果（Collaboration Effectiveness）、任务完成度（Task Completion Rate）、用户体验（User Experience）、鲁棒性与容错能力（Robustness and Fault Tolerance）

&nbsp;

### 5.2 评估数据集

1. #### 基于现有资源的数据集

   例如： KILT(Knowledge Intensive Language Tasks) 基准和 SuperGLUE 数据

   **优势**：提供了标准化的测试场景和广泛的任务覆盖范围。

   **局限**：难以反映动态、真实场景中知识的时效性需求。

2. #### 自动生成的数据集

   利用大语言模型设计查询及其对应的答案，从而为特定评估目标生成定制化数据集。

   例如：RGB、MultiHop-RAG 和 CRUD-RAG

3. #### 数据集的构建策略

   结合任务特点与评估目标，更好地模拟复杂任务场景。

&nbsp;

&nbsp;

## 6 实践： LangChain 框架实现 RAG

#### 6.1 构建一个基础的 RAG 系统

![20](/images/RAG/20.png)

#### 6.2 包含 查询分解 与 检索结果融合 的RAG系统

![21](/images/RAG/21.png)

![22](/images/RAG/22.png)

![23](/images/RAG/23.png)
