---
date: 2025-04-24T11:00:59-04:00
description: ""
featured_image: "/images/resnet18/pia.jpg"
tags: ["CV"]
title: "ResNet18"
---

### 1. 退化现象

ResNet 随着网络层不断的加深，模型的准确率

1. 先是不断的提高，达到最大值（准确率饱和），
2. 然后随着网络深度的继续增加，模型准确率出现大幅度的降低。

**原因**：随着网络深度的不断增大，所引入的激活函数也越来越多，数据被映射到更加离散的空间，此时已经难以让数据回到原点。也就是说，神经网络将这些数据映射回原点所需要的计算量，已经远远超过我们所能承受的。

&nbsp;

### 2. 快捷连接

核心思想：通过添加额外的连接来解决深度神经网络训练中的**梯度消失和梯度爆炸**等问题，从而允许构建非常深的神经网络。 

![1](/images/resnet18/1.jpg)

<!--more-->

残差：观测值与估计值之间的差。

这里H(x)就是观测值，x就是估计值（也就是上一层ResNet输出的特征映射）。

一般称 **x** 为identity Function，它是一个跳跃连接；称 **F(x)** 为ResNet Function。 

+ 注：如果残差映射 F(x) 的结果的维度与跳跃连接 x 的维度不同，须对x进行升维操作：

  - 全0填充；

  - 采用1*1卷积。

&nbsp;

### 3. ResNet18 结构图

含义：网络的基本架构是ResNet，**网络的深度是18层**。

但是这里的网络深度指的是网络的权重层，也就是包括池化，激活，线性层。而不包括批量化归一层，池化层。

![2](/images/resnet18/2.png)



#### 

