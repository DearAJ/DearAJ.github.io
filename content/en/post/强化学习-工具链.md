---
date: 2025-04-04T04:00:59-07:00
description: ""
featured_image: "/images/RLchain/pia.jpg"
tags: ["RL"]
title: "强化学习-工具链"
---

## 1. gym

官方文档：https://www.gymlibrary.dev

+ 最小例子 `CartPole-v0`

  ```python3
  import gymenv = gym.make('CartPole-v0')
  env.reset()
  for _ in range(1000):
      env.render()
      env.step(env.action_space.sample()) # take a random action
  ```

&nbsp;

### 观测 (Observations)

在 Gym 仿真中，每一次回合开始，需要先执行 `reset()` 函数，返回**初始观测信息，然后根据标志位 `done` 的状态，来决定是否进行下一次回合**。代码表示：

&nbsp;

 `env.step()` 函数对每一步进行仿真，返回 4 个参数：

- **观测** Observation (Object)：当前 step 执行后，环境的观测(类型为对象)。例如，从相机获取的像素点，机器人各个关节的角度或棋盘游戏当前的状态等；

- **奖励** Reward (Float): 执行上一步动作(action)后，智体(agent)获得的奖励，不同的环境中奖励值变化范围也不相同，但是强化学习的目标就是使得总奖励值最大；

- **完成** Done (Boolen): 表示是否需要将环境重置 `env.reset`。

  <!--more-->

  大多数情况下，当 `Done` 为 `True`时，就表明当前回合(episode)或者试验(tial)结束。例如当机器人摔倒或者掉出台面，就应当终止当前回合进行重置(reset);

- **信息** Info (Dict): 针对调试过程的诊断信息。在标准的智体仿真评估当中不会使用到这个 info。

总结来说，这就是一个强化学习的基本流程：在每个时间点上，智体执行 action，环境返回上一次 action 的观测和奖励。

&nbsp;

### 空间（Spaces）

每次执行的动作(action)都是从环境动作空间中随机进行选取的.

在 Gym 的仿真环境中，有**运动空间 `action_space`** 和**观测空间 `observation_space`** 两个指标，程序中被定义为 `Space`类型，用于描述有效的运动和观测的格式和范围。

```python
import gymenv = gym.make('CartPole-v0')
print(env.action_space)#> Discrete(2)
print(env.observation_space)#> Box(4,)
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
Discrete(2)
Box(4,)
```

&nbsp;

### 注册表

Gym 是一个包含各种各样强化学习仿真环境的大集合，并且封装成通用的接口暴露给用户，查看所有环境的代码如下：

```python
from gym import envsprint(envs.registry.all())
dict_values([EnvSpec(Copy-v0), EnvSpec(RepeatCopy-v0), EnvSpec(ReversedAddition-v0), EnvSpec(ReversedAddition3-v0), EnvSpec(DuplicatedInput-v0), EnvSpec(Reverse-v0), EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v0), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v2),...
```

Gym 支持将用户制作的环境写入到注册表中，需要执行 `gym.make()` 和在启动时注册 `register`，如:

```python3
register(
    id='CartPole-v0',
    entry_point='gym.envs.classic_control:CartPoleEnv',
    max_episode_steps=200,
    reward_threshold=195.0,
)
```

&nbsp;

###  gym 基本函数接口

1. make()：生成环境对象
2.  reset()：环境复位初始化函数。将环境的状态恢复到初始状态。
3.  env.state：查看环境当前状态。
4.  env.step()：单步执行/智能体与环境之间的一次交互，即智能体在当前状态s下执行一次动作a，环境相应地更新至状态s'，并向智能体反馈及时奖励r。
5.  env.render()：环境显示。以图形化的方式显示环境当前状态，在智能体与环境的持续交互过程中，该图形化显示也是相应地持续更新的。
6. env.close()：关闭环境。
7. env.sample_space.sample(): 对动作空间进行随机采样。
8. env.seed()：指定随机种子。

&nbsp;

&nbsp;

&nbsp;

## 2. stable-baselines3
