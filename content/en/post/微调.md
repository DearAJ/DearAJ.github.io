---
date: 2025-03-20T11:00:59-04:00
description: ""
featured_image: "/images/fine-tuning/lucky.jpg"
tags: ["LLM", "RL"]
title: "微调"
---

## 大模型预训练

#### 1 从零开始的预训练

#### 2 在已有开源模型基础上针对特定任务进行训练

&nbsp;

### LoRa

通过化简权重矩阵，实现高效微调

![1](/Users/aijunyang/DearAJ.github.io/static/images/preTrain/1.png)

将loraA与loraB相乘得到一个lora权重矩阵，将lora权重矩阵加在原始权重矩阵上，就得到了对原始网络的更新。

训练参数量减少，但微调效果基本不变。

+ 两个重要参数：

  ![2](/Users/aijunyang/DearAJ.github.io/static/images/preTrain/2.png)

Lora 的**优点**：

1. ﻿﻿﻿大大节省微调大模型的参数量
2. ﻿﻿﻿效果和全量微调差不多。
3. ﻿﻿微调完的Lora模型，权重可以Merge回原来的权重，不会改变模型结构，推理时不增加额外计算量。
4. ﻿﻿你可以通过改变r参数，最高情况等同于全量微调。

&nbsp;

&nbsp;

## 大模型微调：SFT Trainer

 SFT：Supervised Fine-Tuning

#### 1 Chat Tempate

在预训练基础上，更好回答人类的问题。

+ 网络结构：基本相同
+ loss函数：基本相同
+ 训练数据：不同

微调时，格式需要与原厂一致效果更好。

输入整个对话，对整个对话文本进行学习，**对每个输出token计算loss**。

&nbsp;

#### 2 Completions only

输入整个对话，对整个对话文本进行学习，**只对回答部分进行loss计算**。

用一个loss mask来实现，query部分不需要计算loss。

&nbsp;

#### 3 NEFTune：Noisy Embeddings Finetuning

图像领域的数据增强：通过旋转等操作生成更多样本。

对文本数据的增强：给每个token的embeding随机加上一些噪声，让原有token变成其他相近的token。如，*漂亮*变成了*美丽*。

&nbsp;

&nbsp;

