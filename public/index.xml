<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AJ&#39;s blog on HomePage</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in AJ&#39;s blog on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 15 Jan 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM</title>
      <link>http://localhost:1313/post/llm/</link>
      <pubDate>Wed, 15 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/llm/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;分类&#34;&gt;分类&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;大语言模型（LLM）&lt;/p&gt;&#xA;&lt;p&gt;这类大模型专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。它们通常基于深度学习架构（如Transformer模型），经过大规模文本数据集训练而成，能够捕捉语言的复杂性，包括语法、语义、语境以及蕴含的文化和社会知识。语言大模型典型应用包括文本生成、问答系统、文本分类、机器翻译、对话系统等。示例包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPT系列（OpenAI）：如GPT-3、GPT-3.5、GPT-4等。&lt;/li&gt;&#xA;&lt;li&gt;Bard（Google）：谷歌推出的大型语言模型，用于提供信息丰富的、有创意的文本输出。&lt;/li&gt;&#xA;&lt;li&gt;通义千问（阿里云）：阿里云自主研发的超大规模的语言模型。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多模态模型&lt;/p&gt;&#xA;&lt;p&gt;多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，并在这些模态之间建立关联和交互。它们能够整合不同类型的输入信息，进行跨模态推理、生成和理解任务。多模态大模型的应用涵盖视觉问答、图像描述生成、跨模态检索.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Decision Tree</title>
      <link>http://localhost:1313/post/decision-tree/</link>
      <pubDate>Sat, 11 Jan 2025 10:58:08 -0400</pubDate>
      <guid>http://localhost:1313/post/decision-tree/</guid>
      <description>&lt;p&gt;类型：root node, decision node, leaf node&lt;/p&gt;&#xA;&lt;h3 id=&#34;要解决的问题&#34;&gt;要解决的问题&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;How to choose what feature to split on at each node?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Maximize purity (or minimize impurity)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;When do you stop splitting?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When a node is 100% one class&lt;/li&gt;&#xA;&lt;li&gt;When splitting a node will result in the tree exceeding a maximum depth&lt;/li&gt;&#xA;&lt;li&gt;When improvements in purity score are below a threshold&lt;/li&gt;&#xA;&lt;li&gt;When number of examples in a node is below a threshold&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/chapter1/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;熵和信息增益&#34;&gt;熵和信息增益&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Measuring purity&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reinforcement Learning</title>
      <link>http://localhost:1313/post/rl/</link>
      <pubDate>Thu, 02 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/rl/</guid>
      <description>&lt;p&gt;The core idea is &lt;strong&gt;trial-and-error learning&lt;/strong&gt;: the agent takes actions, observes the outcomes, and receives &lt;strong&gt;rewards&lt;/strong&gt; or &lt;strong&gt;penalties&lt;/strong&gt; as feedback. Over time, the agent improves its &lt;strong&gt;policy&lt;/strong&gt; (decision-making strategy) to maximize cumulative rewards.&lt;/p&gt;&#xA;&lt;p&gt;不用告诉该怎么做，而是给定奖励函数，什么时候做好。&lt;/p&gt;&#xA;&lt;h3 id=&#34;回归&#34;&gt;回归&lt;/h3&gt;&#xA;&lt;p&gt;增加折现因子&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RL/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RL/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;强化学习的形式化&#34;&gt;强化学习的形式化&lt;/h3&gt;&#xA;&lt;p&gt;A policy is a function $\pi(s) = a$ mapping from states to actions, that tells you what $action \space a$ to take in a given $state \space s$.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;goal&lt;/strong&gt;: Find a $policy \space \pi$ that tells you what $action (a = (s))$ to take in every $state (s)$ so as to maximize the return.&lt;/p&gt;</description>
    </item>
    <item>
      <title>VAE</title>
      <link>http://localhost:1313/post/vae/</link>
      <pubDate>Sun, 29 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/vae/</guid>
      <description>&lt;h3 id=&#34;key-concepts-of-vaes&#34;&gt;Key Concepts of VAEs&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Latent Variables&lt;/strong&gt;: VAEs assume that the observed data (e.g., images) is generated from a set of unobserved, lower-dimensional latent variables.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Probabilistic Framework&lt;/strong&gt;: VAEs are based on &lt;strong&gt;variational inference&lt;/strong&gt;, a method for approximating complex probability distributions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder-Decoder Architecture&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: Maps input data x&lt;em&gt;x&lt;/em&gt; to a distribution over latent variables z&lt;em&gt;z&lt;/em&gt;. This is often parameterized as a Gaussian distribution with mean μ&lt;em&gt;μ&lt;/em&gt; and variance σ2&lt;em&gt;σ&lt;/em&gt;2.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: Maps latent variables z&lt;em&gt;z&lt;/em&gt; back to the data space, generating new samples x′&lt;em&gt;x&lt;/em&gt;′ that resemble the original data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;普通自动编码器&#34;&gt;普通自动编码器&lt;/h2&gt;&#xA;&lt;p&gt;目标：将高维度数据压缩成较小的表示&lt;/p&gt;</description>
    </item>
    <item>
      <title>CV</title>
      <link>http://localhost:1313/post/cv/</link>
      <pubDate>Fri, 27 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/cv/</guid>
      <description>&lt;p&gt;问题: 处理高分辨率图像时，原始图像的像素数量通常非常庞大。&lt;/p&gt;&#xA;&lt;p&gt;类型：root node, decision node, leaf node&#xA; &lt;/p&gt;&#xA;&lt;h2 id=&#34;1-解决方案cnn&#34;&gt;1. 解决方案：CNN&lt;/h2&gt;&#xA;&lt;p&gt;卷积神经网络通过引入卷积操作，有效地解决了大图片参数过大的问题。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Automatic Feature Extraction&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;CNNs automatically learn hierarchical features from raw data (like images) without needing manual feature engineering.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Parameter Sharing&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a CNN, the same filter (or kernel) is applied across the entire image. This concept of &lt;strong&gt;weight sharing&lt;/strong&gt; significantly reduces the number of parameters compared to fully connected networks, making CNNs more computationally efficient.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;分层特征学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translation Invariance&lt;/strong&gt;（pooling layers）&lt;/p&gt;</description>
    </item>
    <item>
      <title>End2End</title>
      <link>http://localhost:1313/post/e2e/</link>
      <pubDate>Thu, 26 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/e2e/</guid>
      <description>&lt;p&gt;对于由多个阶段组成的学习系统，端到端学习捕获所有阶段，将其替代为单个神经网络。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;优点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Let the data speak&lt;/li&gt;&#xA;&lt;li&gt;Less hand-designing of components needed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;缺点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;May need large amount of data&lt;/li&gt;&#xA;&lt;li&gt;Excludes potentially useful hand-designed components&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;关键&lt;/strong&gt;：是否有足够的数据&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/e2e/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>transformer</title>
      <link>http://localhost:1313/post/transformer/</link>
      <pubDate>Wed, 25 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/transformer/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;Transformer&lt;/strong&gt; is a deep learning architecture introduced in the 2017 paper &lt;em&gt;&amp;ldquo;Attention is All You Need&amp;rdquo;&lt;/em&gt; by Vaswani et al. It revolutionized natural language processing (NLP) and has since become the foundation for many state-of-the-art models, such as BERT, GPT, and T5.&lt;/p&gt;&#xA;&lt;h3 id=&#34;seq2seq&#34;&gt;Seq2seq&lt;/h3&gt;&#xA;&lt;p&gt;Input a sequence, output a sequence The output length is determined by model.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e22b161f-7704-4d51-8881-70ee7e4c6dcb/%E6%88%AA%E5%B1%8F2024-12-31_15.12.59.png&#34; alt=&#34;截屏2024-12-31 15.12.59.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/180291f8-9817-42b6-87cb-39bf0734b9ef/%E6%88%AA%E5%B1%8F2024-12-31_19.34.56.png&#34; alt=&#34;截屏2024-12-31 19.34.56.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/31c00a57-de1e-43a9-b92a-13e3a050be48/%E6%88%AA%E5%B1%8F2024-12-31_19.35.51.png&#34; alt=&#34;截屏2024-12-31 19.35.51.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;encoder&#34;&gt;Encoder&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/901263ca-4e06-4f07-a672-aab03a6a86d4/cb6d7470-a2be-4ea5-9611-1cf0859d782f.png&#34; alt=&#34;截屏2024-12-31 15.15.42.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/3f6e614d-e0be-49d2-935e-642ebc3eaa82/%E6%88%AA%E5%B1%8F2024-12-31_15.29.37.png&#34; alt=&#34;截屏2024-12-31 15.29.37.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;细节&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/641849c0-19ea-464e-9b96-2e7b93b1d3d5/c8331594-f0cc-4348-967f-b026b8e2b68f.png&#34; alt=&#34;截屏2024-12-31 15.18.01.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>About ME</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;我的本科毕业于北京航空航天大学计算机科学与技术专业，目前，我正在香港大学攻读计算机科学硕士学位。&lt;/p&gt;&#xA;&lt;p&gt;我的生日是11月23号（是的，我的幸运数字是23），我是射手座，enfj。我喜欢和朋友一起探店美食，喜欢弹钢琴。我最喜欢的歌手是泰勒斯威夫特。&lt;/p&gt;&#xA;&lt;p&gt;最近，我刚刚开始学习吉他。欢迎和我成为朋友！&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/images/tayme.HEIC&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;—from AJ23&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description>&lt;p&gt;感谢你访问我的博客！如果你有任何问题或建议，欢迎与我取得联系：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href=&#34;mailto:aijunyang1123@163.com&#34;&gt;aijunyang1123@163.com&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;WeChat&lt;/strong&gt;: DearAJ_23&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/contact/wechat.jpg?width=10&amp;amp;height=10&#34; alt=&#34;wc&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
