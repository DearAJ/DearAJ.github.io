<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AJ&#39;s blog on HomePage</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in AJ&#39;s blog on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 17 Jan 2025 10:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Diffusion Model</title>
      <link>http://localhost:1313/post/diffusion-model/</link>
      <pubDate>Fri, 17 Jan 2025 10:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/diffusion-model/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;影像生成模型本质上的共同目标&#34;&gt;影像生成模型本质上的共同目标&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/19.png&#34; alt=&#34;19&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;进一步：输入加入了文字表述&lt;/p&gt;&#xA;&lt;p&gt;目标：产生的图片与真实图片越接近越好&lt;/p&gt;&#xA;&lt;h3 id=&#34;advantages&#34;&gt;Advantages:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;High-Quality Outputs:&lt;/strong&gt; Diffusion models are known for producing high-quality, realistic samples.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; They can be applied to various types of data, including images, audio, and even text.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Theoretical Foundation:&lt;/strong&gt; The process is grounded in well-understood principles of probability and statistics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Challenges&lt;/strong&gt;: Computational Cost、Training Complexity.&lt;/p&gt;&#xA;&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reverse Process&lt;/strong&gt;（多次Denoise）&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;reconstructing meaningful data from noise&lt;/strong&gt; by iteratively removing noise that was added during the &lt;strong&gt;forward process&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Forward Process&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM</title>
      <link>http://localhost:1313/post/llm/</link>
      <pubDate>Wed, 15 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/llm/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;分类&#34;&gt;分类&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;大语言模型（LLM）&lt;/p&gt;&#xA;&lt;p&gt;这类大模型专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多模态模型&lt;/p&gt;&#xA;&lt;p&gt;多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，并在这些模态之间建立关联和交互。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Decision Tree</title>
      <link>http://localhost:1313/post/decision-tree/</link>
      <pubDate>Sat, 11 Jan 2025 10:58:08 -0400</pubDate>
      <guid>http://localhost:1313/post/decision-tree/</guid>
      <description>&lt;p&gt;类型：root node, decision node, leaf node&lt;/p&gt;&#xA;&lt;h3 id=&#34;要解决的问题&#34;&gt;要解决的问题&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;How to choose what feature to split on at each node?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Maximize purity (or minimize impurity)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;When do you stop splitting?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When a node is 100% one class&lt;/li&gt;&#xA;&lt;li&gt;When splitting a node will result in the tree exceeding a maximum depth&lt;/li&gt;&#xA;&lt;li&gt;When improvements in purity score are below a threshold&lt;/li&gt;&#xA;&lt;li&gt;When number of examples in a node is below a threshold&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/chapter1/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;熵和信息增益&#34;&gt;熵和信息增益&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Measuring purity&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generative AI</title>
      <link>http://localhost:1313/post/ga/</link>
      <pubDate>Sat, 04 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/ga/</guid>
      <description>&lt;h1 id=&#34;chatgpt&#34;&gt;ChatGPT&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/ba53c8d8-3a8d-4bb9-a20f-5cd7d295a29f/%E6%88%AA%E5%B1%8F2025-01-05_23.37.32.png&#34; alt=&#34;截屏2025-01-05 23.37.32.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/740b097c-4c79-42af-bc9b-5817abdc3521/%E6%88%AA%E5%B1%8F2025-01-04_00.25.09.png&#34; alt=&#34;截屏2025-01-04 00.25.09.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ChatGPT 真正做的事：文字接龙&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Autoregressive Generation&lt;/strong&gt;：逐个生成&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/a140588c-153b-4bf3-812b-794d09b256c2/%E6%88%AA%E5%B1%8F2025-01-04_00.18.34.png&#34; alt=&#34;截屏2025-01-04 00.18.34.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/10249f01-191e-4450-9387-201ee36c281d/247f57f5-a4f8-4859-8ce8-9664487924cd.png&#34; alt=&#34;截屏2025-01-04 00.27.44.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;token&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;文字接龙时可以选择的符号&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e0bc078c-68ba-4504-b3dc-2bee0739d6fa/%E6%88%AA%E5%B1%8F2025-01-04_00.29.01.png&#34; alt=&#34;截屏2025-01-04 00.29.01.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;每次回答都随机（掷骰子）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b30b483b-47dd-4cfd-9a2d-bcd030b1b169/%E6%88%AA%E5%B1%8F2025-01-04_11.07.26.png&#34; alt=&#34;截屏2025-01-04 11.07.26.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;进化关键：&lt;strong&gt;自督导式学习(预训练) ➡️ 督导式学习(微调) ➡️ 强化学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b2ca8f91-7703-4339-ae03-089a67c3519f/%E6%88%AA%E5%B1%8F2025-01-04_23.52.07.png&#34; alt=&#34;截屏2025-01-04 23.52.07.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有预训练，督导式学习不用大量资料。&lt;/p&gt;&#xA;&lt;p&gt;强化学习提供回馈。督导式学习提供完整资料，强化学习给反馈（如两次答案，有没有比上次更好）&lt;/p&gt;&#xA;&lt;p&gt;【注】：模型要有一定程度的能力才适合进入强化学习。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Alignment(对齐)&lt;/strong&gt;：督导式学习 + 强化学习&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;学习reward model&lt;/p&gt;&#xA;&lt;p&gt;reward model：模仿人类的偏好&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用reward model进行学习&lt;/p&gt;&#xA;&lt;p&gt;模型只需要向reward model学习&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;GPT-4: 可以看图+引导&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;如何激发gpt的能力？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;把需求说清楚&lt;/li&gt;&#xA;&lt;li&gt;提供咨询&lt;/li&gt;&#xA;&lt;li&gt;提供范例&lt;/li&gt;&#xA;&lt;li&gt;鼓励gpt想一想&lt;/li&gt;&#xA;&lt;li&gt;训练generator&lt;/li&gt;&#xA;&lt;li&gt;上传资料&lt;/li&gt;&#xA;&lt;li&gt;使用其它工具&lt;/li&gt;&#xA;&lt;li&gt;大任务拆解成小任务&lt;/li&gt;&#xA;&lt;li&gt;gpt会反省&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;可以做什么？&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;prompt engineering&lt;/li&gt;&#xA;&lt;li&gt;训练自己的模型（如调整LLaMA参数），困难&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;大型语言模型训练过程&#34;&gt;大型语言模型训练过程&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/7e6521a3-d2cf-42bc-8550-aacc3027b83f/%E6%88%AA%E5%B1%8F2025-01-06_00.37.19.png&#34; alt=&#34;截屏2025-01-06 00.37.19.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;自我学习阶段&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;调整超参数&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;训练成果，但测试失败：找到多样数据&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;找到合适的初始参数：随机/ 先验知识&lt;/p&gt;&#xA;&lt;p&gt;先验知识：爬网络资料+资料清理(训练资料品质分类器/除重)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;人类指导阶段&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Reinforcement Learning</title>
      <link>http://localhost:1313/post/rl/</link>
      <pubDate>Thu, 02 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/rl/</guid>
      <description>&lt;p&gt;The core idea is &lt;strong&gt;trial-and-error learning&lt;/strong&gt;: the agent takes actions, observes the outcomes, and receives &lt;strong&gt;rewards&lt;/strong&gt; or &lt;strong&gt;penalties&lt;/strong&gt; as feedback. Over time, the agent improves its &lt;strong&gt;policy&lt;/strong&gt; (decision-making strategy) to maximize cumulative rewards.&lt;/p&gt;&#xA;&lt;p&gt;不用告诉该怎么做，而是给定奖励函数，什么时候做好。&lt;/p&gt;&#xA;&lt;h3 id=&#34;回归&#34;&gt;回归&lt;/h3&gt;&#xA;&lt;p&gt;增加折现因子&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RL/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RL/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;强化学习的形式化&#34;&gt;强化学习的形式化&lt;/h3&gt;&#xA;&lt;p&gt;A policy is a function $\pi(s) = a$ mapping from states to actions, that tells you what $action \space a$ to take in a given $state \space s$.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;goal&lt;/strong&gt;: Find a $policy \space \pi$ that tells you what $action (a = (s))$ to take in every $state (s)$ so as to maximize the return.&lt;/p&gt;</description>
    </item>
    <item>
      <title>VAE</title>
      <link>http://localhost:1313/post/vae/</link>
      <pubDate>Sun, 29 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/vae/</guid>
      <description>&lt;h3 id=&#34;key-concepts-of-vaes&#34;&gt;Key Concepts of VAEs&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Latent Variables&lt;/strong&gt;: VAEs assume that the observed data (e.g., images) is generated from a set of unobserved, lower-dimensional latent variables.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Probabilistic Framework&lt;/strong&gt;: VAEs are based on &lt;strong&gt;variational inference&lt;/strong&gt;, a method for approximating complex probability distributions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder-Decoder Architecture&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: Maps input data x&lt;em&gt;x&lt;/em&gt; to a distribution over latent variables z&lt;em&gt;z&lt;/em&gt;. This is often parameterized as a Gaussian distribution with mean μ&lt;em&gt;μ&lt;/em&gt; and variance σ2&lt;em&gt;σ&lt;/em&gt;2.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: Maps latent variables z&lt;em&gt;z&lt;/em&gt; back to the data space, generating new samples x′&lt;em&gt;x&lt;/em&gt;′ that resemble the original data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;普通自动编码器&#34;&gt;普通自动编码器&lt;/h2&gt;&#xA;&lt;p&gt;目标：将高维度数据压缩成较小的表示&lt;/p&gt;</description>
    </item>
    <item>
      <title>CV</title>
      <link>http://localhost:1313/post/cv/</link>
      <pubDate>Fri, 27 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/cv/</guid>
      <description>&lt;p&gt;问题: 处理高分辨率图像时，原始图像的像素数量通常非常庞大。&lt;/p&gt;&#xA;&lt;p&gt;类型：root node, decision node, leaf node&#xA; &lt;/p&gt;&#xA;&lt;h2 id=&#34;1-解决方案cnn&#34;&gt;1. 解决方案：CNN&lt;/h2&gt;&#xA;&lt;p&gt;卷积神经网络通过引入卷积操作，有效地解决了大图片参数过大的问题。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Automatic Feature Extraction&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;CNNs automatically learn hierarchical features from raw data (like images) without needing manual feature engineering.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Parameter Sharing&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a CNN, the same filter (or kernel) is applied across the entire image. This concept of &lt;strong&gt;weight sharing&lt;/strong&gt; significantly reduces the number of parameters compared to fully connected networks, making CNNs more computationally efficient.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;分层特征学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translation Invariance&lt;/strong&gt;（pooling layers）&lt;/p&gt;</description>
    </item>
    <item>
      <title>End2End</title>
      <link>http://localhost:1313/post/e2e/</link>
      <pubDate>Thu, 26 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/e2e/</guid>
      <description>&lt;p&gt;对于由多个阶段组成的学习系统，端到端学习捕获所有阶段，将其替代为单个神经网络。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;优点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Let the data speak&lt;/li&gt;&#xA;&lt;li&gt;Less hand-designing of components needed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;缺点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;May need large amount of data&lt;/li&gt;&#xA;&lt;li&gt;Excludes potentially useful hand-designed components&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;关键&lt;/strong&gt;：是否有足够的数据&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/e2e/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>transformer</title>
      <link>http://localhost:1313/post/transformer/</link>
      <pubDate>Wed, 25 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/transformer/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;Transformer&lt;/strong&gt; is a deep learning architecture introduced in the 2017 paper &lt;em&gt;&amp;ldquo;Attention is All You Need&amp;rdquo;&lt;/em&gt; by Vaswani et al. It revolutionized natural language processing (NLP) and has since become the foundation for many state-of-the-art models, such as BERT, GPT, and T5.&lt;/p&gt;&#xA;&lt;h3 id=&#34;seq2seq&#34;&gt;Seq2seq&lt;/h3&gt;&#xA;&lt;p&gt;Input a sequence, output a sequence The output length is determined by model.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e22b161f-7704-4d51-8881-70ee7e4c6dcb/%E6%88%AA%E5%B1%8F2024-12-31_15.12.59.png&#34; alt=&#34;截屏2024-12-31 15.12.59.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/180291f8-9817-42b6-87cb-39bf0734b9ef/%E6%88%AA%E5%B1%8F2024-12-31_19.34.56.png&#34; alt=&#34;截屏2024-12-31 19.34.56.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/31c00a57-de1e-43a9-b92a-13e3a050be48/%E6%88%AA%E5%B1%8F2024-12-31_19.35.51.png&#34; alt=&#34;截屏2024-12-31 19.35.51.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;encoder&#34;&gt;Encoder&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/901263ca-4e06-4f07-a672-aab03a6a86d4/cb6d7470-a2be-4ea5-9611-1cf0859d782f.png&#34; alt=&#34;截屏2024-12-31 15.15.42.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/3f6e614d-e0be-49d2-935e-642ebc3eaa82/%E6%88%AA%E5%B1%8F2024-12-31_15.29.37.png&#34; alt=&#34;截屏2024-12-31 15.29.37.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;细节&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/641849c0-19ea-464e-9b96-2e7b93b1d3d5/c8331594-f0cc-4348-967f-b026b8e2b68f.png&#34; alt=&#34;截屏2024-12-31 15.18.01.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>About ME</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;我的本科毕业于北京航空航天大学计算机科学与技术专业，目前，我正在香港大学攻读计算机科学硕士学位。&lt;/p&gt;&#xA;&lt;p&gt;我的生日是11月23号（是的，我的幸运数字是23），我是射手座，enfj。我喜欢和朋友一起探店美食，喜欢弹钢琴。我最喜欢的歌手是泰勒斯威夫特。&lt;/p&gt;&#xA;&lt;p&gt;最近，我刚刚开始学习吉他。欢迎和我成为朋友！&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/images/tayme.HEIC&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;—from AJ23&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description>&lt;p&gt;感谢你访问我的博客！如果你有任何问题或建议，欢迎与我取得联系：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href=&#34;mailto:aijunyang1123@163.com&#34;&gt;aijunyang1123@163.com&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;WeChat&lt;/strong&gt;: DearAJ_23&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/contact/wechat.jpg?width=10&amp;amp;height=10&#34; alt=&#34;wc&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
