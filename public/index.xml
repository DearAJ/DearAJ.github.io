<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AJ&#39;s blog on HomePage</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in AJ&#39;s blog on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 22 Jan 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>「持续更新」算法题笔记</title>
      <link>http://localhost:1313/post/algrithom/</link>
      <pubDate>Wed, 22 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/algrithom/</guid>
      <description></description>
    </item>
    <item>
      <title>World Models</title>
      <link>http://localhost:1313/post/world-model/</link>
      <pubDate>Wed, 22 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/world-model/</guid>
      <description></description>
    </item>
    <item>
      <title>LLM</title>
      <link>http://localhost:1313/post/llm/</link>
      <pubDate>Mon, 20 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/llm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&amp;amp;vd_source=80aea28698fb0235b45699fc7e6fcdac&amp;amp;p=2&#34;&gt;https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&amp;vd_source=80aea28698fb0235b45699fc7e6fcdac&amp;p=2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;大模型的演变&#34;&gt;大模型的演变&lt;/h2&gt;&#xA;&lt;p&gt;大模型的训练整体上分为三个阶段：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个阶段它会学习各种不同种类的语料，学习到语言的统计规律和一般知识。&lt;/p&gt;&#xA;&lt;p&gt;但是大模型在这个阶段只是学会了补全句子，却没有学会怎么样去领会人类的意图（类似成语接龙）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;SFT（监督微调）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个阶段大模型可以学习各种人类的对话语料，甚至是非常专业的垂直领域知识。&lt;/p&gt;&#xA;&lt;p&gt;但是模型的回答有时候可能并不符合人类的偏好，它可能会输出一些涉黄、涉政、涉暴或者种族歧视等言论。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;RLHF（基于人类反馈的强化学习）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个阶段大模型会针对同一问题进行多次回答，人类会对这些回答打分。&lt;/p&gt;&#xA;&lt;p&gt;大模型会在此阶段学习到如何输出分数最高的回答，使得回答更符合人类的偏好。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;分类&#34;&gt;分类&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;大语言模型（LLM）&lt;/p&gt;&#xA;&lt;p&gt;专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多模态模型&lt;/p&gt;&#xA;&lt;p&gt;多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，在这些模态之间建立关联和交互。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;工作流程&#34;&gt;工作流程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;分词化与词表映射&#34;&gt;分词化与词表映射&lt;/h3&gt;&#xA;&lt;p&gt;**分词化（Tokenization）**是指将段落和句子分割成更小的分词（token）的过程。&lt;/p&gt;&#xA;&lt;p&gt;分词化有不同的粒度分类：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;﻿词粒度（Word-Level Tokenization）分词化：适用于大多数西方语言，如英语。&lt;/li&gt;&#xA;&lt;li&gt;﻿字符粒度（Character-Level）分词化：中文最直接的分词方法，它是以单个汉字为单位进行分词化。&lt;/li&gt;&#xA;&lt;li&gt;﻿子词粒度（Subword-Level）分词化：将单词分解成更小的单位，比如词根、词缀等。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;每一个token都会通过预先设置好的词表，映射为一个 token id，这是token 的“身份证”，一句话最终会被表示为一个元素为token id的列表，供计算机进行下一步处理。&lt;/p&gt;&#xA;&lt;h3 id=&#34;文本生成过程&#34;&gt;文本生成过程&lt;/h3&gt;&#xA;&lt;p&gt;大语言模型根据给定的文本&lt;strong&gt;预测下一个token&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;大模型进行推理时，基于现有的token，根据概率最大原则预测出下一个最有可能的token，然后将该预测的token加入到输入序列中，并将更新后的输入序列继续输入大模型预测下一个token，这个过程叫做&lt;strong&gt;自回归&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;直到输出特殊token（如&lt;!-- raw HTML omitted --&gt;，end of sentence，专门用来控制推理何时结束）或输出长度达到阈值。&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-agent&#34;&gt;AI Agent&lt;/h1&gt;&#xA;&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;&#xA;&lt;h3 id=&#34;agent认知与原理分析&#34;&gt;agent认知与原理分析&lt;/h3&gt;&#xA;&lt;p&gt;Al Agents是基于LLM的能够自主理解、自主规划笨策、执行复杂任务的習能体。&lt;/p&gt;&#xA;&lt;p&gt;Agent的设计目的是为了处理那些简单的语言模型可能无法直接解决的问题，尤其是当这些任务涉及到多个步骤或者需要外部数据源的情况。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;﻿LLM：接受输入、思考、输出&lt;/li&gt;&#xA;&lt;li&gt;﻿人类：LLM（接受输入、思考、输出）+记忆＋工具+规划&amp;mdash;&amp;mdash;&amp;gt;Agents&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;agent技术框架&#34;&gt;agent技术框架&lt;/h3&gt;&#xA;&lt;h3 id=&#34;agent策略分析与parer解读&#34;&gt;agent策略分析与Parer解读&lt;/h3&gt;&#xA;&lt;h3 id=&#34;单agent系统与多agent系统&#34;&gt;单Agent系统与多Agent系统&lt;/h3&gt;&#xA;&lt;h3 id=&#34;个性化agent应用定制全流程详讲&#34;&gt;个性化Agent应用定制全流程详讲&lt;/h3&gt;&#xA;&lt;h2 id=&#34;实践&#34;&gt;实践&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Quantization</title>
      <link>http://localhost:1313/post/quantization/</link>
      <pubDate>Mon, 20 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/quantization/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;量化&lt;/strong&gt;：Store the parameters of the model in lower precision&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Knowledge distillation&lt;/strong&gt;: Train a smaller model (student) using the original model (instructor).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pruning&lt;/strong&gt;: Remove connections (weights) from the model&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Application&lt;/strong&gt;: Perform linear quantization on any model using Quanto in two lines&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;内容&#34;&gt;内容&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Linear Quantization theory&lt;/strong&gt; in detail and how to code it (&lt;em&gt;per channel, per tensor, per group quantization&lt;/em&gt;)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Build your own 8-bit linear quantizer and apply it on real models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion Model</title>
      <link>http://localhost:1313/post/diffusion-model/</link>
      <pubDate>Fri, 17 Jan 2025 10:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/diffusion-model/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;影像生成模型本质上的共同目标&#34;&gt;影像生成模型本质上的共同目标&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/19.png&#34; alt=&#34;19&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;进一步：输入加入了文字表述&lt;/p&gt;&#xA;&lt;p&gt;目标：产生的图片与真实图片越接近越好&lt;/p&gt;&#xA;&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reverse Process&lt;/strong&gt;（多次Denoise）&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;reconstructing meaningful data from noise&lt;/strong&gt; by iteratively removing noise that was added during the &lt;strong&gt;forward process&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Forward Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;p&gt;Gradually adds noise to data over multiple steps until the data becomes pure noise.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Denoise输入：图片 + 噪音程度&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;denoise-model内部&#34;&gt;Denoise Model内部&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/3.png&#34; alt=&#34;3&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Noise Predicter&lt;/strong&gt;: 预测noise长什么样&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何训练Noise Predicter？&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;人为创造（加杂讯/Forward Process）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/4.png&#34; alt=&#34;4&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;text-to-image&#34;&gt;&lt;strong&gt;Text-to-Image&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Laion拥有5.85B图片，可进行搜索&lt;/p&gt;&#xA;&lt;p&gt;输入：图片+噪声程度+&lt;strong&gt;文字叙述&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/5.png&#34; alt=&#34;5&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;算法&#34;&gt;算法&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/6.png&#34; alt=&#34;6&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;训练&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DM/17.png&#34; alt=&#34;17&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;sample一张clean image&lt;/li&gt;&#xA;&lt;li&gt;sample出一个数字&lt;/li&gt;&#xA;&lt;li&gt;sample出一个noise&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;clean image 和 noise 做加权和得到一个有杂讯的图&lt;/strong&gt;，然后训练noise predictor（输入有杂讯的图 和 数字；输出目标noise）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;产生图&lt;/strong&gt;：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decision Tree</title>
      <link>http://localhost:1313/post/decision-tree/</link>
      <pubDate>Sat, 11 Jan 2025 10:58:08 -0400</pubDate>
      <guid>http://localhost:1313/post/decision-tree/</guid>
      <description>&lt;p&gt;类型：root node, decision node, leaf node&lt;/p&gt;&#xA;&lt;h3 id=&#34;要解决的问题&#34;&gt;要解决的问题&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;How to choose what feature to split on at each node?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Maximize purity (or minimize impurity)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;When do you stop splitting?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When a node is 100% one class&lt;/li&gt;&#xA;&lt;li&gt;When splitting a node will result in the tree exceeding a maximum depth&lt;/li&gt;&#xA;&lt;li&gt;When improvements in purity score are below a threshold&lt;/li&gt;&#xA;&lt;li&gt;When number of examples in a node is below a threshold&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/chapter1/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;熵和信息增益&#34;&gt;熵和信息增益&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Measuring purity&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generative AI</title>
      <link>http://localhost:1313/post/ga/</link>
      <pubDate>Sat, 04 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/ga/</guid>
      <description>&lt;h1 id=&#34;chatgpt&#34;&gt;ChatGPT&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/ba53c8d8-3a8d-4bb9-a20f-5cd7d295a29f/%E6%88%AA%E5%B1%8F2025-01-05_23.37.32.png&#34; alt=&#34;截屏2025-01-05 23.37.32.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/740b097c-4c79-42af-bc9b-5817abdc3521/%E6%88%AA%E5%B1%8F2025-01-04_00.25.09.png&#34; alt=&#34;截屏2025-01-04 00.25.09.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ChatGPT 真正做的事：文字接龙&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Autoregressive Generation&lt;/strong&gt;：逐个生成&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/a140588c-153b-4bf3-812b-794d09b256c2/%E6%88%AA%E5%B1%8F2025-01-04_00.18.34.png&#34; alt=&#34;截屏2025-01-04 00.18.34.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/10249f01-191e-4450-9387-201ee36c281d/247f57f5-a4f8-4859-8ce8-9664487924cd.png&#34; alt=&#34;截屏2025-01-04 00.27.44.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;token&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;文字接龙时可以选择的符号&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e0bc078c-68ba-4504-b3dc-2bee0739d6fa/%E6%88%AA%E5%B1%8F2025-01-04_00.29.01.png&#34; alt=&#34;截屏2025-01-04 00.29.01.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;每次回答都随机（掷骰子）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b30b483b-47dd-4cfd-9a2d-bcd030b1b169/%E6%88%AA%E5%B1%8F2025-01-04_11.07.26.png&#34; alt=&#34;截屏2025-01-04 11.07.26.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;进化关键：&lt;strong&gt;自督导式学习(预训练) ➡️ 督导式学习(微调) ➡️ 强化学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b2ca8f91-7703-4339-ae03-089a67c3519f/%E6%88%AA%E5%B1%8F2025-01-04_23.52.07.png&#34; alt=&#34;截屏2025-01-04 23.52.07.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有预训练，督导式学习不用大量资料。&lt;/p&gt;&#xA;&lt;p&gt;强化学习提供回馈。督导式学习提供完整资料，强化学习给反馈（如两次答案，有没有比上次更好）&lt;/p&gt;&#xA;&lt;p&gt;【注】：模型要有一定程度的能力才适合进入强化学习。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Alignment(对齐)&lt;/strong&gt;：督导式学习 + 强化学习&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;学习reward model&lt;/p&gt;&#xA;&lt;p&gt;reward model：模仿人类的偏好&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用reward model进行学习&lt;/p&gt;&#xA;&lt;p&gt;模型只需要向reward model学习&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;GPT-4: 可以看图+引导&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;如何激发gpt的能力？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;把需求说清楚&lt;/li&gt;&#xA;&lt;li&gt;提供咨询&lt;/li&gt;&#xA;&lt;li&gt;提供范例&lt;/li&gt;&#xA;&lt;li&gt;鼓励gpt想一想&lt;/li&gt;&#xA;&lt;li&gt;训练generator&lt;/li&gt;&#xA;&lt;li&gt;上传资料&lt;/li&gt;&#xA;&lt;li&gt;使用其它工具&lt;/li&gt;&#xA;&lt;li&gt;大任务拆解成小任务&lt;/li&gt;&#xA;&lt;li&gt;gpt会反省&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;可以做什么？&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;prompt engineering&lt;/li&gt;&#xA;&lt;li&gt;训练自己的模型（如调整LLaMA参数），困难&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;大型语言模型训练过程&#34;&gt;大型语言模型训练过程&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/7e6521a3-d2cf-42bc-8550-aacc3027b83f/%E6%88%AA%E5%B1%8F2025-01-06_00.37.19.png&#34; alt=&#34;截屏2025-01-06 00.37.19.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;自我学习阶段&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;调整超参数&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;训练成果，但测试失败：找到多样数据&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;找到合适的初始参数：随机/ 先验知识&lt;/p&gt;&#xA;&lt;p&gt;先验知识：爬网络资料+资料清理(训练资料品质分类器/除重)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;人类指导阶段&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Reinforcement Learning</title>
      <link>http://localhost:1313/post/rl/</link>
      <pubDate>Thu, 02 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/rl/</guid>
      <description>&lt;p&gt;The core idea is &lt;strong&gt;trial-and-error learning&lt;/strong&gt;: the agent takes actions, observes the outcomes, and receives &lt;strong&gt;rewards&lt;/strong&gt; or &lt;strong&gt;penalties&lt;/strong&gt; as feedback. Over time, the agent improves its &lt;strong&gt;policy&lt;/strong&gt; (decision-making strategy) to maximize cumulative rewards.&lt;/p&gt;&#xA;&lt;p&gt;不用告诉该怎么做，而是给定奖励函数，什么时候做好。&lt;/p&gt;&#xA;&lt;h3 id=&#34;回归&#34;&gt;回归&lt;/h3&gt;&#xA;&lt;p&gt;增加折现因子&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RL/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RL/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;强化学习的形式化&#34;&gt;强化学习的形式化&lt;/h3&gt;&#xA;&lt;p&gt;A policy is a function $\pi(s) = a$ mapping from states to actions, that tells you what $action \space a$ to take in a given $state \space s$.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;goal&lt;/strong&gt;: Find a $policy \space \pi$ that tells you what $action (a = (s))$ to take in every $state (s)$ so as to maximize the return.&lt;/p&gt;</description>
    </item>
    <item>
      <title>VAE</title>
      <link>http://localhost:1313/post/vae/</link>
      <pubDate>Sun, 29 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/vae/</guid>
      <description>&lt;h3 id=&#34;key-concepts-of-vaes&#34;&gt;Key Concepts of VAEs&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Latent Variables&lt;/strong&gt;: VAEs assume that the observed data (e.g., images) is generated from a set of unobserved, lower-dimensional latent variables.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Probabilistic Framework&lt;/strong&gt;: VAEs are based on &lt;strong&gt;variational inference&lt;/strong&gt;, a method for approximating complex probability distributions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder-Decoder Architecture&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: Maps input data x&lt;em&gt;x&lt;/em&gt; to a distribution over latent variables z&lt;em&gt;z&lt;/em&gt;. This is often parameterized as a Gaussian distribution with mean μ&lt;em&gt;μ&lt;/em&gt; and variance σ2&lt;em&gt;σ&lt;/em&gt;2.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: Maps latent variables z&lt;em&gt;z&lt;/em&gt; back to the data space, generating new samples x′&lt;em&gt;x&lt;/em&gt;′ that resemble the original data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;普通自动编码器&#34;&gt;普通自动编码器&lt;/h2&gt;&#xA;&lt;p&gt;目标：将高维度数据压缩成较小的表示&lt;/p&gt;</description>
    </item>
    <item>
      <title>CV</title>
      <link>http://localhost:1313/post/cv/</link>
      <pubDate>Fri, 27 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/cv/</guid>
      <description>&lt;p&gt;问题: 处理高分辨率图像时，原始图像的像素数量通常非常庞大。&lt;/p&gt;&#xA;&lt;p&gt;类型：root node, decision node, leaf node&#xA; &lt;/p&gt;&#xA;&lt;h2 id=&#34;1-解决方案cnn&#34;&gt;1. 解决方案：CNN&lt;/h2&gt;&#xA;&lt;p&gt;卷积神经网络通过引入卷积操作，有效地解决了大图片参数过大的问题。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Automatic Feature Extraction&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;CNNs automatically learn hierarchical features from raw data (like images) without needing manual feature engineering.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Parameter Sharing&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a CNN, the same filter (or kernel) is applied across the entire image. This concept of &lt;strong&gt;weight sharing&lt;/strong&gt; significantly reduces the number of parameters compared to fully connected networks, making CNNs more computationally efficient.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;分层特征学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translation Invariance&lt;/strong&gt;（pooling layers）&lt;/p&gt;</description>
    </item>
    <item>
      <title>End2End</title>
      <link>http://localhost:1313/post/e2e/</link>
      <pubDate>Thu, 26 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/e2e/</guid>
      <description>&lt;p&gt;对于由多个阶段组成的学习系统，端到端学习捕获所有阶段，将其替代为单个神经网络。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;优点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Let the data speak&lt;/li&gt;&#xA;&lt;li&gt;Less hand-designing of components needed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;缺点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;May need large amount of data&lt;/li&gt;&#xA;&lt;li&gt;Excludes potentially useful hand-designed components&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;关键&lt;/strong&gt;：是否有足够的数据&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/e2e/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>transformer</title>
      <link>http://localhost:1313/post/transformer/</link>
      <pubDate>Wed, 25 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/transformer/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;Transformer&lt;/strong&gt; is a deep learning architecture introduced in the 2017 paper &lt;em&gt;&amp;ldquo;Attention is All You Need&amp;rdquo;&lt;/em&gt; by Vaswani et al. It revolutionized natural language processing (NLP) and has since become the foundation for many state-of-the-art models, such as BERT, GPT, and T5.&lt;/p&gt;&#xA;&lt;h3 id=&#34;seq2seq&#34;&gt;Seq2seq&lt;/h3&gt;&#xA;&lt;p&gt;Input a sequence, output a sequence The output length is determined by model.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e22b161f-7704-4d51-8881-70ee7e4c6dcb/%E6%88%AA%E5%B1%8F2024-12-31_15.12.59.png&#34; alt=&#34;截屏2024-12-31 15.12.59.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/180291f8-9817-42b6-87cb-39bf0734b9ef/%E6%88%AA%E5%B1%8F2024-12-31_19.34.56.png&#34; alt=&#34;截屏2024-12-31 19.34.56.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/31c00a57-de1e-43a9-b92a-13e3a050be48/%E6%88%AA%E5%B1%8F2024-12-31_19.35.51.png&#34; alt=&#34;截屏2024-12-31 19.35.51.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;encoder&#34;&gt;Encoder&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/901263ca-4e06-4f07-a672-aab03a6a86d4/cb6d7470-a2be-4ea5-9611-1cf0859d782f.png&#34; alt=&#34;截屏2024-12-31 15.15.42.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/3f6e614d-e0be-49d2-935e-642ebc3eaa82/%E6%88%AA%E5%B1%8F2024-12-31_15.29.37.png&#34; alt=&#34;截屏2024-12-31 15.29.37.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;细节&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/641849c0-19ea-464e-9b96-2e7b93b1d3d5/c8331594-f0cc-4348-967f-b026b8e2b68f.png&#34; alt=&#34;截屏2024-12-31 15.18.01.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>About ME</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;我的本科毕业于北京航空航天大学计算机科学与技术专业，目前，我正在香港大学攻读计算机科学硕士学位。&lt;/p&gt;&#xA;&lt;p&gt;我的生日是11月23号（是的，我的幸运数字是23），我是射手座，enfj。我喜欢和朋友一起探店美食，喜欢弹钢琴。我最喜欢的歌手是泰勒斯威夫特。&lt;/p&gt;&#xA;&lt;p&gt;最近，我刚刚开始学习吉他。欢迎和我成为朋友！&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/images/tayme.HEIC&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;—from AJ23&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description>&lt;p&gt;感谢你访问我的博客！如果你有任何问题或建议，欢迎与我取得联系：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href=&#34;mailto:aijunyang1123@163.com&#34;&gt;aijunyang1123@163.com&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;WeChat&lt;/strong&gt;: DearAJ_23&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/contact/wechat.jpg?width=10&amp;amp;height=10&#34; alt=&#34;wc&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
