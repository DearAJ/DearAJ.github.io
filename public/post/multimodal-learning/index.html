<!DOCTYPE html>
<html lang="en-US">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>multimodal learning | HomePage</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="CLIP
CLIP 文本-图像匹配
(1) 使用 CLIPProcessor 预处理
from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel

model_id = &#34;openai/clip-vit-base-patch32&#34;

# Load a tokenizer to preprocess the text
clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id)

# Load a processor to preprocess the images
clip_processor = CLIPProcessor.from_pretrained(model_id)

# Main model for generating text and image embeddings
model = CLIPModel.from_pretrained(model_id)


# 处理文本
text = [&#34;a photo of a cat&#34;]
inputs = processor(text=text, return_tensors=&#34;pt&#34;, padding=True)  # -&gt; {&#34;input_ids&#34;: ..., &#34;attention_mask&#34;: ...}

# 处理图像
image = Image.open(&#34;cat.jpg&#34;)
processed_image = processor(images=image, return_tensors=&#34;pt&#34;)[&#34;pixel_values&#34;]  # -&gt; [1, 3, 224, 224]
(2) 生成 Embedding
# 文本嵌入
text_embedding = model.get_text_features(**inputs)  # -&gt; [1, 512]

# 图像嵌入
image_embedding = model.get_image_features(processed_image)  # -&gt; [1, 512]
(3) 计算相似度
# 归一化（使点积=余弦相似度）
text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True)
image_embedding = image_embedding / image_embedding.norm(dim=-1, keepdim=True)

# 计算相似度
similarity = (text_embedding @ image_embedding.T).item()  # 值在 [-1, 1] 之间
为什么 CLIPProcessor 后还需要 Embedding？">
    <meta name="generator" content="Hugo 0.140.2">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/post/multimodal-learning/">
    

    <meta property="og:url" content="http://localhost:1313/post/multimodal-learning/">
  <meta property="og:site_name" content="HomePage">
  <meta property="og:title" content="multimodal learning">
  <meta property="og:description" content="CLIP CLIP 文本-图像匹配 (1) 使用 CLIPProcessor 预处理 from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel model_id = &#34;openai/clip-vit-base-patch32&#34; # Load a tokenizer to preprocess the text clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id) # Load a processor to preprocess the images clip_processor = CLIPProcessor.from_pretrained(model_id) # Main model for generating text and image embeddings model = CLIPModel.from_pretrained(model_id) # 处理文本 text = [&#34;a photo of a cat&#34;] inputs = processor(text=text, return_tensors=&#34;pt&#34;, padding=True) # -&gt; {&#34;input_ids&#34;: ..., &#34;attention_mask&#34;: ...} # 处理图像 image = Image.open(&#34;cat.jpg&#34;) processed_image = processor(images=image, return_tensors=&#34;pt&#34;)[&#34;pixel_values&#34;] # -&gt; [1, 3, 224, 224] (2) 生成 Embedding # 文本嵌入 text_embedding = model.get_text_features(**inputs) # -&gt; [1, 512] # 图像嵌入 image_embedding = model.get_image_features(processed_image) # -&gt; [1, 512] (3) 计算相似度 # 归一化（使点积=余弦相似度） text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True) image_embedding = image_embedding / image_embedding.norm(dim=-1, keepdim=True) # 计算相似度 similarity = (text_embedding @ image_embedding.T).item() # 值在 [-1, 1] 之间 为什么 CLIPProcessor 后还需要 Embedding？">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2025-06-29T10:00:59-04:00">
    <meta property="article:modified_time" content="2025-06-29T10:00:59-04:00">
    <meta property="article:tag" content="Multimodal">
    <meta property="article:tag" content="LLM">

  <meta itemprop="name" content="multimodal learning">
  <meta itemprop="description" content="CLIP CLIP 文本-图像匹配 (1) 使用 CLIPProcessor 预处理 from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel model_id = &#34;openai/clip-vit-base-patch32&#34; # Load a tokenizer to preprocess the text clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id) # Load a processor to preprocess the images clip_processor = CLIPProcessor.from_pretrained(model_id) # Main model for generating text and image embeddings model = CLIPModel.from_pretrained(model_id) # 处理文本 text = [&#34;a photo of a cat&#34;] inputs = processor(text=text, return_tensors=&#34;pt&#34;, padding=True) # -&gt; {&#34;input_ids&#34;: ..., &#34;attention_mask&#34;: ...} # 处理图像 image = Image.open(&#34;cat.jpg&#34;) processed_image = processor(images=image, return_tensors=&#34;pt&#34;)[&#34;pixel_values&#34;] # -&gt; [1, 3, 224, 224] (2) 生成 Embedding # 文本嵌入 text_embedding = model.get_text_features(**inputs) # -&gt; [1, 512] # 图像嵌入 image_embedding = model.get_image_features(processed_image) # -&gt; [1, 512] (3) 计算相似度 # 归一化（使点积=余弦相似度） text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True) image_embedding = image_embedding / image_embedding.norm(dim=-1, keepdim=True) # 计算相似度 similarity = (text_embedding @ image_embedding.T).item() # 值在 [-1, 1] 之间 为什么 CLIPProcessor 后还需要 Embedding？">
  <meta itemprop="datePublished" content="2025-06-29T10:00:59-04:00">
  <meta itemprop="dateModified" content="2025-06-29T10:00:59-04:00">
  <meta itemprop="wordCount" content="160">
  <meta itemprop="keywords" content="Multimodal,LLM">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="multimodal learning">
  <meta name="twitter:description" content="CLIP CLIP 文本-图像匹配 (1) 使用 CLIPProcessor 预处理 from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel model_id = &#34;openai/clip-vit-base-patch32&#34; # Load a tokenizer to preprocess the text clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id) # Load a processor to preprocess the images clip_processor = CLIPProcessor.from_pretrained(model_id) # Main model for generating text and image embeddings model = CLIPModel.from_pretrained(model_id) # 处理文本 text = [&#34;a photo of a cat&#34;] inputs = processor(text=text, return_tensors=&#34;pt&#34;, padding=True) # -&gt; {&#34;input_ids&#34;: ..., &#34;attention_mask&#34;: ...} # 处理图像 image = Image.open(&#34;cat.jpg&#34;) processed_image = processor(images=image, return_tensors=&#34;pt&#34;)[&#34;pixel_values&#34;] # -&gt; [1, 3, 224, 224] (2) 生成 Embedding # 文本嵌入 text_embedding = model.get_text_features(**inputs) # -&gt; [1, 512] # 图像嵌入 image_embedding = model.get_image_features(processed_image) # -&gt; [1, 512] (3) 计算相似度 # 归一化（使点积=余弦相似度） text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True) image_embedding = image_embedding / image_embedding.norm(dim=-1, keepdim=True) # 计算相似度 similarity = (text_embedding @ image_embedding.T).item() # 值在 [-1, 1] 之间 为什么 CLIPProcessor 后还需要 Embedding？">

	
  </head><body class="ma0 avenir bg-near-white development">

    
   
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://localhost:1313/images/multimodal/jaz.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        HomePage
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About ME page">
              About ME
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Articles page">
              Articles
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"><a href="https://www.facebook.com/patrick.kollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition facebook link dib z-999 pt3 pt0-l mr1"
        title="follow on Facebook - Opens in a new window"
        aria-label="follow on Facebook - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
            
          </span></a><a href="https://bsky.app/profile/kollitsch.dev" target="_blank" rel="noopener"
        class="ananke-social-link link-transition bluesky link dib z-999 pt3 pt0-l mr1"
        title="follow on Bluesky - Opens in a new window"
        aria-label="follow on Bluesky - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            
          </span></a><a href="http://linkedin.com/in/patrickkollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition linkedin link dib z-999 pt3 pt0-l mr1"
        title="follow on LinkedIn - Opens in a new window"
        aria-label="follow on LinkedIn - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
            
          </span></a></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">multimodal learning</div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Articles
      </aside><div id="sharing" class="mt3 ananke-socials"><a href="mailto:?&amp;body=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fmultimodal-learning%2F&amp;subject=multimodal&#43;learning"
        class="ananke-social-link email no-underline"
        title="Share on Email" aria-label="Share on Email"
        target="_blank" rel="nofollow noopener noreferrer">
        <span class="icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M64 112c-8.8 0-16 7.2-16 16l0 22.1L220.5 291.7c20.7 17 50.4 17 71.1 0L464 150.1l0-22.1c0-8.8-7.2-16-16-16L64 112zM48 212.2L48 384c0 8.8 7.2 16 16 16l384 0c8.8 0 16-7.2 16-16l0-171.8L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128C0 92.7 28.7 64 64 64l384 0c35.3 0 64 28.7 64 64l0 256c0 35.3-28.7 64-64 64L64 448c-35.3 0-64-28.7-64-64L0 128z"/></svg>
                
              </span></a><a href="https://facebook.com/sharer/sharer.php?&amp;u=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fmultimodal-learning%2F"
        class="ananke-social-link facebook no-underline"
        title="Share on Facebook" aria-label="Share on Facebook"
        target="_blank" rel="nofollow noopener noreferrer">
        <span class="icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
                
              </span></a><a href="https://bsky.app/intent/compose?&amp;text=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fmultimodal-learning%2F"
        class="ananke-social-link bluesky no-underline"
        title="Share on Bluesky" aria-label="Share on Bluesky"
        target="_blank" rel="nofollow noopener noreferrer">
        <span class="icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
                
              </span></a><a href="https://www.linkedin.com/shareArticle?&amp;mini=true&amp;source=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fmultimodal-learning%2F&amp;summary=CLIP&#43;CLIP&#43;%E6%96%87%E6%9C%AC-%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D&#43;%281%29&#43;%E4%BD%BF%E7%94%A8&#43;CLIPProcessor&#43;%E9%A2%84%E5%A4%84%E7%90%86&#43;from&#43;transformers&#43;import&#43;CLIPTokenizerFast%2C&#43;CLIPProcessor%2C&#43;CLIPModel&#43;model_id&#43;%3D&#43;%26amp%3B%2334%3Bopenai%2Fclip-vit-base-patch32%26amp%3B%2334%3B&#43;%23&#43;Load&#43;a&#43;tokenizer&#43;to&#43;preprocess&#43;the&#43;text&#43;clip_tokenizer&#43;%3D&#43;CLIPTokenizerFast.from_pretrained%28model_id%29&#43;%23&#43;Load&#43;a&#43;processor&#43;to&#43;preprocess&#43;the&#43;images&#43;clip_processor&#43;%3D&#43;CLIPProcessor.from_pretrained%28model_id%29&#43;%23&#43;Main&#43;model&#43;for&#43;generating&#43;text&#43;and&#43;image&#43;embeddings&#43;model&#43;%3D&#43;CLIPModel.from_pretrained%28model_id%29&#43;%23&#43;%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC&#43;text&#43;%3D&#43;%5B%26amp%3B%2334%3Ba&#43;photo&#43;of&#43;a&#43;cat%26amp%3B%2334%3B%5D&#43;inputs&#43;%3D&#43;processor%28text%3Dtext%2C&#43;return_tensors%3D%26amp%3B%2334%3Bpt%26amp%3B%2334%3B%2C&#43;padding%3DTrue%29&#43;%23&#43;-%26amp%3Bgt%3B&#43;%7B%26amp%3B%2334%3Binput_ids%26amp%3B%2334%3B%3A&#43;...%2C&#43;%26amp%3B%2334%3Battention_mask%26amp%3B%2334%3B%3A&#43;...%7D&#43;%23&#43;%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F&#43;image&#43;%3D&#43;Image.open%28%26amp%3B%2334%3Bcat.jpg%26amp%3B%2334%3B%29&#43;processed_image&#43;%3D&#43;processor%28images%3Dimage%2C&#43;return_tensors%3D%26amp%3B%2334%3Bpt%26amp%3B%2334%3B%29%5B%26amp%3B%2334%3Bpixel_values%26amp%3B%2334%3B%5D&#43;%23&#43;-%26amp%3Bgt%3B&#43;%5B1%2C&#43;3%2C&#43;224%2C&#43;224%5D&#43;%282%29&#43;%E7%94%9F%E6%88%90&#43;Embedding&#43;%23&#43;%E6%96%87%E6%9C%AC%E5%B5%8C%E5%85%A5&#43;text_embedding&#43;%3D&#43;model.get_text_features%28%2A%2Ainputs%29&#43;%23&#43;-%26amp%3Bgt%3B&#43;%5B1%2C&#43;512%5D&#43;%23&#43;%E5%9B%BE%E5%83%8F%E5%B5%8C%E5%85%A5&#43;image_embedding&#43;%3D&#43;model.get_image_features%28processed_image%29&#43;%23&#43;-%26amp%3Bgt%3B&#43;%5B1%2C&#43;512%5D&#43;%283%29&#43;%E8%AE%A1%E7%AE%97%E7%9B%B8%E4%BC%BC%E5%BA%A6&#43;%23&#43;%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%88%E4%BD%BF%E7%82%B9%E7%A7%AF%3D%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%89&#43;text_embedding&#43;%3D&#43;text_embedding&#43;%2F&#43;text_embedding.norm%28dim%3D-1%2C&#43;keepdim%3DTrue%29&#43;image_embedding&#43;%3D&#43;image_embedding&#43;%2F&#43;image_embedding.norm%28dim%3D-1%2C&#43;keepdim%3DTrue%29&#43;%23&#43;%E8%AE%A1%E7%AE%97%E7%9B%B8%E4%BC%BC%E5%BA%A6&#43;similarity&#43;%3D&#43;%28text_embedding&#43;%40&#43;image_embedding.T%29.item%28%29&#43;%23&#43;%E5%80%BC%E5%9C%A8&#43;%5B-1%2C&#43;1%5D&#43;%E4%B9%8B%E9%97%B4&#43;%E4%B8%BA%E4%BB%80%E4%B9%88&#43;CLIPProcessor&#43;%E5%90%8E%E8%BF%98%E9%9C%80%E8%A6%81&#43;Embedding%EF%BC%9F%0A&amp;title=multimodal&#43;learning&amp;url=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fmultimodal-learning%2F"
        class="ananke-social-link linkedin no-underline"
        title="Share on LinkedIn" aria-label="Share on LinkedIn"
        target="_blank" rel="nofollow noopener noreferrer">
        <span class="icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
                
              </span></a></div>
<h1 class="f1 athelas mt3 mb1">multimodal learning</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-06-29T10:00:59-04:00">June 29, 2025</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h2 id="clip">CLIP</h2>
<h3 id="clip-文本-图像匹配"><strong>CLIP 文本-图像匹配</strong></h3>
<h4 id="1-使用-clipprocessor-预处理"><strong>(1) 使用 <code>CLIPProcessor</code> 预处理</strong></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> CLIPTokenizerFast, CLIPProcessor, CLIPModel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model_id <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;openai/clip-vit-base-patch32&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load a tokenizer to preprocess the text</span>
</span></span><span style="display:flex;"><span>clip_tokenizer <span style="color:#f92672">=</span> CLIPTokenizerFast<span style="color:#f92672">.</span>from_pretrained(model_id)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load a processor to preprocess the images</span>
</span></span><span style="display:flex;"><span>clip_processor <span style="color:#f92672">=</span> CLIPProcessor<span style="color:#f92672">.</span>from_pretrained(model_id)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Main model for generating text and image embeddings</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> CLIPModel<span style="color:#f92672">.</span>from_pretrained(model_id)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 处理文本</span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;a photo of a cat&#34;</span>]
</span></span><span style="display:flex;"><span>inputs <span style="color:#f92672">=</span> processor(text<span style="color:#f92672">=</span>text, return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pt&#34;</span>, padding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)  <span style="color:#75715e"># -&gt; {&#34;input_ids&#34;: ..., &#34;attention_mask&#34;: ...}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 处理图像</span>
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#34;cat.jpg&#34;</span>)
</span></span><span style="display:flex;"><span>processed_image <span style="color:#f92672">=</span> processor(images<span style="color:#f92672">=</span>image, return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pt&#34;</span>)[<span style="color:#e6db74">&#34;pixel_values&#34;</span>]  <span style="color:#75715e"># -&gt; [1, 3, 224, 224]</span>
</span></span></code></pre></div><h4 id="2-生成-embedding"><strong>(2) 生成 Embedding</strong></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 文本嵌入</span>
</span></span><span style="display:flex;"><span>text_embedding <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>get_text_features(<span style="color:#f92672">**</span>inputs)  <span style="color:#75715e"># -&gt; [1, 512]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 图像嵌入</span>
</span></span><span style="display:flex;"><span>image_embedding <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>get_image_features(processed_image)  <span style="color:#75715e"># -&gt; [1, 512]</span>
</span></span></code></pre></div><h4 id="3-计算相似度"><strong>(3) 计算相似度</strong></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 归一化（使点积=余弦相似度）</span>
</span></span><span style="display:flex;"><span>text_embedding <span style="color:#f92672">=</span> text_embedding <span style="color:#f92672">/</span> text_embedding<span style="color:#f92672">.</span>norm(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image_embedding <span style="color:#f92672">=</span> image_embedding <span style="color:#f92672">/</span> image_embedding<span style="color:#f92672">.</span>norm(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 计算相似度</span>
</span></span><span style="display:flex;"><span>similarity <span style="color:#f92672">=</span> (text_embedding <span style="color:#f92672">@</span> image_embedding<span style="color:#f92672">.</span>T)<span style="color:#f92672">.</span>item()  <span style="color:#75715e"># 值在 [-1, 1] 之间</span>
</span></span></code></pre></div><p><strong>为什么 <code>CLIPProcessor</code> 后还需要 Embedding？</strong></p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">步骤</th>
          <th style="text-align: left">作用</th>
          <th style="text-align: left">输入</th>
          <th style="text-align: left">输出</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>CLIPProcessor</strong></td>
          <td style="text-align: left">预处理（文本→token，图像→张量）</td>
          <td style="text-align: left">原始文本/图像</td>
          <td style="text-align: left"><code>input_ids</code>, <code>pixel_values</code></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Embedding</strong></td>
          <td style="text-align: left">生成语义向量（文本/图像→高维向量）</td>
          <td style="text-align: left"><code>input_ids</code>, <code>pixel_values</code></td>
          <td style="text-align: left"><code>[1, 512]</code> 向量</td>
      </tr>
  </tbody>
</table>
<ul>
<li><strong><code>CLIPProcessor</code></strong> 只是 <strong>数据预处理</strong>，不涉及模型推理。</li>
<li><strong>Embedding</strong> 是 <strong>模型的核心计算</strong>，将输入映射到语义空间。</li>
</ul>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/multimodal/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Multimodal</a>
   </li>
  
   <li class="list di">
     <a href="/tags/llm/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">LLM</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/post/dify-agent/">dify - Agent</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/langchain-semanticsearch/">langchain - 混合搜索</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/langchain-agent/">langchain - Agent</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/prompt/">Prompting Guide</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/llm4/">LLM - 4.大模型增强 - RAG</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/llm3.5/">LLM - 3.指令理解阶段(核心) - 强化学习</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/llm3/">LLM - 3.指令理解阶段(核心) - 指令微调</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/llm2/">LLM - 2.预训练阶段</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/llm1/">LLM - 1.基础理论</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/bert/">BERT</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/%E5%BE%AE%E8%B0%83/">微调</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/mllm/">MLLM</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/post/transformer/">transformer</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  HomePage 2025 
  </a>
    <div><div class="ananke-socials"><a href="https://www.facebook.com/patrick.kollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition facebook link dib z-999 pt3 pt0-l mr1"
        title="follow on Facebook - Opens in a new window"
        aria-label="follow on Facebook - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
            
          </span></a><a href="https://bsky.app/profile/kollitsch.dev" target="_blank" rel="noopener"
        class="ananke-social-link link-transition bluesky link dib z-999 pt3 pt0-l mr1"
        title="follow on Bluesky - Opens in a new window"
        aria-label="follow on Bluesky - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            
          </span></a><a href="http://linkedin.com/in/patrickkollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition linkedin link dib z-999 pt3 pt0-l mr1"
        title="follow on LinkedIn - Opens in a new window"
        aria-label="follow on LinkedIn - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
            
          </span></a></div>
</div>
  </div>
</footer>

  </body>
</html>
