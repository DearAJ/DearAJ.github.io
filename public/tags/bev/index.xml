<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BEV on HomePage</title>
    <link>http://localhost:1313/tags/bev/</link>
    <description>Recent content in BEV on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 17 Feb 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/bev/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BEV 论文学习</title>
      <link>http://localhost:1313/post/bev%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Mon, 17 Feb 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/bev%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h2 id=&#34;vision-centric-bev-perception-a-survey&#34;&gt;Vision-Centric BEV Perception: A Survey&lt;/h2&gt;&#xA;&lt;p&gt;许多方法被提出以&lt;strong&gt;解决从透视视图（Perspective View, PV）到 BEV 的转换问题&lt;/strong&gt;，本文将它们分为基于几何、基于深度、基于 MLP 和基于 Transformer 的四类方法。&lt;/p&gt;&#xA;&lt;p&gt;此外，本文还探讨了 BEV 感知的扩展应用，如多任务学习、多模态融合和语义占据预测等。&lt;/p&gt;&#xA;&lt;h4 id=&#34;1-背景介绍&#34;&gt;1. 背景介绍&lt;/h4&gt;&#xA;&lt;p&gt;BEV 感知的核心任务是将 PV 中的&lt;strong&gt;图像序列转换为BEV特征，并在BEV空间中进行感知任务&lt;/strong&gt;（如3D目标检测和语义地图生成），能够提供精确的定位和绝对尺度信息，便于多视图、多模态和时间序列数据的融合。&lt;/p&gt;&#xA;&lt;p&gt;但由于摄像头通常安装在车辆上，捕捉到的图像是透视视图，如何将 PV 转换为 BEV 仍然是一个具有挑战性的问题。&lt;/p&gt;&#xA;&lt;h4 id=&#34;3-主要方法分类&#34;&gt;3. 主要方法分类&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于几何的方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：这类方法主要依赖于&lt;strong&gt;逆透视映射（IPM）&lt;/strong&gt;，通过几何变换将 PV 图像转换为 BEV 图像。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;缺陷&lt;/strong&gt;：但 IPM 假设地面是平坦的，因此在复杂场景中（如存在高度变化的物体）会产生失真。为了减少失真，一些方法引入了&lt;strong&gt;语义信息&lt;/strong&gt;或使用 &lt;strong&gt;GAN&lt;/strong&gt; 。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于深度的方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过深度估计将 2D 特征提升到 3D 空间，然后通过降维得到 BEV 表示。深度估计可以是显式的（如通过深度图）或隐式的（如通过任务监督）。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;点云方法&lt;/strong&gt;：将深度图转换为伪 LiDAR 点云，然后使用 LiDAR 检测器进行 3D 检测&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;体素方法&lt;/strong&gt;：将 2D 特征映射到 3D 体素空间，并通过体素特征进行 BEV 感知&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于MLP的方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：MLP 方法不依赖于摄像头的几何参数，而是通过学习隐式表示来完成视图转换。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;缺陷&lt;/strong&gt;：尽管 MLP 具有通用逼近能力，但由于缺乏深度信息和遮挡问题，视图转换仍然具有挑战性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于Transformer的方法&lt;/strong&gt;：&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
