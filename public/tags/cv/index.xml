<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CV on HomePage</title>
    <link>http://localhost:1313/tags/cv/</link>
    <description>Recent content in CV on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 14 Apr 2025 04:00:59 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/cv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LSS代码</title>
      <link>http://localhost:1313/post/lss%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 14 Apr 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/lss%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</guid>
      <description>&lt;p&gt;文章搬运，自用。&lt;/p&gt;&#xA;&lt;p&gt;论文：&lt;a href=&#34;https://arxiv.org/abs/2008.05711&#34;&gt;Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;官方源码：&lt;a href=&#34;https://github.com/nv-tlabs/lift-splat-shoot&#34;&gt;lift-splat-shoot&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h4 id=&#34;lift-splat-shoot图像bev安装与模型代码详解httpsblogcsdnnetqq_41366026articledetails133840315&#34;&gt;&lt;a href=&#34;https://blog.csdn.net/qq_41366026/article/details/133840315&#34;&gt;Lift, Splat, Shoot图像BEV安装与模型代码详解&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;p&gt;对于任意数量不同相机帧的图像直接提取场景的BEV表达；主要由三部分实现：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Lift&lt;/strong&gt;：将每一个相机的图像帧根据相机的内参转换提升到 frustum（锥形）形状的点云空间中。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;splate&lt;/strong&gt;：将所有相机转换到锥形点云空间中的特征根据相机的内参 K 与相机相对于 ego 的外参T映射到栅格化的 3D 空间（BEV）中来融合多帧信息。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;shoot&lt;/strong&gt;：根据上述 BEV 的检测或分割结果来生成规划的路径 proposal；从而实现可解释的端到端的路径规划任务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;注：LSS在训练的过程中并不需要激光雷达的点云来进行监督。&lt;/p&gt;</description>
    </item>
    <item>
      <title>语义分割</title>
      <link>http://localhost:1313/post/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</link>
      <pubDate>Sat, 29 Mar 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</guid>
      <description>&lt;p&gt;语义分割将图片中的&lt;strong&gt;每个像素&lt;/strong&gt;分类到对应的类别。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/SemanticSegmentation/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;应用&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;背景虚化、路面分割、实例分割(会关注具体是哪个个体，如 Mask R-CNN)、全景分割（还要对背景进行分割，如 Panoptic FPN）&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;常见模型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/SemanticSegmentation/5.png&#34; alt=&#34;5&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;语义分割任务常见的数据集格式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;PASCAL VOC&lt;/strong&gt;：PNG图片 + 每个像素的类别信息（每个像素都对应一个颜色）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MS COCO&lt;/strong&gt;：每个目标都记录了一个多边形坐标，将所有的点连一起，即可得到边缘信息(还可以用于实例分析)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;语义分割得到的具体形式&lt;/strong&gt;：单通道图片，加上调色板 mask 蒙版后可以上色（palette），方便可视化。每个像素数值对应类别索引。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Lift-splat-shoot</title>
      <link>http://localhost:1313/post/lss/</link>
      <pubDate>Thu, 27 Mar 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/lss/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2008.05711&#34;&gt;Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;简单来说，&lt;strong&gt;Lift&lt;/strong&gt;就是预测了一个&lt;strong&gt;深度值分布D&lt;/strong&gt;，以及&lt;strong&gt;提取的特征c&lt;/strong&gt;，然后将两种进行外积操作，实现了&lt;strong&gt;增维&lt;/strong&gt;操作。&lt;/p&gt;&#xA;&lt;p&gt;**Splat（拍扁）**操作则是使用了一种特殊的“求和池化”操作（z累加，压平），实现降维。&lt;/p&gt;&#xA;&lt;p&gt;最后的&lt;strong&gt;Shooting&lt;/strong&gt;，则是将预测的一组轨迹投射出来，选取最优的轨迹作为预测结果。&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h3 id=&#34;1-关键lift&#34;&gt;1. 关键：Lift&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/lss/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;特征提取&amp;amp;深度估计&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;多视角相机输入后，进行特征提取与深度估计&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;外积（Outer product）&lt;/strong&gt;—— 最核心的操作&lt;/p&gt;&#xA;&lt;p&gt;无法确定每个 pixel 的特征投影 BEV 视角下的具体位置；对于每个 pixel 特征，使用的是“all possible depths”。&lt;/p&gt;&#xA;&lt;p&gt;使用外积操作，将 Image feature (H * W * C) 和 Depth feature (H * W * D)构造成一个(H * W * D * C) 的 Frustum feature。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>BEV 论文学习</title>
      <link>http://localhost:1313/post/bev%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Mon, 17 Feb 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/bev%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h2 id=&#34;vision-centric-bev-perception-a-survey&#34;&gt;Vision-Centric BEV Perception: A Survey&lt;/h2&gt;&#xA;&lt;p&gt;许多方法被提出以&lt;strong&gt;解决从透视视图（Perspective View, PV）到 BEV 的转换问题&lt;/strong&gt;，本文将它们分为基于几何、基于深度、基于 MLP 和基于 Transformer 的四类方法。&lt;/p&gt;&#xA;&lt;p&gt;此外，本文还探讨了 BEV 感知的扩展应用，如多任务学习、多模态融合和语义占据预测等。&lt;/p&gt;&#xA;&lt;h4 id=&#34;1-背景介绍&#34;&gt;1. 背景介绍&lt;/h4&gt;&#xA;&lt;p&gt;BEV 感知的核心任务是将 PV 中的&lt;strong&gt;图像序列转换为BEV特征，并在BEV空间中进行感知任务&lt;/strong&gt;（如3D目标检测和语义地图生成），能够提供精确的定位和绝对尺度信息，便于多视图、多模态和时间序列数据的融合。&lt;/p&gt;&#xA;&lt;p&gt;但由于摄像头通常安装在车辆上，捕捉到的图像是透视视图，如何将 PV 转换为 BEV 仍然是一个具有挑战性的问题。&lt;/p&gt;&#xA;&lt;h4 id=&#34;3-主要方法分类&#34;&gt;3. 主要方法分类&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于几何的方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：这类方法主要依赖于&lt;strong&gt;逆透视映射（IPM）&lt;/strong&gt;，通过几何变换将 PV 图像转换为 BEV 图像。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;缺陷&lt;/strong&gt;：但 IPM 假设地面是平坦的，因此在复杂场景中（如存在高度变化的物体）会产生失真。为了减少失真，一些方法引入了&lt;strong&gt;语义信息&lt;/strong&gt;或使用 &lt;strong&gt;GAN&lt;/strong&gt; 。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于深度的方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过深度估计将 2D 特征提升到 3D 空间，然后通过降维得到 BEV 表示。深度估计可以是显式的（如通过深度图）或隐式的（如通过任务监督）。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;点云方法&lt;/strong&gt;：将深度图转换为伪 LiDAR 点云，然后使用 LiDAR 检测器进行 3D 检测&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;体素方法&lt;/strong&gt;：将 2D 特征映射到 3D 体素空间，并通过体素特征进行 BEV 感知&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于MLP的方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：MLP 方法不依赖于摄像头的几何参数，而是通过学习隐式表示来完成视图转换。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;缺陷&lt;/strong&gt;：尽管 MLP 具有通用逼近能力，但由于缺乏深度信息和遮挡问题，视图转换仍然具有挑战性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于Transformer的方法&lt;/strong&gt;：&lt;/p&gt;</description>
    </item>
    <item>
      <title>MLLM</title>
      <link>http://localhost:1313/post/mllm/</link>
      <pubDate>Sun, 09 Feb 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/mllm/</guid>
      <description>&lt;h1 id=&#34;1基础&#34;&gt;1基础&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-特征提取&#34;&gt;1. 特征提取&lt;/h2&gt;&#xA;&lt;h3 id=&#34;一cv中的特征提取&#34;&gt;&lt;strong&gt;一、CV中的特征提取&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1-传统方法手工设计特征&#34;&gt;&lt;strong&gt;1. 传统方法（手工设计特征）&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;p&gt;&lt;strong&gt;(1) 低级视觉特征&lt;/strong&gt;：颜色、纹理、 边缘与形状&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;(2) 中级语义特征&lt;/strong&gt;：SIFT（尺度不变特征变换）、SURF（加速鲁棒特征）、LBP（局部二值模式）&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h4 id=&#34;2-深度学习方法自动学习特征&#34;&gt;&lt;strong&gt;2. 深度学习方法（自动学习特征）&lt;/strong&gt;&lt;/h4&gt;&#xA;&lt;h5 id=&#34;1-卷积神经网络cnn&#34;&gt;&lt;strong&gt;(1) 卷积神经网络（CNN）&lt;/strong&gt;&lt;/h5&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：通过卷积层提取局部特征，池化层降低维度，全连接层进行分类。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;经典模型&lt;/strong&gt;：LeNet-5、AlexNet、VGGNet、ResNet(使用残差可以训练更深的网络)&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/MLLM/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h5 id=&#34;2-视觉transformervit&#34;&gt;&lt;strong&gt;(2) 视觉Transformer（ViT）&lt;/strong&gt;&lt;/h5&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：将图像分割为小块（patches），通过自注意力机制建模全局关系。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：无需局部卷积先验，直接建模长距离依赖; 在ImageNet等任务上超越传统CNN。&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>目标检测</title>
      <link>http://localhost:1313/post/object-detection/</link>
      <pubDate>Fri, 31 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/object-detection/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/CV/19.png&#34; alt=&#34;19&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;技巧&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Ensembling&lt;/strong&gt;：Train several networks independently and average their outputs &lt;strong&gt;Multi-crop at test time&lt;/strong&gt;：Run classifier on multiple versions of test images and average results&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h3 id=&#34;定位&#34;&gt;定位&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/CV/20.png&#34; alt=&#34;20&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Need to output bx, by, bn, bw, class label (1-4)&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/CV/21.png&#34; alt=&#34;21&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;需人工标注&lt;strong&gt;特征点的坐标&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h3 id=&#34;基于滑动窗口的目标检测算法&#34;&gt;基于滑动窗口的目标检测算法&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;先训练卷积网络识别物体&lt;/li&gt;&#xA;&lt;li&gt;滑动+放大窗口+再次滑动&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;：计算效率大，慢&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;</description>
    </item>
  </channel>
</rss>
