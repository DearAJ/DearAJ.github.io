<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Processing on HomePage</title>
    <link>http://localhost:1313/tags/data-processing/</link>
    <description>Recent content in Data Processing on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 17 Apr 2025 05:00:59 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/data-processing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>工具链-PyTorch</title>
      <link>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-pytorch/</link>
      <pubDate>Thu, 17 Apr 2025 05:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-pytorch/</guid>
      <description>&lt;h2 id=&#34;1-处理数据&#34;&gt;1. 处理数据&lt;/h2&gt;&#xA;&lt;p&gt;PyTorch 有两个用于处理数据的基元： &lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt; 和 &lt;code&gt;torch.utils.data.Dataset&lt;/code&gt;。&#xA;&lt;code&gt;Dataset&lt;/code&gt; 存储样本及其相应的标签，&lt;code&gt;DataLoader&lt;/code&gt; 将 &lt;code&gt;Dataset&lt;/code&gt; 包装成一个迭代器。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;下面以 TorchVision 库模块里的 FashionMNIST 数据集为例：&lt;/p&gt;&#xA;&lt;p&gt;每个 TorchVision &lt;code&gt;Dataset&lt;/code&gt; 都包含两个参数： &lt;code&gt;transform&lt;/code&gt; 和 &lt;code&gt;target_transform&lt;/code&gt; 分别修改样本和标签&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download training data from open datasets.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;FashionMNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    root&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ToTensor(),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download test data from open datasets.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;FashionMNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    root&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ToTensor(),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将 &lt;code&gt;Dataset&lt;/code&gt; 作为参数传递给 &lt;code&gt;DataLoader&lt;/code&gt; ，将一个可迭代对象包装在数据集上，支持自动批处理、采样、洗牌和多进程数据加载。&lt;/p&gt;&#xA;&lt;p&gt;定义了一个 batch size 为 64，即 dataloader 迭代器中的每个元素将返回&lt;strong&gt;一个 64 features and labels 的 batch&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>数据集-NuSences</title>
      <link>http://localhost:1313/post/%E6%95%B0%E6%8D%AE%E9%9B%86-nusences/</link>
      <pubDate>Fri, 11 Apr 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E6%95%B0%E6%8D%AE%E9%9B%86-nusences/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;h4 id=&#34;内容&#34;&gt;内容&lt;/h4&gt;&#xA;&lt;p&gt;nuScenes 包含 1000 个场景，大约 1.4M 的相机图像、390k LIDAR 扫描、1.4M 雷达扫描和 40k 关键帧中的 1.4M 对象边界框。&lt;/p&gt;&#xA;&lt;p&gt;nuScenes-lidarseg 包含 40000 个点云和 1000 个场景（850 个用于训练和验证的场景，以及 150 个用于测试的场景）中的 14 亿个注释点。&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;h4 id=&#34;数据采集&#34;&gt;数据采集&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;车辆设置&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/nuSences/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;1 个旋转激光雷达 （Velodyne HDL32E）&lt;/li&gt;&#xA;&lt;li&gt;5 个远程雷达传感器 （Continental ARS 408-21）&lt;/li&gt;&#xA;&lt;li&gt;6 个相机 （Basler acA1600-60gc）&lt;/li&gt;&#xA;&lt;li&gt;1个 IMU &amp;amp; GPS （高级导航空间版）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Sensor(传感器)校准 - 内外参&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;LIDAR extrinsics&lt;/li&gt;&#xA;&lt;li&gt;相机 extrinsics&lt;/li&gt;&#xA;&lt;li&gt;RADAR extrinsics&lt;/li&gt;&#xA;&lt;li&gt;相机 intrinsic 校准&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Sensor(传感器)同步&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;实现跨模态数据对齐：当顶部 LIDAR 扫描相机 FOV 的中心时，会触发相机的曝光&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
  </channel>
</rss>
