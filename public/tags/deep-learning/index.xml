<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on HomePage</title>
    <link>http://localhost:1313/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 15 Jan 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM</title>
      <link>http://localhost:1313/post/llm/</link>
      <pubDate>Wed, 15 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/llm/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;分类&#34;&gt;分类&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;大语言模型（LLM）&lt;/p&gt;&#xA;&lt;p&gt;这类大模型专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。它们通常基于深度学习架构（如Transformer模型），经过大规模文本数据集训练而成，能够捕捉语言的复杂性，包括语法、语义、语境以及蕴含的文化和社会知识。语言大模型典型应用包括文本生成、问答系统、文本分类、机器翻译、对话系统等。示例包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPT系列（OpenAI）：如GPT-3、GPT-3.5、GPT-4等。&lt;/li&gt;&#xA;&lt;li&gt;Bard（Google）：谷歌推出的大型语言模型，用于提供信息丰富的、有创意的文本输出。&lt;/li&gt;&#xA;&lt;li&gt;通义千问（阿里云）：阿里云自主研发的超大规模的语言模型。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多模态模型 多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，并在这些模态之间建立关联和交互。它们能够整合不同类型的输入信息，进行跨模态推理、生成和理解任务。多模态大模型的应用涵盖视觉问答、图像描述生成、跨模态检索.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>CV</title>
      <link>http://localhost:1313/post/cv/</link>
      <pubDate>Fri, 27 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/cv/</guid>
      <description>&lt;p&gt;问题: 处理高分辨率图像时，原始图像的像素数量通常非常庞大。&lt;/p&gt;&#xA;&lt;p&gt;类型：root node, decision node, leaf node&lt;/p&gt;&#xA;&lt;h3 id=&#34;解决方案cnn&#34;&gt;解决方案：CNN&lt;/h3&gt;&#xA;&lt;p&gt;卷积神经网络通过引入卷积操作，有效地解决了大图片参数过大的问题。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Automatic Feature Extraction&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;CNNs automatically learn hierarchical features from raw data (like images) without needing manual feature engineering.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Parameter Sharing&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a CNN, the same filter (or kernel) is applied across the entire image. This concept of &lt;strong&gt;weight sharing&lt;/strong&gt; significantly reduces the number of parameters compared to fully connected networks, making CNNs more computationally efficient.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;分层特征学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translation Invariance&lt;/strong&gt;（pooling layers）&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reduced Computational Complexity&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
