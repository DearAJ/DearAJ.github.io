<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on HomePage</title>
    <link>http://localhost:1313/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 20 Jan 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM</title>
      <link>http://localhost:1313/post/llm/</link>
      <pubDate>Mon, 20 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/llm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&amp;amp;vd_source=80aea28698fb0235b45699fc7e6fcdac&amp;amp;p=2&#34;&gt;https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&amp;vd_source=80aea28698fb0235b45699fc7e6fcdac&amp;p=2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;h2 id=&#34;大模型的演变&#34;&gt;大模型的演变&lt;/h2&gt;&#xA;&lt;p&gt;大模型的训练整体上分为三个阶段：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个阶段它会学习各种不同种类的语料，学习到语言的统计规律和一般知识。&lt;/p&gt;&#xA;&lt;p&gt;但是大模型在这个阶段只是学会了补全句子，却没有学会怎么样去领会人类的意图（类似成语接龙）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;SFT（监督微调）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个阶段大模型可以学习各种人类的对话语料，甚至是非常专业的垂直领域知识。&lt;/p&gt;&#xA;&lt;p&gt;但是模型的回答有时候可能并不符合人类的偏好，它可能会输出一些涉黄、涉政、涉暴或者种族歧视等言论。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;RLHF（基于人类反馈的强化学习）&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个阶段大模型会针对同一问题进行多次回答，人类会对这些回答打分。&lt;/p&gt;&#xA;&lt;p&gt;大模型会在此阶段学习到如何输出分数最高的回答，使得回答更符合人类的偏好。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;分类&#34;&gt;分类&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;大语言模型（LLM）&lt;/p&gt;&#xA;&lt;p&gt;专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多模态模型&lt;/p&gt;&#xA;&lt;p&gt;多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，在这些模态之间建立关联和交互。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;工作流程&#34;&gt;工作流程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;分词化与词表映射&#34;&gt;分词化与词表映射&lt;/h3&gt;&#xA;&lt;p&gt;**分词化（Tokenization）**是指将段落和句子分割成更小的分词（token）的过程。&lt;/p&gt;&#xA;&lt;p&gt;分词化有不同的粒度分类：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;﻿词粒度（Word-Level Tokenization）分词化：适用于大多数西方语言，如英语。&lt;/li&gt;&#xA;&lt;li&gt;﻿字符粒度（Character-Level）分词化：中文最直接的分词方法，它是以单个汉字为单位进行分词化。&lt;/li&gt;&#xA;&lt;li&gt;﻿子词粒度（Subword-Level）分词化：将单词分解成更小的单位，比如词根、词缀等。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;每一个token都会通过预先设置好的词表，映射为一个 token id，这是token 的“身份证”，一句话最终会被表示为一个元素为token id的列表，供计算机进行下一步处理。&lt;/p&gt;&#xA;&lt;h3 id=&#34;文本生成过程&#34;&gt;文本生成过程&lt;/h3&gt;&#xA;&lt;p&gt;大语言模型根据给定的文本&lt;strong&gt;预测下一个token&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;大模型进行推理时，基于现有的token，根据概率最大原则预测出下一个最有可能的token，然后将该预测的token加入到输入序列中，并将更新后的输入序列继续输入大模型预测下一个token，这个过程叫做&lt;strong&gt;自回归&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;直到输出特殊token（如&lt;!-- raw HTML omitted --&gt;，end of sentence，专门用来控制推理何时结束）或输出长度达到阈值。&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-agent&#34;&gt;AI Agent&lt;/h1&gt;&#xA;&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;&#xA;&lt;h3 id=&#34;agent认知与原理分析&#34;&gt;agent认知与原理分析&lt;/h3&gt;&#xA;&lt;p&gt;Al Agents是基于LLM的能够自主理解、自主规划笨策、执行复杂任务的習能体。&lt;/p&gt;&#xA;&lt;p&gt;Agent的设计目的是为了处理那些简单的语言模型可能无法直接解决的问题，尤其是当这些任务涉及到多个步骤或者需要外部数据源的情况。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;﻿LLM：接受输入、思考、输出&lt;/li&gt;&#xA;&lt;li&gt;﻿人类：LLM（接受输入、思考、输出）+记忆＋工具+规划&amp;mdash;&amp;mdash;&amp;gt;Agents&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;agent技术框架&#34;&gt;agent技术框架&lt;/h3&gt;&#xA;&lt;h3 id=&#34;agent策略分析与parer解读&#34;&gt;agent策略分析与Parer解读&lt;/h3&gt;&#xA;&lt;h3 id=&#34;单agent系统与多agent系统&#34;&gt;单Agent系统与多Agent系统&lt;/h3&gt;&#xA;&lt;h3 id=&#34;个性化agent应用定制全流程详讲&#34;&gt;个性化Agent应用定制全流程详讲&lt;/h3&gt;&#xA;&lt;h2 id=&#34;实践&#34;&gt;实践&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Quantization</title>
      <link>http://localhost:1313/post/quantization/</link>
      <pubDate>Mon, 20 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/quantization/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;概述&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;量化&lt;/strong&gt;：Store the parameters of the model in lower precision&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Knowledge distillation&lt;/strong&gt;: Train a smaller model (student) using the original model (instructor).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pruning&lt;/strong&gt;: Remove connections (weights) from the model&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Application&lt;/strong&gt;: Perform linear quantization on any model using Quanto in two lines&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;内容&#34;&gt;内容&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Linear Quantization theory&lt;/strong&gt; in detail and how to code it (&lt;em&gt;per channel, per tensor, per group quantization&lt;/em&gt;)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Build your own 8-bit linear quantizer and apply it on real models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>CV</title>
      <link>http://localhost:1313/post/cv/</link>
      <pubDate>Fri, 27 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/cv/</guid>
      <description>&lt;p&gt;问题: 处理高分辨率图像时，原始图像的像素数量通常非常庞大。&lt;/p&gt;&#xA;&lt;p&gt;类型：root node, decision node, leaf node&#xA; &lt;/p&gt;&#xA;&lt;h2 id=&#34;1-解决方案cnn&#34;&gt;1. 解决方案：CNN&lt;/h2&gt;&#xA;&lt;p&gt;卷积神经网络通过引入卷积操作，有效地解决了大图片参数过大的问题。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Automatic Feature Extraction&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;CNNs automatically learn hierarchical features from raw data (like images) without needing manual feature engineering.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Parameter Sharing&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a CNN, the same filter (or kernel) is applied across the entire image. This concept of &lt;strong&gt;weight sharing&lt;/strong&gt; significantly reduces the number of parameters compared to fully connected networks, making CNNs more computationally efficient.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;分层特征学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Translation Invariance&lt;/strong&gt;（pooling layers）&lt;/p&gt;</description>
    </item>
    <item>
      <title>transformer</title>
      <link>http://localhost:1313/post/transformer/</link>
      <pubDate>Wed, 25 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/transformer/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;Transformer&lt;/strong&gt; is a deep learning architecture introduced in the 2017 paper &lt;em&gt;&amp;ldquo;Attention is All You Need&amp;rdquo;&lt;/em&gt; by Vaswani et al. It revolutionized natural language processing (NLP) and has since become the foundation for many state-of-the-art models, such as BERT, GPT, and T5.&lt;/p&gt;&#xA;&lt;h3 id=&#34;seq2seq&#34;&gt;Seq2seq&lt;/h3&gt;&#xA;&lt;p&gt;Input a sequence, output a sequence The output length is determined by model.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e22b161f-7704-4d51-8881-70ee7e4c6dcb/%E6%88%AA%E5%B1%8F2024-12-31_15.12.59.png&#34; alt=&#34;截屏2024-12-31 15.12.59.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/180291f8-9817-42b6-87cb-39bf0734b9ef/%E6%88%AA%E5%B1%8F2024-12-31_19.34.56.png&#34; alt=&#34;截屏2024-12-31 19.34.56.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/31c00a57-de1e-43a9-b92a-13e3a050be48/%E6%88%AA%E5%B1%8F2024-12-31_19.35.51.png&#34; alt=&#34;截屏2024-12-31 19.35.51.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;encoder&#34;&gt;Encoder&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/901263ca-4e06-4f07-a672-aab03a6a86d4/cb6d7470-a2be-4ea5-9611-1cf0859d782f.png&#34; alt=&#34;截屏2024-12-31 15.15.42.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/3f6e614d-e0be-49d2-935e-642ebc3eaa82/%E6%88%AA%E5%B1%8F2024-12-31_15.29.37.png&#34; alt=&#34;截屏2024-12-31 15.29.37.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;细节&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/641849c0-19ea-464e-9b96-2e7b93b1d3d5/c8331594-f0cc-4348-967f-b026b8e2b68f.png&#34; alt=&#34;截屏2024-12-31 15.18.01.png&#34;&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
