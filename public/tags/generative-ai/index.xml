<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative AI on HomePage</title>
    <link>http://localhost:1313/tags/generative-ai/</link>
    <description>Recent content in Generative AI on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 17 Jan 2025 10:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/generative-ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Diffusion Model</title>
      <link>http://localhost:1313/post/diffusion-model/</link>
      <pubDate>Fri, 17 Jan 2025 10:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/diffusion-model/</guid>
      <description>&lt;h3 id=&#34;advantages&#34;&gt;Advantages:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;High-Quality Outputs:&lt;/strong&gt; Diffusion models are known for producing high-quality, realistic samples.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; They can be applied to various types of data, including images, audio, and even text.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Theoretical Foundation:&lt;/strong&gt; The process is grounded in well-understood principles of probability and statistics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Challenges&lt;/strong&gt;: Computational Cost、Training Complexity.&lt;/p&gt;&#xA;&lt;h1 id=&#34;原理&#34;&gt;原理&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reverse Process&lt;/strong&gt;（多次Denoise）&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;reconstructing meaningful data from noise&lt;/strong&gt; by iteratively removing noise that was added during the &lt;strong&gt;forward process&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Forward Process&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;p&gt;Gradually adds noise to data over multiple steps until the data becomes pure noise.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generative AI</title>
      <link>http://localhost:1313/post/ga/</link>
      <pubDate>Sat, 04 Jan 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/ga/</guid>
      <description>&lt;h1 id=&#34;chatgpt&#34;&gt;ChatGPT&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/ba53c8d8-3a8d-4bb9-a20f-5cd7d295a29f/%E6%88%AA%E5%B1%8F2025-01-05_23.37.32.png&#34; alt=&#34;截屏2025-01-05 23.37.32.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/740b097c-4c79-42af-bc9b-5817abdc3521/%E6%88%AA%E5%B1%8F2025-01-04_00.25.09.png&#34; alt=&#34;截屏2025-01-04 00.25.09.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ChatGPT 真正做的事：文字接龙&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Autoregressive Generation&lt;/strong&gt;：逐个生成&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/a140588c-153b-4bf3-812b-794d09b256c2/%E6%88%AA%E5%B1%8F2025-01-04_00.18.34.png&#34; alt=&#34;截屏2025-01-04 00.18.34.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/10249f01-191e-4450-9387-201ee36c281d/247f57f5-a4f8-4859-8ce8-9664487924cd.png&#34; alt=&#34;截屏2025-01-04 00.27.44.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;token&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;文字接龙时可以选择的符号&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e0bc078c-68ba-4504-b3dc-2bee0739d6fa/%E6%88%AA%E5%B1%8F2025-01-04_00.29.01.png&#34; alt=&#34;截屏2025-01-04 00.29.01.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;每次回答都随机（掷骰子）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b30b483b-47dd-4cfd-9a2d-bcd030b1b169/%E6%88%AA%E5%B1%8F2025-01-04_11.07.26.png&#34; alt=&#34;截屏2025-01-04 11.07.26.png&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;进化关键：&lt;strong&gt;自督导式学习(预训练) ➡️ 督导式学习(微调) ➡️ 强化学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b2ca8f91-7703-4339-ae03-089a67c3519f/%E6%88%AA%E5%B1%8F2025-01-04_23.52.07.png&#34; alt=&#34;截屏2025-01-04 23.52.07.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有预训练，督导式学习不用大量资料。&lt;/p&gt;&#xA;&lt;p&gt;强化学习提供回馈。督导式学习提供完整资料，强化学习给反馈（如两次答案，有没有比上次更好）&lt;/p&gt;&#xA;&lt;p&gt;【注】：模型要有一定程度的能力才适合进入强化学习。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Alignment(对齐)&lt;/strong&gt;：督导式学习 + 强化学习&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;学习reward model&lt;/p&gt;&#xA;&lt;p&gt;reward model：模仿人类的偏好&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用reward model进行学习&lt;/p&gt;&#xA;&lt;p&gt;模型只需要向reward model学习&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;GPT-4: 可以看图+引导&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;如何激发gpt的能力？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;把需求说清楚&lt;/li&gt;&#xA;&lt;li&gt;提供咨询&lt;/li&gt;&#xA;&lt;li&gt;提供范例&lt;/li&gt;&#xA;&lt;li&gt;鼓励gpt想一想&lt;/li&gt;&#xA;&lt;li&gt;训练generator&lt;/li&gt;&#xA;&lt;li&gt;上传资料&lt;/li&gt;&#xA;&lt;li&gt;使用其它工具&lt;/li&gt;&#xA;&lt;li&gt;大任务拆解成小任务&lt;/li&gt;&#xA;&lt;li&gt;gpt会反省&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;可以做什么？&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;prompt engineering&lt;/li&gt;&#xA;&lt;li&gt;训练自己的模型（如调整LLaMA参数），困难&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;大型语言模型训练过程&#34;&gt;大型语言模型训练过程&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/7e6521a3-d2cf-42bc-8550-aacc3027b83f/%E6%88%AA%E5%B1%8F2025-01-06_00.37.19.png&#34; alt=&#34;截屏2025-01-06 00.37.19.png&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;自我学习阶段&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;调整超参数&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;训练成果，但测试失败：找到多样数据&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;找到合适的初始参数：随机/ 先验知识&lt;/p&gt;&#xA;&lt;p&gt;先验知识：爬网络资料+资料清理(训练资料品质分类器/除重)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;人类指导阶段&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>VAE</title>
      <link>http://localhost:1313/post/vae/</link>
      <pubDate>Sun, 29 Dec 2024 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/vae/</guid>
      <description>&lt;h3 id=&#34;key-concepts-of-vaes&#34;&gt;Key Concepts of VAEs&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Latent Variables&lt;/strong&gt;: VAEs assume that the observed data (e.g., images) is generated from a set of unobserved, lower-dimensional latent variables.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Probabilistic Framework&lt;/strong&gt;: VAEs are based on &lt;strong&gt;variational inference&lt;/strong&gt;, a method for approximating complex probability distributions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder-Decoder Architecture&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: Maps input data x&lt;em&gt;x&lt;/em&gt; to a distribution over latent variables z&lt;em&gt;z&lt;/em&gt;. This is often parameterized as a Gaussian distribution with mean μ&lt;em&gt;μ&lt;/em&gt; and variance σ2&lt;em&gt;σ&lt;/em&gt;2.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: Maps latent variables z&lt;em&gt;z&lt;/em&gt; back to the data space, generating new samples x′&lt;em&gt;x&lt;/em&gt;′ that resemble the original data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;普通自动编码器&#34;&gt;普通自动编码器&lt;/h2&gt;&#xA;&lt;p&gt;目标：将高维度数据压缩成较小的表示&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
