<!DOCTYPE html>
<html lang="en-US">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>HomePage</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.140.2">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    
    
      <link href="/tags/index.xml" rel="alternate" type="application/rss+xml" title="HomePage" />
      <link href="/tags/index.xml" rel="feed" type="application/rss+xml" title="HomePage" />
      
    

    
      <link rel="canonical" href="http://localhost:1313/tags/">
    

    <meta property="og:url" content="http://localhost:1313/tags/">
  <meta property="og:site_name" content="HomePage">
  <meta property="og:title" content="Tags">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="website">

  <meta itemprop="name" content="Tags">
  <meta itemprop="datePublished" content="2025-02-09T11:00:59-04:00">
  <meta itemprop="dateModified" content="2025-02-09T11:00:59-04:00">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Tags">

	
  </head><body class="ma0 avenir bg-near-white development">

    

  
  
  <header class="cover bg-top" style="background-image: url('http://localhost:1313/images/taytay.jpg');">
    
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        HomePage
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About ME page">
              About ME
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Articles page">
              Articles
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"><a href="https://www.facebook.com/patrick.kollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition facebook link dib z-999 pt3 pt0-l mr1"
        title="follow on Facebook - Opens in a new window"
        aria-label="follow on Facebook - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
            
          </span></a><a href="https://bsky.app/profile/kollitsch.dev" target="_blank" rel="noopener"
        class="ananke-social-link link-transition bluesky link dib z-999 pt3 pt0-l mr1"
        title="follow on Bluesky - Opens in a new window"
        aria-label="follow on Bluesky - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            
          </span></a><a href="http://linkedin.com/in/patrickkollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition linkedin link dib z-999 pt3 pt0-l mr1"
        title="follow on LinkedIn - Opens in a new window"
        aria-label="follow on LinkedIn - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
            
          </span></a></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv4 pv6-l ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw2 white-90 mb0 lh-title">
          Tags
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
    
  <article class="cf pa3 pa4-m pa4-l">
    <div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray">
      
    </div>
  </article>
  <div class="mw8 center">
    <section class="ph4">
      
        <h2 class="f1">
          <a href="/tags/cv/" class="link blue hover-black">
            Tag: CV
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 9, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/mllm/" class="link black dim">
        MLLM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="1-cvnlp基础">1. CV/NLP基础</h1>
<h3 id="一计算机视觉cv中的特征提取"><strong>一、计算机视觉（CV）中的特征提取</strong></h3>
<h4 id="1-传统方法手工设计特征"><strong>1. 传统方法（手工设计特征）</strong></h4>
<p>在深度学习兴起之前，CV主要依赖手工设计的特征，这些特征需要领域专家设计，能捕捉图像中的特定模式。</p>
<h5 id="1-低级视觉特征"><strong>(1) 低级视觉特征</strong></h5>
<ul>
<li><strong>颜色特征</strong>：
<ul>
<li><strong>颜色直方图</strong>：统计图像中不同颜色值的分布，简单但缺乏空间信息。</li>
<li><strong>颜色矩</strong>：通过数学矩（均值、方差、偏度等）描述颜色分布。</li>
</ul>
</li>
<li><strong>纹理特征</strong>：
<ul>
<li><strong>灰度共生矩阵（GLCM）</strong>：通过统计像素对的灰度值分布，提取纹理粗糙度、对比度等。</li>
<li><strong>Gabor滤波器</strong>：模拟人类视觉系统，通过不同方向和尺度的滤波器提取纹理。</li>
</ul>
</li>
<li><strong>边缘与形状特征</strong>：
<ul>
<li><strong>Canny边缘检测</strong>：提取图像中的边缘信息。</li>
<li><strong>HOG（方向梯度直方图）</strong>：统计局部区域的梯度方向分布，广泛用于目标检测（如行人检测）。</li>
</ul>
</li>
</ul>
<h5 id="2-中级语义特征"><strong>(2) 中级语义特征</strong></h5>
<ul>
<li><strong>SIFT（尺度不变特征变换）</strong>：
<ul>
<li>通过检测关键点并生成局部特征描述子，具有尺度、旋转和光照不变性。</li>
<li>用于图像匹配、目标识别（如全景图像拼接）。</li>
</ul>
</li>
<li><strong>SURF（加速鲁棒特征）</strong>：
<ul>
<li>SIFT的加速版本，通过积分图像和简化描述子计算。</li>
</ul>
</li>
<li><strong>LBP（局部二值模式）</strong>：
<ul>
<li>通过比较像素与其邻域的灰度值生成二进制模式，用于纹理分类和人脸识别。</li>
</ul>
</li>
</ul>
<h5 id="3-局限性"><strong>(3) 局限性</strong>：</h5>
<ul>
<li>手工特征依赖专家经验，泛化能力有限。</li>
<li>难以捕捉高层语义信息（如物体类别、场景理解）。</li>
</ul>
<h4 id="2-深度学习方法自动学习特征"><strong>2. 深度学习方法（自动学习特征）</strong></h4>
<p>深度学习通过神经网络自动学习图像特征，显著提升了CV任务的性能。</p>
<h5 id="1-卷积神经网络cnn"><strong>(1) 卷积神经网络（CNN）</strong></h5>
<ul>
<li><strong>核心思想</strong>：
<ul>
<li>通过卷积层提取局部特征，池化层降低维度，全连接层进行分类。</li>
</ul>
</li>
<li><strong>经典模型</strong>：
<ul>
<li><strong>LeNet-5</strong>（1998）：首个成功应用于手写数字识别的CNN。</li>
<li><strong>AlexNet</strong>（2012）：引入ReLU和Dropout，大幅提升ImageNet分类精度。</li>
<li><strong>VGGNet</strong>（2014）：通过堆叠3x3卷积层构建深层网络。</li>
<li><strong>ResNet</strong>（2015）：提出残差连接，解决深层网络梯度消失问题。</li>
</ul>
</li>
</ul>
<h5 id="2-视觉transformervit"><strong>(2) 视觉Transformer（ViT）</strong></h5>
<ul>
<li><strong>核心思想</strong>：
<ul>
<li>将图像分割为小块（patches），通过自注意力机制建模全局关系。</li>
</ul>
</li>
<li><strong>优势</strong>：
<ul>
<li>无需局部卷积先验，直接建模长距离依赖。</li>
<li>在ImageNet等任务上超越传统CNN。</li>
</ul>
</li>
</ul>
<h5 id="3-特征提取流程"><strong>(3) 特征提取流程</strong>：</h5>
<ol>
<li><strong>低级特征</strong>：边缘、纹理（浅层卷积层）。</li>
<li><strong>中级特征</strong>：物体部件（中层卷积层）。</li>
<li><strong>高级特征</strong>：语义类别（深层卷积层或Transformer）。</li>
</ol>
<h3 id="二自然语言处理nlp中的特征提取"><strong>二、自然语言处理（NLP）中的特征提取</strong></h3>
<h4 id="1-传统方法基于统计与规则"><strong>1. 传统方法（基于统计与规则）</strong></h4>
<p>传统NLP依赖词法、句法和统计特征，通常需要手动设计。</p>
<h5 id="1-词袋模型bag-of-words-bow"><strong>(1) 词袋模型（Bag of Words, BoW）</strong></h5>
<ul>
<li>将文本表示为词汇表中单词的出现频率。</li>
<li><strong>缺点</strong>：忽略词序和上下文信息。</li>
</ul>
<h5 id="2-tf-idf词频-逆文档频率"><strong>(2) TF-IDF（词频-逆文档频率）</strong></h5>
<ul>
<li>衡量单词在文档中的重要性（TF-IDF值 = 词频 × 逆文档频率）。</li>
<li>用于文本分类和信息检索。</li>
</ul>
<h5 id="3-n-gram模型"><strong>(3) N-gram模型</strong></h5>
<ul>
<li>统计连续N个词的组合频率（如Bi-gram、Tri-gram）。</li>
<li>捕捉局部词序信息，但维度爆炸问题严重。</li>
</ul>
<h5 id="4-词嵌入预训练词向量"><strong>(4) 词嵌入（预训练词向量）</strong></h5>
<ul>
<li><strong>Word2Vec</strong>（2013）：
<ul>
<li>通过Skip-Gram或CBOW模型，将词映射为低维稠密向量。</li>
<li>相似词在向量空间中距离相近（如“国王-王后≈男人-女人”）。</li>
</ul>
</li>
<li><strong>GloVe</strong>（2014）：
<ul>
<li>基于全局词共现矩阵，结合统计信息和词向量学习。</li>
</ul>
</li>
</ul>
<h5 id="5-局限性"><strong>(5) 局限性</strong>：</h5>
<ul>
<li>无法建模长距离上下文依赖。</li>
<li>词向量静态，无法处理一词多义。</li>
</ul>
<h4 id="2-深度学习方法上下文感知特征"><strong>2. 深度学习方法（上下文感知特征）</strong></h4>
<p>深度学习通过神经网络自动捕捉文本的语义和上下文信息。</p>
    </div>
  <a href="/post/mllm/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/llm/" class="link blue hover-black">
            Tag: LLM
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 9, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/mllm/" class="link black dim">
        MLLM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="1-cvnlp基础">1. CV/NLP基础</h1>
<h3 id="一计算机视觉cv中的特征提取"><strong>一、计算机视觉（CV）中的特征提取</strong></h3>
<h4 id="1-传统方法手工设计特征"><strong>1. 传统方法（手工设计特征）</strong></h4>
<p>在深度学习兴起之前，CV主要依赖手工设计的特征，这些特征需要领域专家设计，能捕捉图像中的特定模式。</p>
<h5 id="1-低级视觉特征"><strong>(1) 低级视觉特征</strong></h5>
<ul>
<li><strong>颜色特征</strong>：
<ul>
<li><strong>颜色直方图</strong>：统计图像中不同颜色值的分布，简单但缺乏空间信息。</li>
<li><strong>颜色矩</strong>：通过数学矩（均值、方差、偏度等）描述颜色分布。</li>
</ul>
</li>
<li><strong>纹理特征</strong>：
<ul>
<li><strong>灰度共生矩阵（GLCM）</strong>：通过统计像素对的灰度值分布，提取纹理粗糙度、对比度等。</li>
<li><strong>Gabor滤波器</strong>：模拟人类视觉系统，通过不同方向和尺度的滤波器提取纹理。</li>
</ul>
</li>
<li><strong>边缘与形状特征</strong>：
<ul>
<li><strong>Canny边缘检测</strong>：提取图像中的边缘信息。</li>
<li><strong>HOG（方向梯度直方图）</strong>：统计局部区域的梯度方向分布，广泛用于目标检测（如行人检测）。</li>
</ul>
</li>
</ul>
<h5 id="2-中级语义特征"><strong>(2) 中级语义特征</strong></h5>
<ul>
<li><strong>SIFT（尺度不变特征变换）</strong>：
<ul>
<li>通过检测关键点并生成局部特征描述子，具有尺度、旋转和光照不变性。</li>
<li>用于图像匹配、目标识别（如全景图像拼接）。</li>
</ul>
</li>
<li><strong>SURF（加速鲁棒特征）</strong>：
<ul>
<li>SIFT的加速版本，通过积分图像和简化描述子计算。</li>
</ul>
</li>
<li><strong>LBP（局部二值模式）</strong>：
<ul>
<li>通过比较像素与其邻域的灰度值生成二进制模式，用于纹理分类和人脸识别。</li>
</ul>
</li>
</ul>
<h5 id="3-局限性"><strong>(3) 局限性</strong>：</h5>
<ul>
<li>手工特征依赖专家经验，泛化能力有限。</li>
<li>难以捕捉高层语义信息（如物体类别、场景理解）。</li>
</ul>
<h4 id="2-深度学习方法自动学习特征"><strong>2. 深度学习方法（自动学习特征）</strong></h4>
<p>深度学习通过神经网络自动学习图像特征，显著提升了CV任务的性能。</p>
<h5 id="1-卷积神经网络cnn"><strong>(1) 卷积神经网络（CNN）</strong></h5>
<ul>
<li><strong>核心思想</strong>：
<ul>
<li>通过卷积层提取局部特征，池化层降低维度，全连接层进行分类。</li>
</ul>
</li>
<li><strong>经典模型</strong>：
<ul>
<li><strong>LeNet-5</strong>（1998）：首个成功应用于手写数字识别的CNN。</li>
<li><strong>AlexNet</strong>（2012）：引入ReLU和Dropout，大幅提升ImageNet分类精度。</li>
<li><strong>VGGNet</strong>（2014）：通过堆叠3x3卷积层构建深层网络。</li>
<li><strong>ResNet</strong>（2015）：提出残差连接，解决深层网络梯度消失问题。</li>
</ul>
</li>
</ul>
<h5 id="2-视觉transformervit"><strong>(2) 视觉Transformer（ViT）</strong></h5>
<ul>
<li><strong>核心思想</strong>：
<ul>
<li>将图像分割为小块（patches），通过自注意力机制建模全局关系。</li>
</ul>
</li>
<li><strong>优势</strong>：
<ul>
<li>无需局部卷积先验，直接建模长距离依赖。</li>
<li>在ImageNet等任务上超越传统CNN。</li>
</ul>
</li>
</ul>
<h5 id="3-特征提取流程"><strong>(3) 特征提取流程</strong>：</h5>
<ol>
<li><strong>低级特征</strong>：边缘、纹理（浅层卷积层）。</li>
<li><strong>中级特征</strong>：物体部件（中层卷积层）。</li>
<li><strong>高级特征</strong>：语义类别（深层卷积层或Transformer）。</li>
</ol>
<h3 id="二自然语言处理nlp中的特征提取"><strong>二、自然语言处理（NLP）中的特征提取</strong></h3>
<h4 id="1-传统方法基于统计与规则"><strong>1. 传统方法（基于统计与规则）</strong></h4>
<p>传统NLP依赖词法、句法和统计特征，通常需要手动设计。</p>
<h5 id="1-词袋模型bag-of-words-bow"><strong>(1) 词袋模型（Bag of Words, BoW）</strong></h5>
<ul>
<li>将文本表示为词汇表中单词的出现频率。</li>
<li><strong>缺点</strong>：忽略词序和上下文信息。</li>
</ul>
<h5 id="2-tf-idf词频-逆文档频率"><strong>(2) TF-IDF（词频-逆文档频率）</strong></h5>
<ul>
<li>衡量单词在文档中的重要性（TF-IDF值 = 词频 × 逆文档频率）。</li>
<li>用于文本分类和信息检索。</li>
</ul>
<h5 id="3-n-gram模型"><strong>(3) N-gram模型</strong></h5>
<ul>
<li>统计连续N个词的组合频率（如Bi-gram、Tri-gram）。</li>
<li>捕捉局部词序信息，但维度爆炸问题严重。</li>
</ul>
<h5 id="4-词嵌入预训练词向量"><strong>(4) 词嵌入（预训练词向量）</strong></h5>
<ul>
<li><strong>Word2Vec</strong>（2013）：
<ul>
<li>通过Skip-Gram或CBOW模型，将词映射为低维稠密向量。</li>
<li>相似词在向量空间中距离相近（如“国王-王后≈男人-女人”）。</li>
</ul>
</li>
<li><strong>GloVe</strong>（2014）：
<ul>
<li>基于全局词共现矩阵，结合统计信息和词向量学习。</li>
</ul>
</li>
</ul>
<h5 id="5-局限性"><strong>(5) 局限性</strong>：</h5>
<ul>
<li>无法建模长距离上下文依赖。</li>
<li>词向量静态，无法处理一词多义。</li>
</ul>
<h4 id="2-深度学习方法上下文感知特征"><strong>2. 深度学习方法（上下文感知特征）</strong></h4>
<p>深度学习通过神经网络自动捕捉文本的语义和上下文信息。</p>
    </div>
  <a href="/post/mllm/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 8, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/ai-agent/" class="link black dim">
        AI Agent
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="1-ai-agent认知与原理分析">1. AI agent认知与原理分析</h1>
<h1 id="2-agent技术框架">2. agent技术框架</h1>
<h1 id="3-agent策略分析与parer解读">3. agent策略分析与Parer解读</h1>
<h1 id="4-单agent系统与多agent系统">4. 单Agent系统与多Agent系统</h1>
<h1 id="5-个性社agent应用定制全流程详讲">5. 个性社Agent应用定制全流程详讲</h1>
    </div>
  <a href="/post/ai-agent/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/nlp/" class="link blue hover-black">
            Tag: NLP
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 9, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/mllm/" class="link black dim">
        MLLM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="1-cvnlp基础">1. CV/NLP基础</h1>
<h3 id="一计算机视觉cv中的特征提取"><strong>一、计算机视觉（CV）中的特征提取</strong></h3>
<h4 id="1-传统方法手工设计特征"><strong>1. 传统方法（手工设计特征）</strong></h4>
<p>在深度学习兴起之前，CV主要依赖手工设计的特征，这些特征需要领域专家设计，能捕捉图像中的特定模式。</p>
<h5 id="1-低级视觉特征"><strong>(1) 低级视觉特征</strong></h5>
<ul>
<li><strong>颜色特征</strong>：
<ul>
<li><strong>颜色直方图</strong>：统计图像中不同颜色值的分布，简单但缺乏空间信息。</li>
<li><strong>颜色矩</strong>：通过数学矩（均值、方差、偏度等）描述颜色分布。</li>
</ul>
</li>
<li><strong>纹理特征</strong>：
<ul>
<li><strong>灰度共生矩阵（GLCM）</strong>：通过统计像素对的灰度值分布，提取纹理粗糙度、对比度等。</li>
<li><strong>Gabor滤波器</strong>：模拟人类视觉系统，通过不同方向和尺度的滤波器提取纹理。</li>
</ul>
</li>
<li><strong>边缘与形状特征</strong>：
<ul>
<li><strong>Canny边缘检测</strong>：提取图像中的边缘信息。</li>
<li><strong>HOG（方向梯度直方图）</strong>：统计局部区域的梯度方向分布，广泛用于目标检测（如行人检测）。</li>
</ul>
</li>
</ul>
<h5 id="2-中级语义特征"><strong>(2) 中级语义特征</strong></h5>
<ul>
<li><strong>SIFT（尺度不变特征变换）</strong>：
<ul>
<li>通过检测关键点并生成局部特征描述子，具有尺度、旋转和光照不变性。</li>
<li>用于图像匹配、目标识别（如全景图像拼接）。</li>
</ul>
</li>
<li><strong>SURF（加速鲁棒特征）</strong>：
<ul>
<li>SIFT的加速版本，通过积分图像和简化描述子计算。</li>
</ul>
</li>
<li><strong>LBP（局部二值模式）</strong>：
<ul>
<li>通过比较像素与其邻域的灰度值生成二进制模式，用于纹理分类和人脸识别。</li>
</ul>
</li>
</ul>
<h5 id="3-局限性"><strong>(3) 局限性</strong>：</h5>
<ul>
<li>手工特征依赖专家经验，泛化能力有限。</li>
<li>难以捕捉高层语义信息（如物体类别、场景理解）。</li>
</ul>
<h4 id="2-深度学习方法自动学习特征"><strong>2. 深度学习方法（自动学习特征）</strong></h4>
<p>深度学习通过神经网络自动学习图像特征，显著提升了CV任务的性能。</p>
<h5 id="1-卷积神经网络cnn"><strong>(1) 卷积神经网络（CNN）</strong></h5>
<ul>
<li><strong>核心思想</strong>：
<ul>
<li>通过卷积层提取局部特征，池化层降低维度，全连接层进行分类。</li>
</ul>
</li>
<li><strong>经典模型</strong>：
<ul>
<li><strong>LeNet-5</strong>（1998）：首个成功应用于手写数字识别的CNN。</li>
<li><strong>AlexNet</strong>（2012）：引入ReLU和Dropout，大幅提升ImageNet分类精度。</li>
<li><strong>VGGNet</strong>（2014）：通过堆叠3x3卷积层构建深层网络。</li>
<li><strong>ResNet</strong>（2015）：提出残差连接，解决深层网络梯度消失问题。</li>
</ul>
</li>
</ul>
<h5 id="2-视觉transformervit"><strong>(2) 视觉Transformer（ViT）</strong></h5>
<ul>
<li><strong>核心思想</strong>：
<ul>
<li>将图像分割为小块（patches），通过自注意力机制建模全局关系。</li>
</ul>
</li>
<li><strong>优势</strong>：
<ul>
<li>无需局部卷积先验，直接建模长距离依赖。</li>
<li>在ImageNet等任务上超越传统CNN。</li>
</ul>
</li>
</ul>
<h5 id="3-特征提取流程"><strong>(3) 特征提取流程</strong>：</h5>
<ol>
<li><strong>低级特征</strong>：边缘、纹理（浅层卷积层）。</li>
<li><strong>中级特征</strong>：物体部件（中层卷积层）。</li>
<li><strong>高级特征</strong>：语义类别（深层卷积层或Transformer）。</li>
</ol>
<h3 id="二自然语言处理nlp中的特征提取"><strong>二、自然语言处理（NLP）中的特征提取</strong></h3>
<h4 id="1-传统方法基于统计与规则"><strong>1. 传统方法（基于统计与规则）</strong></h4>
<p>传统NLP依赖词法、句法和统计特征，通常需要手动设计。</p>
<h5 id="1-词袋模型bag-of-words-bow"><strong>(1) 词袋模型（Bag of Words, BoW）</strong></h5>
<ul>
<li>将文本表示为词汇表中单词的出现频率。</li>
<li><strong>缺点</strong>：忽略词序和上下文信息。</li>
</ul>
<h5 id="2-tf-idf词频-逆文档频率"><strong>(2) TF-IDF（词频-逆文档频率）</strong></h5>
<ul>
<li>衡量单词在文档中的重要性（TF-IDF值 = 词频 × 逆文档频率）。</li>
<li>用于文本分类和信息检索。</li>
</ul>
<h5 id="3-n-gram模型"><strong>(3) N-gram模型</strong></h5>
<ul>
<li>统计连续N个词的组合频率（如Bi-gram、Tri-gram）。</li>
<li>捕捉局部词序信息，但维度爆炸问题严重。</li>
</ul>
<h5 id="4-词嵌入预训练词向量"><strong>(4) 词嵌入（预训练词向量）</strong></h5>
<ul>
<li><strong>Word2Vec</strong>（2013）：
<ul>
<li>通过Skip-Gram或CBOW模型，将词映射为低维稠密向量。</li>
<li>相似词在向量空间中距离相近（如“国王-王后≈男人-女人”）。</li>
</ul>
</li>
<li><strong>GloVe</strong>（2014）：
<ul>
<li>基于全局词共现矩阵，结合统计信息和词向量学习。</li>
</ul>
</li>
</ul>
<h5 id="5-局限性"><strong>(5) 局限性</strong>：</h5>
<ul>
<li>无法建模长距离上下文依赖。</li>
<li>词向量静态，无法处理一词多义。</li>
</ul>
<h4 id="2-深度学习方法上下文感知特征"><strong>2. 深度学习方法（上下文感知特征）</strong></h4>
<p>深度学习通过神经网络自动捕捉文本的语义和上下文信息。</p>
    </div>
  <a href="/post/mllm/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/algorithm/" class="link blue hover-black">
            Tag: Algorithm
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 6, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="link black dim">
        数据结构实现
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="数组链表">数组链表</h1>
<h2 id="1-动态数组">1. 动态数组</h2>
<p><strong>动态数组底层还是静态数组，只是自动帮我们进行数组空间的扩缩容，并把增删查改操作进行了封装，让我们使用起来更方便而已</strong>。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c++" data-lang="c++"><span style="display:flex;"><span><span style="color:#75715e">// 创建动态数组
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 不用显式指定数组大小，它会根据实际存储的元素数量自动扩缩容
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>ArrayList<span style="color:#f92672">&lt;</span>Integer<span style="color:#f92672">&gt;</span> arr <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ArrayList<span style="color:#f92672">&lt;&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">10</span>; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// 在末尾追加元素，时间复杂度 O(1)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    arr.add(i);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 在中间插入元素，时间复杂度 O(N)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 在索引 2 的位置插入元素 666
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>arr.add(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">666</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 在头部插入元素，时间复杂度 O(N)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>arr.add(<span style="color:#ae81ff">0</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 删除末尾元素，时间复杂度 O(1)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>arr.remove(arr.size() <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 删除中间元素，时间复杂度 O(N)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 删除索引 2 的元素
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>arr.remove(<span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 根据索引查询元素，时间复杂度 O(1)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> a <span style="color:#f92672">=</span> arr.get(<span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 根据索引修改元素，时间复杂度 O(1)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>arr.set(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">100</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 根据元素值查找索引，时间复杂度 O(N)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> index <span style="color:#f92672">=</span> arr.indexOf(<span style="color:#ae81ff">666</span>);
</span></span></code></pre></div><h2 id="2-链表">2. 链表</h2>
<p>在实际的编程语言中，我们使用的链表节点定义如下：</p>
    </div>
  <a href="/post/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 5, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/c&#43;&#43;%E8%AF%AD%E6%B3%95/" class="link black dim">
        c&#43;&#43;语法
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p>在 C++ 中，<code>using namespace std;</code>指令允许用户使用 std 命名空间中的所有标识符，而无需在它们前面加上<code> std::</code>。</p>
<h3 id="标准输出">标准输出</h3>
<p>C++ 的标准输出是 <code>cout</code>，用 <code>&lt;&lt;</code> 运算符把需要打印的内容传递给 <code>cout</code>，<code>endl</code> 是换行符。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c++" data-lang="c++"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> a <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 输出：10
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> a <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 可以串联输出
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 输出：Hello, World!
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Hello&#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;World!&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>string s <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;abc&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 输出：abc 10
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> s <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> a <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span></code></pre></div><h3 id="动态数组-vector">动态数组 <code>vector</code></h3>
<ol>
<li>
<p><code>vector</code> 的初始化方法如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c++" data-lang="c++"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;vector&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">using</span> <span style="color:#66d9ef">namespace</span> std;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> n <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span>, m <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 初始化一个 int 型的空数组 nums
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> nums;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 初始化一个大小为 n 的数组 nums，数组中的值默认都为 0
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> nums(n);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 初始化一个元素为 1, 3, 5 的数组 nums
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> nums{<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 初始化一个大小为 n 的数组 nums，其值全都为 2
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> nums(n, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 初始化一个二维 int 数组 dp
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector<span style="color:#f92672">&lt;</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;&gt;</span> dp;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 初始化一个大小为 m * n 的布尔数组 dp，
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 其中的值都初始化为 true
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector<span style="color:#f92672">&lt;</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">bool</span><span style="color:#f92672">&gt;&gt;</span> dp(m, vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">bool</span><span style="color:#f92672">&gt;</span>(n, true));
</span></span></code></pre></div></li>
<li>
<p><code>vector</code> 的常用操作：</p>
    </div>
  <a href="/post/c&#43;&#43;%E8%AF%AD%E6%B3%95/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 4, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/%E6%8E%92%E5%BA%8F/" class="link black dim">
        基础算法
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <ul>
<li><strong>主要思想</strong></li>
<li><strong>代码模版</strong>
<ul>
<li><strong>背过：快速默写，调试通过</strong>
<ul>
<li>先看模版思想 —— 模版已为我们考虑好了所有边界情况</li>
<li>默写一遍（用题目）</li>
</ul>
</li>
<li><strong>提高熟练度</strong>
<ul>
<li>一道题目重复3-5次</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="一排序">一、排序</h1>
<h3 id="1-快速排序">1. 快速排序</h3>
<ol>
<li>
<p>核心思想 —— 分治</p>
<ol>
<li>确定分界点x</li>
<li><strong>调整区间</strong></li>
<li>递归处理左右两段</li>
</ol>
</li>
<li>
<p><strong>调整区间的暴力做法</strong>：选定x，开a,b两数组，遍历q，小于x放a，大于x放b。</p>
</li>
<li>
<p><strong>优雅做法</strong>：用两个指针i、j，分别指向第一和最后一个数，两指针向中间移动，使得i左小于x，j右大于x；否则交换i、所指的数。</p>
</li>
</ol>
<h3 id="2-归并排序">2. 归并排序</h3>
<h1 id="二二分">二、二分</h1>
    </div>
  <a href="/post/%E6%8E%92%E5%BA%8F/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 25, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/hash/" class="link black dim">
        hash map
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p><code>UT_hash_handle hh</code> 是 <code>uthash</code> 库中的一个关键结构体，用于实现哈希表。</p>
<h3 id="1-ut_hash_handle-hh-的作用">1. <code>UT_hash_handle hh</code> 的作用</h3>
<p><code>UT_hash_handle hh</code> 是哈希表中每个元素必须包含的结构体，用于存储哈希表的内部信息（如哈希值、链表指针等）。<code>uthash</code> 通过这个结构体来管理哈希表中的元素。</p>
<h3 id="2-使用方法">2. 使用方法</h3>
<p>在使用 <code>uthash</code> 时，通常会在自定义的结构体中包含 <code>UT_hash_handle hh</code>，并通过宏操作来管理哈希表。</p>
<h4 id="示例代码">示例代码</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&#34;uthash.h&#34;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 自定义结构体
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">struct</span> my_struct {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> id;                    <span style="color:#75715e">// 键值
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">char</span> name[<span style="color:#ae81ff">10</span>];             <span style="color:#75715e">// 数据
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    UT_hash_handle hh;         <span style="color:#75715e">// 必须包含的哈希句柄
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 全局哈希表指针
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>users <span style="color:#f92672">=</span> NULL;
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// 添加用户到哈希表
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">add_user</span>(<span style="color:#66d9ef">int</span> user_id, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>name) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>s;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// 检查是否已存在相同键值的元素
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">HASH_FIND_INT</span>(users, <span style="color:#f92672">&amp;</span>user_id, s);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (s <span style="color:#f92672">==</span> NULL) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// 不存在则创建新元素
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        s <span style="color:#f92672">=</span> (<span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>)<span style="color:#a6e22e">malloc</span>(<span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">struct</span> my_struct));
</span></span><span style="display:flex;"><span>        s<span style="color:#f92672">-&gt;</span>id <span style="color:#f92672">=</span> user_id;
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">HASH_ADD_INT</span>(users, id, s);  <span style="color:#75715e">// 添加到哈希表
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">strcpy</span>(s<span style="color:#f92672">-&gt;</span>name, name);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// 根据用户 ID 查找用户
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span><span style="color:#a6e22e">find_user</span>(<span style="color:#66d9ef">int</span> user_id) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>s;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// 查找元素
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">HASH_FIND_INT</span>(users, <span style="color:#f92672">&amp;</span>user_id, s);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> s;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// 删除用户
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">delete_user</span>(<span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>user) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// 删除元素
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">HASH_DEL</span>(users, user);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">free</span>(user);  <span style="color:#75715e">// 释放内存
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// 打印哈希表中的所有用户
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">print_users</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>s;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// 遍历哈希表
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span> (s <span style="color:#f92672">=</span> users; s <span style="color:#f92672">!=</span> NULL; s <span style="color:#f92672">=</span> (<span style="color:#66d9ef">struct</span> my_struct <span style="color:#f92672">*</span>)(s<span style="color:#f92672">-&gt;</span>hh.next)) {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">printf</span>(<span style="color:#e6db74">&#34;user id %d: name %s</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, s<span style="color:#f92672">-&gt;</span>id, s<span style="color:#f92672">-&gt;</span>name);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="3-关键点">3. 关键点</h3>
<ul>
<li><strong><code>UT_hash_handle hh</code></strong>：必须包含在自定义结构体中，用于哈希表管理。</li>
<li><strong><code>HASH_ADD_INT</code></strong>：将元素添加到哈希表，<code>INT</code> 表示键值为整数类型。</li>
<li><strong><code>HASH_FIND_INT</code></strong>：根据键值查找元素。</li>
<li><strong><code>HASH_DEL</code></strong>：从哈希表中删除元素。</li>
<li><strong>遍历哈希表</strong>：通过 <code>hh.next</code> 指针遍历哈希表中的元素。</li>
</ul>
    </div>
  <a href="/post/hash/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 22, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/algrithom/" class="link black dim">
        「持续更新」算法题笔记
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <ol>
<li>
<h3 id="两数之和">两数之和</h3>
<p><strong>题目描述</strong>：给定一个整数数组 <code>nums</code> 和一个整数目标值 <code>target</code>，请你在该数组中找出 <strong>和为目标值</strong> <em><code>target</code></em> 的那 <strong>两个</strong> 整数，并返回它们的数组下标。</p>
<p><strong>方法</strong>：找数 <code>x</code>，寻找数组中是否存在 <code>target - x</code>。</p>
<p>使用哈希表，可以将寻找 <code>target - x</code>的时间复杂度降低到从 O(N) 降低到 O(1) —— 创建一个哈希表，对于每一个 <code>x</code>，我们首先查询哈希表中是否存在 <code>target - x</code>，然后将 <code>x</code>插入到哈希表中，即可保证不会让 <code>x</code>和自己匹配。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> hashTable {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> key;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> val;
</span></span><span style="display:flex;"><span>    UT_hash_handle hh;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> hashTable<span style="color:#f92672">*</span> hashtable;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> hashTable<span style="color:#f92672">*</span> <span style="color:#a6e22e">find</span>(<span style="color:#66d9ef">int</span> ikey) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> hashTable<span style="color:#f92672">*</span> tmp;
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">HASH_FIND_INT</span>(hashtable, <span style="color:#f92672">&amp;</span>ikey, tmp);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> tmp;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">insert</span>(<span style="color:#66d9ef">int</span> ikey, <span style="color:#66d9ef">int</span> ival) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> hashTable<span style="color:#f92672">*</span> it <span style="color:#f92672">=</span> <span style="color:#a6e22e">find</span>(ikey);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (it <span style="color:#f92672">==</span> NULL) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">struct</span> hashTable<span style="color:#f92672">*</span> tmp <span style="color:#f92672">=</span> <span style="color:#a6e22e">malloc</span>(<span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">struct</span> hashTable));
</span></span><span style="display:flex;"><span>        tmp<span style="color:#f92672">-&gt;</span>key <span style="color:#f92672">=</span> ikey, tmp<span style="color:#f92672">-&gt;</span>val <span style="color:#f92672">=</span> ival;
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">HASH_ADD_INT</span>(hashtable, key, tmp);
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>        it<span style="color:#f92672">-&gt;</span>val <span style="color:#f92672">=</span> ival;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> <span style="color:#a6e22e">twoSum</span>(<span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> nums, <span style="color:#66d9ef">int</span> numsSize, <span style="color:#66d9ef">int</span> target, <span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> returnSize) {
</span></span><span style="display:flex;"><span>    hashtable <span style="color:#f92672">=</span> NULL;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> numsSize; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">struct</span> hashTable<span style="color:#f92672">*</span> it <span style="color:#f92672">=</span> <span style="color:#a6e22e">find</span>(target <span style="color:#f92672">-</span> nums[i]);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (it <span style="color:#f92672">!=</span> NULL) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> ret <span style="color:#f92672">=</span> <span style="color:#a6e22e">malloc</span>(<span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">int</span>) <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>            ret[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> it<span style="color:#f92672">-&gt;</span>val, ret[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> i;
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">*</span>returnSize <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> ret;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">insert</span>(nums[i], i);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span>returnSize <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> NULL;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
<li>
<h3 id="最大子数组和">最大子数组和</h3>
<p>给你一个整数数组 <code>nums</code> ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p>
    </div>
  <a href="/post/algrithom/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/generative-ai/" class="link blue hover-black">
            Tag: Generative AI
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 22, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/world-model/" class="link black dim">
        World Models
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="sem2">SEM2</h1>
<p><a href="https://arxiv.org/abs/2210.04017">https://arxiv.org/abs/2210.04017</a></p>
<h2 id="题目摘要解读">题目＆摘要解读</h2>
<h2 id="背景相关工作">背景&amp;相关工作</h2>
<h2 id="方法">﻿﻿方法</h2>
<h2 id="实验">实验</h2>
<h2 id="回顾总结思考">回顾、总结、思考</h2>
    </div>
  <a href="/post/world-model/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 17, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/diffusion-model/" class="link black dim">
        Diffusion Model
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="概述">概述</h1>
<h2 id="影像生成模型本质上的共同目标">影像生成模型本质上的共同目标</h2>
<p><img src="/images/DM/19.png" alt="19"></p>
<p>进一步：输入加入了文字表述</p>
<p>目标：产生的图片与真实图片越接近越好</p>
<h2 id="原理">原理</h2>
<ul>
<li>
<p><strong>Reverse Process</strong>（多次Denoise）</p>
<p><strong>reconstructing meaningful data from noise</strong> by iteratively removing noise that was added during the <strong>forward process</strong>.</p>
</li>
<li>
<p><strong>Forward Process</strong>:</p>
<p>Gradually adds noise to data over multiple steps until the data becomes pure noise.</p>
</li>
</ul>
<p><img src="/images/DM/1.png" alt="1"></p>
<ul>
<li>
<p>Denoise输入：图片 + 噪音程度</p>
<p><img src="/images/DM/2.png" alt="2"></p>
</li>
</ul>
<h3 id="denoise-model内部">Denoise Model内部</h3>
<p><img src="/images/DM/3.png" alt="3"></p>
<p><strong>Noise Predicter</strong>: 预测noise长什么样</p>
<ul>
<li>
<p>如何训练Noise Predicter？</p>
<ul>
<li>
<p>人为创造（加杂讯/Forward Process）</p>
<p><img src="/images/DM/4.png" alt="4"></p>
</li>
</ul>
</li>
</ul>
<h3 id="text-to-image"><strong>Text-to-Image</strong></h3>
<p>Laion拥有5.85B图片，可进行搜索</p>
<p>输入：图片+噪声程度+<strong>文字叙述</strong></p>
<p><img src="/images/DM/5.png" alt="5"></p>
<h3 id="算法">算法</h3>
<p><img src="/images/DM/6.png" alt="6"></p>
<ul>
<li>
<p><strong>训练</strong>：</p>
<p><img src="/images/DM/17.png" alt="17"></p>
<ol>
<li>sample一张clean image</li>
<li>sample出一个数字</li>
<li>sample出一个noise</li>
<li><strong>clean image 和 noise 做加权和得到一个有杂讯的图</strong>，然后训练noise predictor（输入有杂讯的图 和 数字；输出目标noise）</li>
</ol>
</li>
<li>
<p><strong>产生图</strong>：</p>
    </div>
  <a href="/post/diffusion-model/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 4, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/ga/" class="link black dim">
        Generative AI
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="chatgpt">ChatGPT</h1>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/ba53c8d8-3a8d-4bb9-a20f-5cd7d295a29f/%E6%88%AA%E5%B1%8F2025-01-05_23.37.32.png" alt="截屏2025-01-05 23.37.32.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/740b097c-4c79-42af-bc9b-5817abdc3521/%E6%88%AA%E5%B1%8F2025-01-04_00.25.09.png" alt="截屏2025-01-04 00.25.09.png"></p>
<ol>
<li>
<p>ChatGPT 真正做的事：文字接龙</p>
<p><strong>Autoregressive Generation</strong>：逐个生成</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/a140588c-153b-4bf3-812b-794d09b256c2/%E6%88%AA%E5%B1%8F2025-01-04_00.18.34.png" alt="截屏2025-01-04 00.18.34.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/10249f01-191e-4450-9387-201ee36c281d/247f57f5-a4f8-4859-8ce8-9664487924cd.png" alt="截屏2025-01-04 00.27.44.png"></p>
</li>
<li>
<p><strong>token</strong></p>
<p>文字接龙时可以选择的符号</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e0bc078c-68ba-4504-b3dc-2bee0739d6fa/%E6%88%AA%E5%B1%8F2025-01-04_00.29.01.png" alt="截屏2025-01-04 00.29.01.png"></p>
</li>
<li>
<p>每次回答都随机（掷骰子）</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b30b483b-47dd-4cfd-9a2d-bcd030b1b169/%E6%88%AA%E5%B1%8F2025-01-04_11.07.26.png" alt="截屏2025-01-04 11.07.26.png"></p>
</li>
<li>
<p>进化关键：<strong>自督导式学习(预训练) ➡️ 督导式学习(微调) ➡️ 强化学习</strong></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/b2ca8f91-7703-4339-ae03-089a67c3519f/%E6%88%AA%E5%B1%8F2025-01-04_23.52.07.png" alt="截屏2025-01-04 23.52.07.png"></p>
<p>有预训练，督导式学习不用大量资料。</p>
<p>强化学习提供回馈。督导式学习提供完整资料，强化学习给反馈（如两次答案，有没有比上次更好）</p>
<p>【注】：模型要有一定程度的能力才适合进入强化学习。</p>
<p><strong>Alignment(对齐)</strong>：督导式学习 + 强化学习</p>
</li>
<li>
<p><strong>强化学习</strong></p>
<ol>
<li>
<p>学习reward model</p>
<p>reward model：模仿人类的偏好</p>
</li>
<li>
<p>用reward model进行学习</p>
<p>模型只需要向reward model学习</p>
</li>
</ol>
</li>
<li>
<p><strong>GPT-4: 可以看图+引导</strong></p>
</li>
<li>
<p><strong>如何激发gpt的能力？</strong></p>
<ol>
<li>把需求说清楚</li>
<li>提供咨询</li>
<li>提供范例</li>
<li>鼓励gpt想一想</li>
<li>训练generator</li>
<li>上传资料</li>
<li>使用其它工具</li>
<li>大任务拆解成小任务</li>
<li>gpt会反省</li>
</ol>
</li>
<li>
<p>可以做什么？</p>
<ol>
<li>prompt engineering</li>
<li>训练自己的模型（如调整LLaMA参数），困难</li>
</ol>
</li>
</ol>
<h1 id="大型语言模型训练过程">大型语言模型训练过程</h1>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/7e6521a3-d2cf-42bc-8550-aacc3027b83f/%E6%88%AA%E5%B1%8F2025-01-06_00.37.19.png" alt="截屏2025-01-06 00.37.19.png"></p>
<ol>
<li>
<p>自我学习阶段</p>
<ul>
<li>
<p>调整超参数</p>
</li>
<li>
<p>训练成果，但测试失败：找到多样数据</p>
</li>
<li>
<p>找到合适的初始参数：随机/ 先验知识</p>
<p>先验知识：爬网络资料+资料清理(训练资料品质分类器/除重)</p>
</li>
</ul>
</li>
<li>
<p>人类指导阶段</p>
</li>
</ol>
    </div>
  <a href="/post/ga/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        December 29, 2024
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/vae/" class="link black dim">
        VAE
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h3 id="key-concepts-of-vaes">Key Concepts of VAEs</h3>
<ol>
<li><strong>Latent Variables</strong>: VAEs assume that the observed data (e.g., images) is generated from a set of unobserved, lower-dimensional latent variables.</li>
<li><strong>Probabilistic Framework</strong>: VAEs are based on <strong>variational inference</strong>, a method for approximating complex probability distributions.</li>
<li><strong>Encoder-Decoder Architecture</strong>:
<ul>
<li><strong>Encoder</strong>: Maps input data x<em>x</em> to a distribution over latent variables z<em>z</em>. This is often parameterized as a Gaussian distribution with mean μ<em>μ</em> and variance σ2<em>σ</em>2.</li>
<li><strong>Decoder</strong>: Maps latent variables z<em>z</em> back to the data space, generating new samples x′<em>x</em>′ that resemble the original data.</li>
</ul>
</li>
</ol>
<h2 id="普通自动编码器">普通自动编码器</h2>
<p>目标：将高维度数据压缩成较小的表示</p>
    </div>
  <a href="/post/vae/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/rl/" class="link blue hover-black">
            Tag: RL
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 22, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/world-model/" class="link black dim">
        World Models
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="sem2">SEM2</h1>
<p><a href="https://arxiv.org/abs/2210.04017">https://arxiv.org/abs/2210.04017</a></p>
<h2 id="题目摘要解读">题目＆摘要解读</h2>
<h2 id="背景相关工作">背景&amp;相关工作</h2>
<h2 id="方法">﻿﻿方法</h2>
<h2 id="实验">实验</h2>
<h2 id="回顾总结思考">回顾、总结、思考</h2>
    </div>
  <a href="/post/world-model/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 2, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/rl/" class="link black dim">
        Reinforcement Learning
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p>The core idea is <strong>trial-and-error learning</strong>: the agent takes actions, observes the outcomes, and receives <strong>rewards</strong> or <strong>penalties</strong> as feedback. Over time, the agent improves its <strong>policy</strong> (decision-making strategy) to maximize cumulative rewards.</p>
<p>不用告诉该怎么做，而是给定奖励函数，什么时候做好。</p>
<h3 id="回归">回归</h3>
<p>增加折现因子</p>
<p><img src="/images/RL/1.png" alt="1"></p>
<p><img src="/images/RL/2.png" alt="2"></p>
<h3 id="强化学习的形式化">强化学习的形式化</h3>
<p>A policy is a function $\pi(s) = a$ mapping from states to actions, that tells you what $action \space a$ to take in a given $state \space s$.</p>
<p><strong>goal</strong>: Find a $policy \space \pi$ that tells you what $action (a = (s))$ to take in every $state (s)$ so as to maximize the return.</p>
    </div>
  <a href="/post/rl/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        December 29, 2024
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/vae/" class="link black dim">
        VAE
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h3 id="key-concepts-of-vaes">Key Concepts of VAEs</h3>
<ol>
<li><strong>Latent Variables</strong>: VAEs assume that the observed data (e.g., images) is generated from a set of unobserved, lower-dimensional latent variables.</li>
<li><strong>Probabilistic Framework</strong>: VAEs are based on <strong>variational inference</strong>, a method for approximating complex probability distributions.</li>
<li><strong>Encoder-Decoder Architecture</strong>:
<ul>
<li><strong>Encoder</strong>: Maps input data x<em>x</em> to a distribution over latent variables z<em>z</em>. This is often parameterized as a Gaussian distribution with mean μ<em>μ</em> and variance σ2<em>σ</em>2.</li>
<li><strong>Decoder</strong>: Maps latent variables z<em>z</em> back to the data space, generating new samples x′<em>x</em>′ that resemble the original data.</li>
</ul>
</li>
</ol>
<h2 id="普通自动编码器">普通自动编码器</h2>
<p>目标：将高维度数据压缩成较小的表示</p>
    </div>
  <a href="/post/vae/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        December 26, 2024
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/e2e/" class="link black dim">
        End2End
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p>对于由多个阶段组成的学习系统，端到端学习捕获所有阶段，将其替代为单个神经网络。</p>
<ul>
<li>优点：
<ul>
<li>Let the data speak</li>
<li>Less hand-designing of components needed</li>
</ul>
</li>
<li>缺点：
<ul>
<li>May need large amount of data</li>
<li>Excludes potentially useful hand-designed components</li>
</ul>
</li>
</ul>
<p><strong>关键</strong>：是否有足够的数据</p>
<p><img src="/images/e2e/1.png" alt="1"></p>
    </div>
  <a href="/post/e2e/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/deep-learning/" class="link blue hover-black">
            Tag: Deep Learning
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 20, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/llm/" class="link black dim">
        LLM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p><a href="https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&amp;vd_source=80aea28698fb0235b45699fc7e6fcdac&amp;p=2">https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&vd_source=80aea28698fb0235b45699fc7e6fcdac&p=2</a></p>
<h1 id="概述">概述</h1>
<h2 id="大模型的演变">大模型的演变</h2>
<p>大模型的训练整体上分为三个阶段：</p>
<ol>
<li>
<p><strong>预训练</strong></p>
<p>在这个阶段它会学习各种不同种类的语料，学习到语言的统计规律和一般知识。</p>
<p>但是大模型在这个阶段只是学会了补全句子，却没有学会怎么样去领会人类的意图（类似成语接龙）。</p>
</li>
<li>
<p><strong>SFT（监督微调）</strong></p>
<p>在这个阶段大模型可以学习各种人类的对话语料，甚至是非常专业的垂直领域知识。</p>
<p>但是模型的回答有时候可能并不符合人类的偏好，它可能会输出一些涉黄、涉政、涉暴或者种族歧视等言论。</p>
</li>
<li>
<p><strong>RLHF（基于人类反馈的强化学习）</strong></p>
<p>在这个阶段大模型会针对同一问题进行多次回答，人类会对这些回答打分。</p>
<p>大模型会在此阶段学习到如何输出分数最高的回答，使得回答更符合人类的偏好。</p>
</li>
</ol>
<h2 id="分类">分类</h2>
<ol>
<li>
<p>大语言模型（LLM）</p>
<p>专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。</p>
</li>
<li>
<p>多模态模型</p>
<p>多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，在这些模态之间建立关联和交互。</p>
</li>
</ol>
<h2 id="工作流程">工作流程</h2>
<h3 id="分词化与词表映射">分词化与词表映射</h3>
<p>**分词化（Tokenization）**是指将段落和句子分割成更小的分词（token）的过程。</p>
<p>分词化有不同的粒度分类：</p>
<ul>
<li>﻿词粒度（Word-Level Tokenization）分词化：适用于大多数西方语言，如英语。</li>
<li>﻿字符粒度（Character-Level）分词化：中文最直接的分词方法，它是以单个汉字为单位进行分词化。</li>
<li>﻿子词粒度（Subword-Level）分词化：将单词分解成更小的单位，比如词根、词缀等。</li>
</ul>
<p>每一个token都会通过预先设置好的词表，映射为一个 token id，这是token 的“身份证”，一句话最终会被表示为一个元素为token id的列表，供计算机进行下一步处理。</p>
<h3 id="文本生成过程">文本生成过程</h3>
<p>大语言模型根据给定的文本<strong>预测下一个token</strong>。</p>
<p>大模型进行推理时，基于现有的token，根据概率最大原则预测出下一个最有可能的token，然后将该预测的token加入到输入序列中，并将更新后的输入序列继续输入大模型预测下一个token，这个过程叫做<strong>自回归</strong>。</p>
<p>直到输出特殊token（如<!-- raw HTML omitted -->，end of sentence，专门用来控制推理何时结束）或输出长度达到阈值。</p>
<h1 id="ai-agent">AI Agent</h1>
<h2 id="理论">理论</h2>
<h3 id="agent认知与原理分析">agent认知与原理分析</h3>
<p>Al Agents是基于LLM的能够自主理解、自主规划笨策、执行复杂任务的習能体。</p>
<p>Agent的设计目的是为了处理那些简单的语言模型可能无法直接解决的问题，尤其是当这些任务涉及到多个步骤或者需要外部数据源的情况。</p>
<ul>
<li>﻿LLM：接受输入、思考、输出</li>
<li>﻿人类：LLM（接受输入、思考、输出）+记忆＋工具+规划&mdash;&mdash;&gt;Agents</li>
</ul>
<h3 id="agent技术框架">agent技术框架</h3>
<h3 id="agent策略分析与parer解读">agent策略分析与Parer解读</h3>
<h3 id="单agent系统与多agent系统">单Agent系统与多Agent系统</h3>
<h3 id="个性化agent应用定制全流程详讲">个性化Agent应用定制全流程详讲</h3>
<h2 id="实践">实践</h2>
    </div>
  <a href="/post/llm/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 20, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/quantization/" class="link black dim">
        Quantization
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="概述">概述</h1>
<ul>
<li><strong>量化</strong>：Store the parameters of the model in lower precision</li>
</ul>
<ul>
<li><strong>Knowledge distillation</strong>: Train a smaller model (student) using the original model (instructor).</li>
<li><strong>Pruning</strong>: Remove connections (weights) from the model</li>
<li><strong>Application</strong>: Perform linear quantization on any model using Quanto in two lines</li>
</ul>
<h2 id="内容">内容</h2>
<ol>
<li>
<p><strong>Linear Quantization theory</strong> in detail and how to code it (<em>per channel, per tensor, per group quantization</em>)</p>
</li>
<li>
<p>Build your own 8-bit linear quantizer and apply it on real models.</p>
    </div>
  <a href="/post/quantization/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        December 27, 2024
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/cv/" class="link black dim">
        CV
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p>问题: 处理高分辨率图像时，原始图像的像素数量通常非常庞大。</p>
<p>类型：root node, decision node, leaf node
 </p>
<h2 id="1-解决方案cnn">1. 解决方案：CNN</h2>
<p>卷积神经网络通过引入卷积操作，有效地解决了大图片参数过大的问题。</p>
<ol>
<li>
<p><strong>Automatic Feature Extraction</strong></p>
<p>CNNs automatically learn hierarchical features from raw data (like images) without needing manual feature engineering.</p>
</li>
<li>
<p><strong>Parameter Sharing</strong></p>
<p>In a CNN, the same filter (or kernel) is applied across the entire image. This concept of <strong>weight sharing</strong> significantly reduces the number of parameters compared to fully connected networks, making CNNs more computationally efficient.</p>
</li>
<li>
<p><strong>分层特征学习</strong></p>
</li>
<li>
<p><strong>Translation Invariance</strong>（pooling layers）</p>
    </div>
  <a href="/post/cv/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        December 25, 2024
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/transformer/" class="link black dim">
        transformer
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p>The <strong>Transformer</strong> is a deep learning architecture introduced in the 2017 paper <em>&ldquo;Attention is All You Need&rdquo;</em> by Vaswani et al. It revolutionized natural language processing (NLP) and has since become the foundation for many state-of-the-art models, such as BERT, GPT, and T5.</p>
<h3 id="seq2seq">Seq2seq</h3>
<p>Input a sequence, output a sequence The output length is determined by model.</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e22b161f-7704-4d51-8881-70ee7e4c6dcb/%E6%88%AA%E5%B1%8F2024-12-31_15.12.59.png" alt="截屏2024-12-31 15.12.59.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/180291f8-9817-42b6-87cb-39bf0734b9ef/%E6%88%AA%E5%B1%8F2024-12-31_19.34.56.png" alt="截屏2024-12-31 19.34.56.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/31c00a57-de1e-43a9-b92a-13e3a050be48/%E6%88%AA%E5%B1%8F2024-12-31_19.35.51.png" alt="截屏2024-12-31 19.35.51.png"></p>
<h2 id="encoder">Encoder</h2>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/901263ca-4e06-4f07-a672-aab03a6a86d4/cb6d7470-a2be-4ea5-9611-1cf0859d782f.png" alt="截屏2024-12-31 15.15.42.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/3f6e614d-e0be-49d2-935e-642ebc3eaa82/%E6%88%AA%E5%B1%8F2024-12-31_15.29.37.png" alt="截屏2024-12-31 15.29.37.png"></p>
<ul>
<li>
<p><strong>细节</strong>：</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/641849c0-19ea-464e-9b96-2e7b93b1d3d5/c8331594-f0cc-4348-967f-b026b8e2b68f.png" alt="截屏2024-12-31 15.18.01.png"></p>
    </div>
  <a href="/post/transformer/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
        <h2 class="f1">
          <a href="/tags/machine-learning/" class="link blue hover-black">
            Tag: Machine Learning
          </a>
        </h2>
        
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 11, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/decision-tree/" class="link black dim">
        Decision Tree
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p>类型：root node, decision node, leaf node</p>
<h3 id="要解决的问题">要解决的问题</h3>
<ol>
<li>
<p><strong>How to choose what feature to split on at each node?</strong></p>
<p>Maximize purity (or minimize impurity)</p>
</li>
<li>
<p><strong>When do you stop splitting?</strong></p>
<ul>
<li>When a node is 100% one class</li>
<li>When splitting a node will result in the tree exceeding a maximum depth</li>
<li>When improvements in purity score are below a threshold</li>
<li>When number of examples in a node is below a threshold</li>
</ul>
</li>
</ol>
<p><img src="/images/chapter1/1.png" alt="1"></p>
<h2 id="熵和信息增益">熵和信息增益</h2>
<p><strong>Measuring purity</strong></p>
    </div>
  <a href="/post/decision-tree/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        
      
    </section>
  </div>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  HomePage 2025 
  </a>
    <div><div class="ananke-socials"><a href="https://www.facebook.com/patrick.kollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition facebook link dib z-999 pt3 pt0-l mr1"
        title="follow on Facebook - Opens in a new window"
        aria-label="follow on Facebook - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
            
          </span></a><a href="https://bsky.app/profile/kollitsch.dev" target="_blank" rel="noopener"
        class="ananke-social-link link-transition bluesky link dib z-999 pt3 pt0-l mr1"
        title="follow on Bluesky - Opens in a new window"
        aria-label="follow on Bluesky - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            
          </span></a><a href="http://linkedin.com/in/patrickkollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition linkedin link dib z-999 pt3 pt0-l mr1"
        title="follow on LinkedIn - Opens in a new window"
        aria-label="follow on LinkedIn - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
            
          </span></a></div>
</div>
  </div>
</footer>

  </body>
</html>
