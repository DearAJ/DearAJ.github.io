<!DOCTYPE html>
<html lang="en-US">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>HomePage</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.140.2">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    
    
      <link href="/tags/llm/index.xml" rel="alternate" type="application/rss+xml" title="HomePage" />
      <link href="/tags/llm/index.xml" rel="feed" type="application/rss+xml" title="HomePage" />
      
    

    
      <link rel="canonical" href="http://localhost:1313/tags/llm/">
    

    <meta property="og:url" content="http://localhost:1313/tags/llm/">
  <meta property="og:site_name" content="HomePage">
  <meta property="og:title" content="LLM">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="website">

  <meta itemprop="name" content="LLM">
  <meta itemprop="datePublished" content="2025-02-09T11:00:59-04:00">
  <meta itemprop="dateModified" content="2025-02-09T11:00:59-04:00">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="LLM">

	
  </head><body class="ma0 avenir bg-near-white development">

    

  
  
  <header class="cover bg-top" style="background-image: url('http://localhost:1313/images/taytay.jpg');">
    
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        HomePage
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About ME page">
              About ME
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Articles page">
              Articles
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"><a href="https://www.facebook.com/patrick.kollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition facebook link dib z-999 pt3 pt0-l mr1"
        title="follow on Facebook - Opens in a new window"
        aria-label="follow on Facebook - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
            
          </span></a><a href="https://bsky.app/profile/kollitsch.dev" target="_blank" rel="noopener"
        class="ananke-social-link link-transition bluesky link dib z-999 pt3 pt0-l mr1"
        title="follow on Bluesky - Opens in a new window"
        aria-label="follow on Bluesky - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            
          </span></a><a href="http://linkedin.com/in/patrickkollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition linkedin link dib z-999 pt3 pt0-l mr1"
        title="follow on LinkedIn - Opens in a new window"
        aria-label="follow on LinkedIn - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
            
          </span></a></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv4 pv6-l ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw2 white-90 mb0 lh-title">
          LLM
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
  <article class="cf pa3 pa4-m pa4-l">
    <div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray">
      <p>Below you will find pages that utilize the taxonomy term “LLM”</p>
    </div>
  </article>
  <div class="mw8 center">
    <section class="flex-ns flex-wrap justify-around mt5">
      
        <div class="relative w-100  mb4 bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 9, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/mllm/" class="link black dim">
        MLLM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="1基础">1基础</h1>
<h2 id="1-特征提取">1. 特征提取</h2>
<h3 id="一cv中的特征提取"><strong>一、CV中的特征提取</strong></h3>
<h4 id="1-传统方法手工设计特征"><strong>1. 传统方法（手工设计特征）</strong></h4>
<p><strong>(1) 低级视觉特征</strong>：颜色、纹理、 边缘与形状&hellip;</p>
<p><strong>(2) 中级语义特征</strong>：SIFT（尺度不变特征变换）、SURF（加速鲁棒特征）、LBP（局部二值模式）&hellip;</p>
<h4 id="2-深度学习方法自动学习特征"><strong>2. 深度学习方法（自动学习特征）</strong></h4>
<h5 id="1-卷积神经网络cnn"><strong>(1) 卷积神经网络（CNN）</strong></h5>
<ul>
<li>
<p><strong>核心思想</strong>：通过卷积层提取局部特征，池化层降低维度，全连接层进行分类。</p>
</li>
<li>
<p><strong>经典模型</strong>：LeNet-5、AlexNet、VGGNet、ResNet(使用残差可以训练更深的网络)&hellip;</p>
<p><img src="/images/MLLM/1.png" alt="1"></p>
</li>
</ul>
<h5 id="2-视觉transformervit"><strong>(2) 视觉Transformer（ViT）</strong></h5>
<ul>
<li><strong>核心思想</strong>：将图像分割为小块（patches），通过自注意力机制建模全局关系。</li>
<li><strong>优势</strong>：无需局部卷积先验，直接建模长距离依赖; 在ImageNet等任务上超越传统CNN。</li>
</ul>
<h3 id="二nlp中的特征提取"><strong>二、NLP中的特征提取</strong></h3>
<h4 id="1-传统方法基于统计与规则"><strong>1. 传统方法（基于统计与规则）</strong></h4>
<p><strong>(1) 词袋模型（Bag of Words, BoW）</strong>: 将文本表示为词汇表中单词的出现频率。</p>
<p><strong>(2) TF-IDF（词频-逆文档频率）</strong>: 衡量单词在文档中的重要性（TF-IDF值 = 词频 × 逆文档频率）。</p>
<p><strong>(3) N-gram模型</strong>: 统计连续N个词的组合频率（如Bi-gram、Tri-gram）。</p>
<h5 id="4-词嵌入预训练词向量"><strong>(4) 词嵌入（预训练词向量）</strong></h5>
<ul>
<li><strong>Word2Vec</strong>（2013）：
<ul>
<li>通过Skip-Gram或CBOW模型，将词映射为低维稠密向量。</li>
<li>相似词在向量空间中距离相近（如“国王-王后≈男人-女人”）。</li>
</ul>
</li>
<li><strong>GloVe</strong>（2014）：
<ul>
<li>基于全局词共现矩阵，结合统计信息和词向量学习。</li>
</ul>
</li>
</ul>
<p><strong>(5) 局限性</strong>：无法建模长距离上下文依赖; 词向量静态，无法处理一词多义。</p>
    </div>
  <a href="/post/mllm/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        February 8, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/transformer/" class="link black dim">
        transformer
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h2 id="一transformer架构">一、Transformer架构</h2>
<ul>
<li>
<p>﻿基于编码器-解码器架构来处理序列对</p>
</li>
<li>
<p>﻿跟使用注意力的seq2seq不同，Transformer是纯基于注意力</p>
<ul>
<li>
<p>seq2seq</p>
<p><img src="/images/trans/1.png" alt="1"></p>
</li>
<li>
<p>transformer</p>
<p><img src="/images/trans/2.jpg" alt="1"></p>
</li>
</ul>
</li>
</ul>
<p> </p>
<h3 id="1-多头注意力muti-head-attention">1. 多头注意力(Muti-head attention)</h3>
<ul>
<li>
<p>对同一key，value，query，希望抽取不同的信息*（类似卷积的多通道）*</p>
<ul>
<li>例如短距离关系和长距离关系</li>
</ul>
</li>
<li>
<p>多头注意力使用h个独立的注意力池化</p>
<ul>
<li>合并各个头（head） 输出得到最终输出</li>
</ul>
</li>
</ul>
<p><img src="/images/trans/3.png" alt="3"></p>
<ol>
<li>通过全连阶层，映射到一个较低的维度</li>
<li>进行多个attention</li>
<li>对每一个attention的输出，进行concat</li>
<li>再通过一个全连接，得到输出的维度</li>
</ol>
<h4 id="数学原理">数学原理</h4>
<p><img src="/images/trans/4.jpg" alt="4"></p>
    </div>
  <a href="/post/transformer/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 20, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/llm/" class="link black dim">
        LLM
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p><a href="https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&amp;vd_source=80aea28698fb0235b45699fc7e6fcdac&amp;p=2">https://www.bilibili.com/video/BV1uNk1YxEJQ?spm_id_from=333.788.videopod.episodes&vd_source=80aea28698fb0235b45699fc7e6fcdac&p=2</a></p>
<h1 id="概述">概述</h1>
<h2 id="大模型的演变">大模型的演变</h2>
<p>大模型的训练整体上分为三个阶段：</p>
<ol>
<li>
<p><strong>预训练</strong></p>
<p>在这个阶段它会学习各种不同种类的语料，学习到语言的统计规律和一般知识。</p>
<p>但是大模型在这个阶段只是学会了补全句子，却没有学会怎么样去领会人类的意图（类似成语接龙）。</p>
</li>
<li>
<p><strong>SFT（监督微调）</strong></p>
<p>在这个阶段大模型可以学习各种人类的对话语料，甚至是非常专业的垂直领域知识。</p>
<p>但是模型的回答有时候可能并不符合人类的偏好，它可能会输出一些涉黄、涉政、涉暴或者种族歧视等言论。</p>
</li>
<li>
<p><strong>RLHF（基于人类反馈的强化学习）</strong></p>
<p>在这个阶段大模型会针对同一问题进行多次回答，人类会对这些回答打分。</p>
<p>大模型会在此阶段学习到如何输出分数最高的回答，使得回答更符合人类的偏好。</p>
</li>
</ol>
<h2 id="分类">分类</h2>
<ol>
<li>
<p>大语言模型（LLM）</p>
<p>专注于自然语言处理（NLP），旨在处理语言、文章、对话等自然语言文本。</p>
</li>
<li>
<p>多模态模型</p>
<p>多模态大模型能够同时处理和理解来自不同感知通道（如文本、图像、音频、视频等）的数据，在这些模态之间建立关联和交互。</p>
</li>
</ol>
<h2 id="工作流程">工作流程</h2>
<h3 id="分词化与词表映射">分词化与词表映射</h3>
<p>分词化（Tokenization）是指将段落和句子分割成更小的分词（token）的过程。</p>
    </div>
  <a href="/post/llm/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 17, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/diffusion-model/" class="link black dim">
        Diffusion Model
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="概述">概述</h1>
<h2 id="影像生成模型本质上的共同目标">影像生成模型本质上的共同目标</h2>
<p><img src="/images/DM/19.png" alt="19"></p>
<p>进一步：输入加入了文字表述</p>
<p>目标：产生的图片与真实图片越接近越好</p>
<h2 id="原理">原理</h2>
<ul>
<li>
<p><strong>Reverse Process</strong>（多次Denoise）</p>
<p><strong>reconstructing meaningful data from noise</strong> by iteratively removing noise that was added during the <strong>forward process</strong>.</p>
</li>
<li>
<p><strong>Forward Process</strong>:</p>
<p>Gradually adds noise to data over multiple steps until the data becomes pure noise.</p>
</li>
</ul>
<p><img src="/images/DM/1.png" alt="1"></p>
<ul>
<li>
<p>Denoise输入：图片 + 噪音程度</p>
<p><img src="/images/DM/2.png" alt="2"></p>
</li>
</ul>
<h3 id="denoise-model内部">Denoise Model内部</h3>
<p><img src="/images/DM/3.png" alt="3"></p>
    </div>
  <a href="/post/diffusion-model/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        January 4, 2025
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/generativeai/" class="link black dim">
        Generative AI
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h1 id="chatgpt">ChatGPT</h1>
<p><img src="/images/GA/1.png" alt="1"></p>
<ul>
<li>
<p>G：generative</p>
</li>
<li>
<p>P：pre-trained</p>
</li>
<li>
<p>T：transformer</p>
</li>
</ul>
<p> </p>
<ol>
<li>
<p>ChatGPT 真正做的事：文字接龙</p>
<p><strong>Autoregressive Generation</strong>：逐个生成</p>
<p><img src="/images/GA/3.png" alt="3"></p>
<p><img src="/images/GA/4.png" alt="4"></p>
</li>
<li>
<p><strong>token</strong></p>
<p>文字接龙时可以选择的符号</p>
<p><img src="/images/GA/5.png" alt="5"></p>
</li>
<li>
<p>每次回答都随机（掷骰子）</p>
<p><img src="/images/GA/6.png" alt="6"></p>
</li>
</ol>
    </div>
  <a href="/post/generativeai/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
        <div class="relative w-100  mb4 bg-white">
            <div class="mb3 pa4 mid-gray overflow-hidden">
    
      <div class="f6">
        December 29, 2024
      </div>
    
    <h1 class="f3 near-black">
      <a href="/post/vae/" class="link black dim">
        VAE
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <h2 id="普通自动编码器">普通自动编码器</h2>
<p>目标：将高维度数据压缩成较小的表示</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/ad01491f-ff96-44a7-9a2f-606c66461df8/%E6%88%AA%E5%B1%8F2024-12-30_19.27.19.png" alt="截屏2024-12-30 19.27.19.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/40f99add-baee-40ad-ab9b-45dc5f312af9/%E6%88%AA%E5%B1%8F2024-12-30_19.28.31.png" alt="截屏2024-12-30 19.28.31.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/99bd3fd9-fabb-421d-bcdb-0e6d0c5be310/%E6%88%AA%E5%B1%8F2024-12-30_19.29.08.png" alt="截屏2024-12-30 19.29.08.png"></p>
<p>应用：</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/1b594f9d-d71f-4af3-b7c9-285e1dfffec6/%E6%88%AA%E5%B1%8F2024-12-30_19.29.47.png" alt="截屏2024-12-30 19.29.47.png"></p>
<h2 id="去噪自动编码器">去噪自动编码器</h2>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/a8e8568e-18b2-4281-a7af-05a627e6f5f0/%E6%88%AA%E5%B1%8F2024-12-30_19.35.42.png" alt="截屏2024-12-30 19.35.42.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/ce2c3930-ae83-40a9-b9d3-aa3f4f0246bd/%E6%88%AA%E5%B1%8F2024-12-30_19.36.58.png" alt="截屏2024-12-30 19.36.58.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/fdd726fa-7eb9-4b24-af63-f917ee593b1c/%E6%88%AA%E5%B1%8F2024-12-30_19.37.09.png" alt="截屏2024-12-30 19.37.09.png"></p>
<h2 id="变分自动编码器">变分自动编码器</h2>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/f4509f09-0920-4a7e-b5ba-74cbec294241/%E6%88%AA%E5%B1%8F2024-12-30_19.39.12.png" alt="截屏2024-12-30 19.39.12.png"></p>
<ul>
<li>
<p>损失函数</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/add2cf71-1094-4639-b2d5-699f551beb48/%E6%88%AA%E5%B1%8F2024-12-30_19.40.36.png" alt="截屏2024-12-30 19.40.36.png"></p>
</li>
</ul>
<h3 id="reparameterization-trick重参数化">Reparameterization Trick(重参数化)</h3>
<p>如何实现反向传播？</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/db9e763f-81d3-460f-81dc-b81242f41cdb/%E6%88%AA%E5%B1%8F2024-12-30_19.42.30.png" alt="截屏2024-12-30 19.42.30.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/e3fb22c3-4a30-4511-9457-4dc08d40b210/%E6%88%AA%E5%B1%8F2024-12-30_19.44.43.png" alt="截屏2024-12-30 19.44.43.png"></p>
<ul>
<li>
<p>核心代码</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/9c033e5a-8e28-4e82-ab6e-80d29dd08a20/%E6%88%AA%E5%B1%8F2024-12-30_19.45.33.png" alt="截屏2024-12-30 19.45.33.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/64564c69-b355-4559-95b2-2186d3cf9e08/%E6%88%AA%E5%B1%8F2024-12-30_19.45.42.png" alt="截屏2024-12-30 19.45.42.png"></p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/df9a2aa4-f700-4975-a5ca-f315eab2bcab/%E6%88%AA%E5%B1%8F2024-12-30_19.46.02.png" alt="截屏2024-12-30 19.46.02.png"></p>
</li>
</ul>
<h3 id="解耦变分自编码器"><strong>解耦变分自编码器</strong></h3>
<p>目的：确保潜在分布中的不同神经元互不相干，都在尝试学习输入数据中的不同内容。</p>
<ul>
<li>
<p>解决方式：增加超参数$\beta$，衡量损失函数中的KL散度。</p>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/9501fd11-c948-42ff-ba18-807ca26a11eb/%E6%88%AA%E5%B1%8F2024-12-30_22.11.49.png" alt="截屏2024-12-30 22.11.49.png"></p>
</li>
</ul>
<p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/2da5ebdb-aecd-4b19-910d-af09587de5f1/d64275f8-60ea-4cd6-862a-d8d7821c8b3d/%E6%88%AA%E5%B1%8F2024-12-30_22.18.10.png" alt="截屏2024-12-30 22.18.10.png"></p>
<p>$\beta$过小：过拟合</p>
<p>$\beta$过大：失去输入中的大量细节</p>
<p><strong>在强化学习中的作用</strong>：使Agent可以在压缩后的输入T空间上运行。</p>
    </div>
  <a href="/post/vae/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>

        </div>
      
    </section>
  </div>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  HomePage 2025 
  </a>
    <div><div class="ananke-socials"><a href="https://www.facebook.com/patrick.kollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition facebook link dib z-999 pt3 pt0-l mr1"
        title="follow on Facebook - Opens in a new window"
        aria-label="follow on Facebook - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"/></svg>
            
          </span></a><a href="https://bsky.app/profile/kollitsch.dev" target="_blank" rel="noopener"
        class="ananke-social-link link-transition bluesky link dib z-999 pt3 pt0-l mr1"
        title="follow on Bluesky - Opens in a new window"
        aria-label="follow on Bluesky - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            
          </span></a><a href="http://linkedin.com/in/patrickkollitsch" target="_blank" rel="noopener"
        class="ananke-social-link link-transition linkedin link dib z-999 pt3 pt0-l mr1"
        title="follow on LinkedIn - Opens in a new window"
        aria-label="follow on LinkedIn - Opens in a new window">
      <span class="icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc. --><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
            
          </span></a></div>
</div>
  </div>
</footer>

  </body>
</html>
