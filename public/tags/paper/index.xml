<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper on HomePage</title>
    <link>http://localhost:1313/tags/paper/</link>
    <description>Recent content in Paper on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 14 May 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/paper/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>「论文阅读」Augmented Knowledge Graph Querying leveraging LLMs</title>
      <link>http://localhost:1313/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBaugmented-knowledge-graph-querying-leveraging-llms/</link>
      <pubDate>Wed, 14 May 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBaugmented-knowledge-graph-querying-leveraging-llms/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2502.01298&#34;&gt;这篇论文&lt;/a&gt;引入了一个名为 SparqLLM 的框架，通过结合 RAG 与 LLM，实现了从自然语言到 SPARQL 查询的自动生成，以简化知识图谱的查询过程。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-introduction&#34;&gt;1 Introduction&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;：非技术员工不懂 SPARQL；KG + LLMs 无法生成精确高效的 SPARQL 查询，且存在幻觉问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;SparqLLM&lt;/strong&gt;：被设计为 RAG 框架，可自动从自然语言问题生成 SPARQL 查询，同时生成最适当的数据可视化以返回获得的结果。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/paper-SparqLLM/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：提高 KG 的准确性、可用性和可靠性，实现与语义数据的更直观和有效的交互。&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h3 id=&#34;2-related-work&#34;&gt;2 Related Work&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;自然语言接口 (NLI)&lt;/strong&gt;：将非结构化输入转换为 SPARQL 等正式查询语言，使非技术用户更容易访问基于 RDF 的知识图谱。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;LLMs&lt;/strong&gt;：利用它们处理和生成复杂文本的能力，为自动生成查询提供了一个强大的框架，减少了人工干预的需要，使非专家用户也能访问知识图谱。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于模板的方法&lt;/strong&gt;：通过为查询生成提供确定性框架来补充上述方法。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>「论文阅读」Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering</title>
      <link>http://localhost:1313/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBgenerate-on-graph-treat-llm-as-both-agent-and-kg-for-incomplete-knowledge-graph-question-answering/</link>
      <pubDate>Wed, 14 May 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBgenerate-on-graph-treat-llm-as-both-agent-and-kg-for-incomplete-knowledge-graph-question-answering/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2404.14741&#34;&gt;这篇论文&lt;/a&gt;提出了一种称为 Generate-on-Graph(GoG) 的免训练方法，它可以在探索 KG 时，生成新的事实三元组。&lt;/p&gt;&#xA;&lt;p&gt;具体来说，在不完全知识图谱(IKGQA) 中，GoG 通过 Thinking-Searching-Generating 框架进行推理，它将 LLM 同时视为 Agent 和 KG。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-introduction&#34;&gt;1 Introduction&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/paper-GoG/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
