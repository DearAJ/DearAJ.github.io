<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pytorch on HomePage</title>
    <link>http://localhost:1313/tags/pytorch/</link>
    <description>Recent content in Pytorch on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 14 Jul 2025 11:00:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>分布式并行训练 - FSDP</title>
      <link>http://localhost:1313/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83-fsdp/</link>
      <pubDate>Mon, 14 Jul 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83-fsdp/</guid>
      <description>&lt;h2 id=&#34;fully-sharded-data-parallel&#34;&gt;Fully Sharded Data Parallel&lt;/h2&gt;&#xA;&lt;h3 id=&#34;ddp-回顾&#34;&gt;DDP 回顾&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;名词解释&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DPT-FSDP/0.0.png&#34; alt=&#34;0.0&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Host&lt;/strong&gt;：可以理解为⼀台主机，每个主机有⾃⼰的IP地址，⽤于通信。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Local Rank&lt;/strong&gt;：每个主机上，对不同GPU设备的编。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Global Rank&lt;/strong&gt;：全局的GPU设备编号，Global Rank = Host * num GPUs per host + Local Rank。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Worldsize&lt;/strong&gt;：总的GPU个数。num Hosts * num GPUs per host&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;ddp-参数更新过程&#34;&gt;DDP 参数更新过程&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DPT-FSDP/0.png&#34; alt=&#34;0&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>分布式并行训练 - DDP</title>
      <link>http://localhost:1313/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83-ddp/</link>
      <pubDate>Fri, 11 Jul 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83-ddp/</guid>
      <description>&lt;p&gt;分布式训练将训练工作负载分散到多个工作节点，因此可以显著提高训练速度和模型准确性。&lt;/p&gt;&#xA;&lt;h2 id=&#34;distributed-data-parallel&#34;&gt;Distributed Data Parallel&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;为什么用 Distributed Training？&lt;/strong&gt; 节约时间、增加计算量、模型更快。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;如何实现？&lt;/strong&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在同一机器上使用多个 GPUs&lt;/li&gt;&#xA;&lt;li&gt;在集群上使用多个机器&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;h3 id=&#34;什么是ddp&#34;&gt;什么是DDP？&lt;/h3&gt;&#xA;&lt;p&gt;即在训练过程中内部保持同步：每个 GPU 进程仅数据不同。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;模型在所有设备上复制。&lt;strong&gt;DistributedSampler&lt;/strong&gt; 确保每个设备获得不重叠的输入批次，从而处理 n  倍数据。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DPT/4.png&#34; alt=&#34;4&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;模型接受不同输入的数据后，在本地运行&lt;strong&gt;前向传播和后向传播&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DPT/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>pytorch 基础</title>
      <link>http://localhost:1313/post/pytorch%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Thu, 10 Jul 2025 11:00:59 -0400</pubDate>
      <guid>http://localhost:1313/post/pytorch%E5%9F%BA%E7%A1%80/</guid>
      <description>&lt;h2 id=&#34;数据httpspytorchaccntutorialsbeginnerbasicsdata_tutorialhtml&#34;&gt;&lt;a href=&#34;https://pytorch.ac.cn/tutorials/beginner/basics/data_tutorial.html&#34;&gt;数据&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;PyTorch 有两个用于处理数据的基元： &lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt; 和 &lt;code&gt;torch.utils.data.Dataset&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Dataset&lt;/code&gt; 存储样本及其相应的标签，&lt;code&gt;DataLoader&lt;/code&gt; 则将一个可迭代对象封装在 &lt;code&gt;Dataset&lt;/code&gt; 周围&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torch &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; nn&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; DataLoader&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torchvision &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datasets&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torchvision.transforms &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ToTensor&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;PyTorch 提供特定于域的库，例如 TorchText、TorchVision 和 TorchAudio，所有这些库都包含数据集。&lt;em&gt;以 &lt;a href=&#34;https://pytorch.ac.cn/vision/stable/datasets.html&#34;&gt;TorchVision&lt;/a&gt;) 中的 FashionMNIST 数据集为例：&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;每个 TorchVision &lt;code&gt;Dataset&lt;/code&gt; 都包含两个参数：&lt;code&gt;transform&lt;/code&gt; 和 &lt;code&gt;target_transform&lt;/code&gt;，分别用于修改样本和标签：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download training data from open datasets.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;FashionMNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    root&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ToTensor(),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
