<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tool on HomePage</title>
    <link>http://localhost:1313/tags/tool/</link>
    <description>Recent content in Tool on HomePage</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 12 Jun 2025 04:00:59 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/tool/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG实践</title>
      <link>http://localhost:1313/post/rag%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 12 Jun 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/rag%E5%AE%9E%E8%B7%B5/</guid>
      <description>&lt;h2 id=&#34;rag-整体框架&#34;&gt;RAG 整体框架&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/RAGprac/0.jpg&#34; alt=&#34;0&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;将语料库喂给LLM&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;文字分块向量化（利用LLM），从而基于向量相似度进行搜索&lt;/li&gt;&#xA;&lt;li&gt;将得到的向量存储到向量数据库中&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;搜索&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;将用户问题进行向量化，在向量数据库中进行搜索，得到相关内容&lt;/li&gt;&#xA;&lt;li&gt;将检索得到的相关内容（不一定相关）和关用户问题 一起传给 LLM&lt;/li&gt;&#xA;&lt;li&gt;LLM提取出相关信息，生成正确结果&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h3 id=&#34;llm-常见参数&#34;&gt;LLM 常见参数&lt;/h3&gt;&#xA;&lt;h4 id=&#34;temperature&#34;&gt;&lt;code&gt;temperature&lt;/code&gt;&lt;/h4&gt;&#xA;&lt;p&gt;控制生成文本的随机性。温度越高，生成的文本越随机和创造性；温度越低，文本越趋向于确定性和重复性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具链 - docker</title>
      <link>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-docker/</link>
      <pubDate>Fri, 16 May 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-docker/</guid>
      <description>&lt;p&gt;虚拟机的缺点：OS 太重、慢。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/docker/1.JPG&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;容器技术：&lt;strong&gt;只隔离应用程序的运行时环境，但容器之间可共享同一操作系统。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/docker/2.JPG&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;容器技术的代表：docker&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具链-Carla</title>
      <link>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-carla/</link>
      <pubDate>Tue, 13 May 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-carla/</guid>
      <description>&lt;p&gt;官方文档：&lt;a href=&#34;https://carla.readthedocs.io/en/0.9.9/#getting-started&#34;&gt;https://carla.readthedocs.io/en/0.9.9/#getting-started&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Carla是一款开源的 &lt;em&gt;自动驾驶&lt;/em&gt; 仿真器，它基本可以用来帮助训练自动驾驶的所有模块，包括感知系统，Localization，规划系统等等。许多自动驾驶公司在进行实际路跑前都要在这Carla上先进行训练。&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-基本架构&#34;&gt;1. 基本架构&lt;/h3&gt;&#xA;&lt;h4 id=&#34;client-server-的交互形式&#34;&gt;Client-Server 的交互形式&lt;/h4&gt;&#xA;&lt;p&gt;Carla主要分为Server与Client两个模块&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具链-PyTorch</title>
      <link>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-pytorch/</link>
      <pubDate>Thu, 17 Apr 2025 05:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-pytorch/</guid>
      <description>&lt;h2 id=&#34;1-处理数据&#34;&gt;1. 处理数据&lt;/h2&gt;&#xA;&lt;p&gt;PyTorch 有两个用于处理数据的基元： &lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt; 和 &lt;code&gt;torch.utils.data.Dataset&lt;/code&gt;。&#xA;&lt;code&gt;Dataset&lt;/code&gt; 存储样本及其相应的标签，&lt;code&gt;DataLoader&lt;/code&gt; 将 &lt;code&gt;Dataset&lt;/code&gt; 包装成一个迭代器。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;下面以 TorchVision 库模块里的 FashionMNIST 数据集为例：&lt;/p&gt;&#xA;&lt;p&gt;每个 TorchVision &lt;code&gt;Dataset&lt;/code&gt; 都包含两个参数： &lt;code&gt;transform&lt;/code&gt; 和 &lt;code&gt;target_transform&lt;/code&gt; 分别修改样本和标签&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download training data from open datasets.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;FashionMNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    root&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ToTensor(),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download test data from open datasets.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;FashionMNIST(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    root&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    download&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    transform&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ToTensor(),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将 &lt;code&gt;Dataset&lt;/code&gt; 作为参数传递给 &lt;code&gt;DataLoader&lt;/code&gt; ，将一个可迭代对象包装在数据集上，支持自动批处理、采样、洗牌和多进程数据加载。&lt;/p&gt;&#xA;&lt;p&gt;定义了一个 batch size 为 64，即 dataloader 迭代器中的每个元素将返回&lt;strong&gt;一个 64 features and labels 的 batch&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具链-深度学习</title>
      <link>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Thu, 17 Apr 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h2 id=&#34;torch--cuda--nvidia&#34;&gt;&lt;strong&gt;Torch + CUDA + NVIDIA&lt;/strong&gt;：&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;安装步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;去 Nvidia 官网下载 CUDA 并安装（核心：驱动+CUDA开发环境）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DLtool/1.png&#34; alt=&#34;1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;检查：&lt;code&gt;nvidia-smi&lt;/code&gt; 指令&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;下载 Anaconda，用于运行 python 环境&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;下载 GPU 版本的 pytorch&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/DLtool/2.png&#34; alt=&#34;2&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;可以开始跑深度学习了！&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Torch&lt;/strong&gt; 是一个深度学习框架，用于构建和训练神经网络，该可以利用&lt;strong&gt;CUDA&lt;/strong&gt;在&lt;strong&gt;NVIDIA GPU&lt;/strong&gt;上加速计算。通过在PyTorch中指定使用CUDA进行训练，可以在处理大数据集时大大提高计算效率。&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具链-强化学习</title>
      <link>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 04 Apr 2025 04:00:59 -0700</pubDate>
      <guid>http://localhost:1313/post/%E5%B7%A5%E5%85%B7%E9%93%BE-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h2 id=&#34;1-gym&#34;&gt;1. gym&lt;/h2&gt;&#xA;&lt;p&gt;官方文档：https://www.gymlibrary.dev&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;最小例子 &lt;code&gt;CartPole-v0&lt;/code&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python3&#34; data-lang=&#34;python3&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; gymenv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gym&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;make(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;CartPole-v0&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;env&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    env&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;render()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    env&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step(env&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;action_space&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sample()) &lt;span style=&#34;color:#75715e&#34;&gt;# take a random action&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;h3 id=&#34;观测-observations&#34;&gt;观测 (Observations)&lt;/h3&gt;&#xA;&lt;p&gt;在 Gym 仿真中，每一次回合开始，需要先执行 &lt;code&gt;reset()&lt;/code&gt; 函数，返回&lt;strong&gt;初始观测信息，然后根据标志位 &lt;code&gt;done&lt;/code&gt; 的状态，来决定是否进行下一次回合&lt;/strong&gt;。代码表示：&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;env.step()&lt;/code&gt; 函数对每一步进行仿真，返回 4 个参数：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;观测&lt;/strong&gt; Observation (Object)：当前 step 执行后，环境的观测(类型为对象)。例如，从相机获取的像素点，机器人各个关节的角度或棋盘游戏当前的状态等；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;奖励&lt;/strong&gt; Reward (Float): 执行上一步动作(action)后，智体(agent)获得的奖励，不同的环境中奖励值变化范围也不相同，但是强化学习的目标就是使得总奖励值最大；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;完成&lt;/strong&gt; Done (Boolen): 表示是否需要将环境重置 &lt;code&gt;env.reset&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
